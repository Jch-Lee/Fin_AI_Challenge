\n## Page 1\n\n- 주제목: 인공지능(AI) 개발 · 서비스를 위한 공개된 개인정보 처리 안내서
- 중제목: 2024. 7.
- 소제목: 발간등록번호 11-1790365-000032-01
- 소제목: 발간등록번호 11-1790365-000032-01
- 소제목: 개인정보보호위원회
- 소제목: Personal Information Protection Commission

|-------|-------|-------|
| 데이터 | 데이터 | 데이터 |
- 미완성: ... [다음 페이지에 계속]
- 연속: [이전 페이지에서 계속] ...
###
- 인용: > 사용
---
### 텍스트 내용
인공지능(AI) 개발 · 서비스를 위한 공개된 개인정보 처리 안내서
2024. 7.
발간등록번호 11-1790365-000032-01
발간등록번호 11-1790365-000032-01
개인정보보호위원회
Personal Information Protection Commission\n\n## Page 2\n\n- 주제목: 공개된 개인정보 처리 안내서
- 중제목: 안내 사항

| 일자 | 주요 내용 |
|------|-----------|
| '24. 7. 발간 | 공개된 개인정보 처리 안내서 발간 |
### 텍스트 내용
- **발간 목적**: 본 안내서는 인공지능(AI) 개발·서비스를 위해 공개된 개인정보를 처리하는 경우 참고할 수 있는 법 해석 기준을 제시하기 위해 마련되었습니다.
- **제·개정 이력**: 개인정보보호 관련 법·제도 및 환경 변화를 반영하여 다음과 같이 개정하였습니다.
- '24. 7. 발간 | 공개된 개인정보 처리 안내서 발간
- **재검토 기한**: 안내서의 최신성을 유지하기 위해 발간일(2024년 7월)을 기준으로 매 3년이 되는 시점(매 3년째의 12.31.까지를 말함)마다 보완 및 개선 등의 조치를 취할 예정입니다.
- **저작권 표시**: 본 안내서 내용의 무단전재를 금하며, 가공·인용할 때는 출처를 밝혀 주시기 바랍니다.
- *출처 : 개인정보보호위원회, 「공개된 개인정보 처리 안내서」 2024.7.
- **문의처**: 안내서 내용 관련 문의는 다음의 연락처로 주시기 바랍니다.
- 개인정보보호위원회 인공지능프라이버시팀(☎02-2100-3073, 3078)
- **관계법령**: 「개인정보 보호법」
- ※ 법령 최신 자료는 국가법령정보센터(www.law.go.kr), 개인정보 보호 안내서 최신 자료는 개인정보보호위원회 누리집*, 개인정보 포털**을 참고
- * 개인정보보호위원회 누리집(www.pipc.go.kr) : 법령 > 법률정보 > 안내서
- ** 개인정보 포털(www.privacy.go.kr) : 자료 > 자료보기 > 안내서\n\n## Page 3\n\n```markdown
# 인공지능(AI) 개발·서비스를 위한 공개된 개인정보 처리 안내서
## Contents
1. 개요
- 5
2. 공개된 개인정보 처리의 법적 근거
- 11
3. 안전성 확보 조치 기준
- 21
4. 정보주체 권리 보장 방안
- 37
5. 책임있는 AI 개발·활용을 위한 AI 기업 등의 역할
- 43
## 부록
- 45
[부록1] 자주 묻는 질문(FAQ)
- 46
[부록2] AI 단계별 주요 프라이버시 이슈
- 49
[부록3] 공개된 개인정보 관련 국내외 논의 동향
- 50
**본 안내서는 AI 개발·서비스를 위해 공개된 개인정보를 처리하는 경우 참고할 수 있는 법 해석 기준을 제시한 것으로서 법적 구속력이 없음**
```\n\n## Page 4\n\n```markdown
# 인공지능(AI) 개발·서비스를 위한 공개된 개인정보 처리 안내서
## 개요
### 1. 안내서 성격
- 안내서 성격에 대한 설명이 필요합니다.
### 2. 적용 대상
- 적용 대상에 대한 설명이 필요합니다.
## I. 개요
### 1. 안내서 성격
- 안내서 성격에 대한 설명이 필요합니다.
### 2. 적용 대상
- 적용 대상에 대한 설명이 필요합니다.
```\n\n## Page 5\n\n```markdown
# 개요
## 1. 안내서 성격
- 개인정보 보호법상 공개된 개인정보를 수집·이용할 수 있는 법 해석 기준 제시
- 공개된 개인정보는 일반적으로 헌법상 개인정보자기결정권의 보호대상으로서, 타인의 수집·이용은 원칙적으로 개인정보자기결정권을 제한할 수 있음
- 공개된 개인정보의 수집·이용은 개인정보 보호법의 목적(제1조), 원칙(제3조), 정보주체 권리(제4조) 규정의 범위 내에서 적법근거(제15조)가 충족되는 경우 허용됨
- 다만, AI 학습은 전통적인 개인정보 처리와 규모, 방식, 목적 등이 상이하여 적법근거가 불명확한 측면이 있어, 개인정보 보호법상 공개된 개인정보 수집·이용 근거를 명확히 하고자 함
- 공개된 개인정보의 수집·이용이 적법하기 위한 전제로서 AI 기업 등이 이행할 수 있는 최소한의 안전성 확보 기준을 AI 학습-서비스 주기별로 안내
- 본 안내서는 개인정보보호 법률을 토대로 공개된 개인정보의 안전한 처리에 관한 최소한의 기준을 제시하는 것임
- AI 기업 등은 모델 성능과 개인정보 보호 간 조화를 이룰 수 있는 최적의 안전성 확보 조치를 여건에 맞게 도입·시행함으로써 공개된 개인정보 처리의 적법성을 확보하고 정보주체 권리침해 위험을 예방·경감할 수 있음
- 한편, AI 관련 법·제도·기술이 지속적으로 발전·변화함에 따라 본 안내서는 주기적으로 수정·보완될 수 있음
- 본 안내서는 현시점에서 공개된 개인정보를 적법하고 안전하게 처리하기 위한 법 해석 기준을 제시하기 위한 것으로, 추후 개인정보 관련 법률의 제·개정, 새로운 판결, AI 기술발전 추이 등은 반영하여 지속 개정될 필요
- 개인정보보호위원회는 주기적 사전실태점검, 사전적정성 검토제 등을 통해 기술발전과 시장상황을 모니터링하고, 추가적인 연구와 의견수렴 등을 통해 개인정보 보호법을 AI 시대에 맞게 개정하는 작업도 추진해갈 예정임
## 2. 적용 대상
### 공개된 개인정보의 범위
- 본 안내서에서 '공개된 개인정보'는 누구나 합법적으로 접근 가능한 개인정보(개인정보 보호법 제2조 제1호)로서,
- 주로 AI 학습을 위해 웹 스크래핑 기술을 이용하여 공개적으로 접근 가능한 출처에서 수집한 데이터셋에 개인정보가 포함된 경우를 상정함
- 공개된 개인정보는 정보주체 스스로 공개한 개인정보에 국한되는 것은 아님
- 법령에 의해 공시·공개된 개인정보, 출판물, 방송매체 등에 포함된 개인정보도 사안에 따라 본 안내서의 적용 대상에 포함될 수 있음
- 또한, 공개된 개인정보 수집·이용과 관련하여 다른 법률 또는 계약상의 의무를 이행했는지 여부에 대해서는 다루지 않음
- 예: 정당한 접근권한 없이 수집된 정보(정보통신망법 제48조), 유명인의 성명·초상권 등 침해(부정경쟁방지법 제2조), 저작물의 공정한 이용(저작권법 제35조의5) 등
### 단계별 범위
#### AI 학습 단계
- AI 학습의 개념
- AI 학습은 컴퓨터가 방대한 양의 데이터를 통해 패턴, 구조, 배열 등의 통계적 상관관계를 파악하고 예측값을 생성하는 것으로서, 크게 지도학습, 비지도학습, 강화학습으로 분류됨
- 지도학습(supervised learning): AI가 레이블된 데이터를 통해 학습하는 방법으로, AI 응용 분야에서 가장 널리 사용됨
- 예: 이미지 분류 작업에서 각 이미지에 “고양이”, “개” 등의 레이블을 붙여 학습
- 비지도학습(unsupervised learning): AI가 레이블이 없는 데이터를 통해 학습하는 방법으로, 복잡하고 대량의 데이터에서 숨겨진 패턴·구조 등을 찾는데 유용함
- 예: 클러스터링(clustering) 방법을 사용하여 비슷한 특성을 가진 데이터를 그룹화
- 강화학습(reinforcement learning): AI가 주어진 환경에서 행동을 선택하고 그 결과로서 ‘보상’이나 ‘처벌’을 받도록 하여 AI가 더 나은 행동을 선택하도록 유도
- 예: 로봇학습, 자율주행차 등 다양한 분야에 적용
1) 실무에서는 웹 크롤링이나 스크래핑 모두 웹에 존재하는 데이터 수집을 위한 목적으로 사용되고 있어, 본 안내서에서는 국제적으로 통용되고 있는 '스크래핑'으로 용어 통일
```\n\n## Page 6\n\n```markdown
# AI 학습의 법적 성격
- AI 학습은 공개된 개인정보를 포함한 학습데이터 수집, 저장, 가공(토큰화 등 전처리) 등을 수반하므로 개인정보 보호법상 '처리'에 해당함
※ “처리”란 개인정보의 수집, 생성, 연계, 연동, 기록, 저장, 보유, 가공, 편집, 검색, 출력, 정정(訂正), 복구, 이용, 제공, 공개, 파기(破棄), 그 밖에 이와 유사한 행위를 의미(제2조 제2호)
## AI 서비스 단계
- AI 서비스 단계에서는 (i)이용자가 개인정보를 포함한 프롬프트를 입력하여 개인에 관한 결과값을 제공받을 수 있고, (ii)프롬프트 입력 및 결과값은 다시 AI 학습 목적으로 이용될 수 있다는 점에서 개인정보 ‘처리’에 해당
- 한편, ‘AI 학습’과 그 후 ‘AI 서비스’ 단계에서의 개인정보 처리는 정보주체에 대한 권익침해 측면에서 구분됨
- AI 서비스 단계에서는 (i)암기된 개인정보가 원본 그대로 출력되거나 (ii)개인식별 또는 민감정보 추론 목적으로 운용되는 등 AI 학습 단계보다 정보주체 권익침해 측면에서 리스크가 높아질 수 있음
- 이에 따라, AI 학습-서비스 단계별 예견 가능한 개인정보 리스크 차이를 고려하면서 적절한 보호조치를 통해 정보주체에 대한 권익침해를 예방·최소화할 필요
## 사업자 범위
- 본 안내서는 개인정보 보호법상 개인정보처리자의 지위를 갖는 AI 개발자 및 서비스 제공자를 대상으로 함
- AI 개발자 및 서비스 제공자는 원칙적으로 개인정보 보호법상의 개인정보처리자(제2조 제5호)에 해당함
- 개인정보처리자 해당 여부는 ‘업무를 목적으로 개인정보파일*을 운용하기 위한 개인정보 처리’인지를 기준으로 함
* 개인정보를 쉽게 검색할 수 있도록 일정한 규칙에 따라 체계적으로 배열하거나 구성한 개인정보의 집합물 (제2조 제4호)
- AI 개발자 및 서비스 제공자는 직업상 또는 사회생활상의 지위에 기하여 AI 관련 사무·사업을 수행하는 자로서 ‘업무 목적’이 인정됨4)
---
## AI 학습의 특성
- AI 학습은 텍스트, 이미지 등 비정형 데이터를 기계가 학습할 수 있는 하여 구조, 패턴을 찾는 것으로(예: 토큰화), 그 과정에서 개인 식별성이 낮아질 수 있음
- 또한, 기계가 반복학습을 통해 토큰화된 단어(또는 형태소)의 위치, 순서, 구조 등의 배열 방식을 확률적으로 결정한다는 점에서 개인에 대한 식별이 주된 목적이라고 단정할 수는 없음
- 다만, 학습이 완료된 AI 모델에는 개인을 식별할 수 있는 정보가 포함(embedded)되어 있을 수 있고2), 암기 리스크(memorization risk), 프롬프트 공격 등에 의하여 학습데이터에 포함된 개인정보가 유·노출3)될 가능성도 존재함
## LLM 학습을 위한 텍스트 데이터 전처리 과정
| 텍스트 | 표준화된 텍스트 | 토큰 | 토큰 인덱스 | 인덱스의 벡터 인코딩 |
|--------|----------------|------|-------------|---------------------|
| The coffee is on the table | the coffee is on the table | "the", "coffee", "is", "on", "the", "table" | 3, 47, 10, 9, 3, 285 | 원-핫 인코딩 또는 임베딩 |
| 텍스트 표준화: 구두점 제거, 어간 추출 (stemming) 등 표준화를 통해 AI 학습의 효율성 제고 | 텍스트 토큰화: 텍스트를 컴퓨터가 이해할 수 있는 숫자 벡터(vector)로 변환하기 위하여 최소 단위(토큰)으로 분할 | 토큰 인덱싱: 각 토큰을 수치 벡터로 변환하여 토큰 인덱스 생성 | 토큰 임베딩: 각 토큰 간의 의미 유사성 등 관계를 포착하기 위한 과정 |
2) 학습이 완료된 AI 모델은 학습데이터를 저장하거나 포함하지 않는다는 이견도 존재함
3) 일반적으로 개인정보 유출이란 정보주체의 개인정보에 대하여 개인정보처리자가 통제를 상실하거나 권한 없는 자의 접근을 허용한 것을 의미하며, 개인정보 노출이란 웹사이트 등에서 개인정보를 누구든지 알아볼 수 있어 개인정보 유출로 이어질 수 있는 상태를 의미함('홈페이지 개인정보 노출방지 안내서」(2024.4.) 참고)
---
## AI 학습 단계
- AI 학습 단계에서는 (i)이용자가 개인정보를 포함한 프롬프트를 입력하여 개인에 관한 결과값을 제공받을 수 있고, (ii)프롬프트 입력 및 결과값은 다시 AI 학습 목적으로 이용될 수 있다는 점에서 개인정보 ‘처리’에 해당
```\n\n## Page 7\n\n```markdown
# 인공지능(AI) 개발·서비스를 위한 공개된 개인정보 처리 안내서
## 공개된 개인정보 처리의 법적 근거
### [ 공개된 개인정보와 이용자 입력 데이터와의 구별 ]
- **이용자가 AI 모델에 입력한 질문(프롬프트)과 답변에는 개인정보가 포함될 수 있고, AI 개발자 및 서비스 제공자는 해당 데이터를 AI 학습 목적으로 이용할 수 있음**
- **이용자 입력 데이터를 AI 학습 목적으로 이용하는 경우, 공개된 개인정보와 마찬가지로 개인정보 보호법 제15조에 따른 적법근거를 충족해야 함**
- 대규모 웹 스크래핑을 통해 수집한 공개된 개인정보 처리와 달리, 이용자 입력 데이터의 경우 이용자와 AI 서비스 제공자 간의 1:1 관계를 전제로 투명한 고지와 동의에 기한 데이터 처리가 가능할 수 있음
- 따라서 이용자 입력 데이터를 AI 학습 목적으로 이용하고자 하는 경우에는 공개된 개인정보와 달리 정당한 이익(제Ⅱ장 참고) 요건의 인정 범위가 사실상 제한될 수 있고, 자발적 동의, 계약 등 다른 적법 근거가 더 유효할 수 있음
### [ 공개된 개인정보와 이용자 입력 데이터와의 구별 ]
- **해외 AI 개발자 및 서비스 제공자의 경우에도 (i)한국 정보주체를 대상으로 재화 또는 서비스를 제공하거나 (ii)한국인 또는 한국 정보주체의 개인정보를 처리하여 한국 정보주체에게 영향을 미치는 경우 등에는 원칙적으로 본 안내서가 적용됨**
- 「해외사업자 개인정보 보호법 적용 안내서」(2024.4.) 참고
### [ 공개된 개인정보와 이용자 입력 데이터와의 구별 ]
- **판례는 법률에 명시적인 역외적용 조항이 없다고 하더라도 법률의 적용 대상을 한국 사업자로 한정하는 등의 예외 규정이 없는 한, 법률에서 정한 목적, 위반행위가 국내에 미치는 영향 등을 고려하여 해외사업자에 대한 한국 법 적용을 인정(대법원 2006.3.23., 선고 2003두11124)**
---
## AI 학습 단계
... [다음 페이지에 계속]
```\n\n## Page 8\n\n```markdown
# 공개된 개인정보 처리의 법적 근거
## 목적의 정당성
- 개인정보처리자의 '정당한 이익'은 개인정보 처리에 관한 합법적인 이익으로서, AI 개발자 및 서비스 제공자의 영업상 이익뿐 아니라, 그로부터 발생하는 사회적 이익 등 다양한 층위의 이익을 포함할 수 있음
### 대법원 2016. 8. 17. 선고 2014다235080 판결("로앤비 판결")
- 이 사건 개인정보와 같이 국민 누구나 일반적으로 접근할 수 있는 정보원에 공개된 개인정보의 경우에는 이를 수집할 수 있는 '알 권리'가 정보처리자나 그로부터 정보를 제공받는 정보수용자에게 인정됨은 물론, 이러한 '알 권리'를 기반으로 하는 정보수용자들의 표현의 자유도 이 사건 개인정보의 처리행위로 보호받을 수 있는 법적 이익에 포함된다고 볼 수 있다. 또한 영업의 자유가 직업수행의 자유의 일환으로 헌법상 보장되므로, 기업이나 사인이 영리추구를 위하여 개인정보를 활용하는 것도 영업의 자유에 의하여 당연히 보장되는 영리활동에 해당한다고 할 것이고 나아가 피고 로앤비가 집적한 데이터베이스에서 정보를 편리하게 제공받고자 하는 사회적 수요가 존재한다면 그 정보제공으로 인하여 이러한 수요가 충족됨으로써 사회 전체의 경제적 효율성도 증가하게 될 것이다.
## 예시
### AI 맥락에서 정당한 이익에 포함될 수 있는 사회적 이익 예시
- AI 학습에 특정 개인정보가 배제되지 않도록 하여 인종, 종교, 지역, 성별, 소득, 재산 등에 따라 차별적인 예측값이 생성되지 않도록 하여 AI 생성물의 공정성을 높이는 것
- 특정 언어로 표시된 데이터가 과소 학습됨에 따라 특정 언어에 대한 AI 성능이 저하되고 특정 언어를 사용하는 개인의 AI 접근성이 저하되는 것을 방지하는 것
### 사례
#### 오픈소스 형태로 배포되는 AI 모델의 경우
- (사회적 이익) 자본력이 부족한 중소기업 등이 자유롭게 사용·수정·배포할 수 있도록 하여 기술의 독점을 방지하고 의료, 교육 등 다양한 분야에서의 기술 혁신을 촉진할 수 있음
- (사회적 비용) 오픈소스 모델이 배포되면 AI 모델의 활용 목적과 범위, 용도 등에 대한 최초 개발자의 통제력이 약화되어 개인정보 침해 관련 취약점이 발견되더라도 수정·회수하기 어렵고, 악의적으로 이용될 가능성(예: 거짓정보 유포 등)도 존재
## 개요
- AI 학습·서비스를 위해 공개된 개인정보를 수집·이용하는 경우, 개인정보 보호법 제15조 제1항 제6호의 정당한 이익 조항이 실질적인 적법 근거가 될 수 있음
- 정당한 이익 조항은 동의(제1호), 법률상 의무(제2호), 계약(제4호) 등 적용 영역이 구체적으로 정해져 있는 다른 근거와는 달리, AI 개발의 구체적 맥락을 고려하여 개인정보처리자 이익과 정보주체 권리를 비교형평할 수 있도록 함
- 유사한 규정을 두고 있는 EU 주요국도 AI 개발에 있어 정당한 이익 조항이 근거가 될 수 있다고 판단
### 참고 : 해외 규제기관의 AI 학습 관련 정당한 이익 인정 여부
- (영국 ICO) 개인정보처리자의 이익은 영업의 이익(business interest)은 물론 광범위한 사회적 이익(wider societal benefit)을 포함할 수 있음
- (프랑스 CNIL) AI 모델 개발 또는 과학 지식의 향상은 정당한 이익이 인정될 수 있음
- (이탈리아 Garante) ChatGPT 알고리즘 훈련을 위한 개인정보 처리의 법적 근거로 GDPR상 '동의'나 '정당한 이익' 요건을 충족하도록 요구
- (스페인 AEPD) WP29 의견 제06/2014호에 따라 적절한 보호조치가 시행되는 경우, 정당한 이익이 AI 학습을 위한 개인정보 처리에 대한 법적 근거가 될 수 있음을 인정
## 정당한 이익 조항의 성립 요건
- 개인정보 보호법은 개인정보처리자의 정당한 이익이 인정될 수 있는 경우로 다음 세 가지 요건이 충족될 것을 요구함
1. 개인정보처리자의 정당한 이익이 있을 것
2. 개인정보 처리가 정당한 이익의 달성을 위하여 필요하고, 상당한 관련성 및 합리성이 인정될 것
3. 개인정보처리자의 정당한 이익이 명백하게 정보주체의 권리보다 우선할 것
### 제15조(개인정보의 수집·이용)
- ① 개인정보처리자는 다음 각 호의 어느 하나에 해당하는 경우에는 개인정보를 수집할 수 있으며 그 수집 목적의 범위에서 이용할 수 있다.
- 6. 개인정보처리자의 정당한 이익을 달성하기 위하여 필요한 경우로서 명백하게 정보주체의 권리보다 우선하는 경우. 이 경우 개인정보처리자의 정당한 이익과 상당한 관련이 있고 합리적인 범위를 초과하지 아니하는 경우에 한한다.
6) 본 안내서는 AI 개발·서비스 목적으로 공개된 개인정보를 수집·이용하는 경우에 한하여 정당한 이익이 인정될 수 있는 판단기준을 제시하는 것임
```\n\n## Page 9\n\n```markdown
# II. 공개된 개인정보 처리의 법적 근거
## 1. 목적의 정당성 인정될 수 없는 경우
- 안면인식 DB와 결합하여 개인에 대한 프로파일링 및 감시 목적으로 AI 시스템 개발
- 사이버 공격, 개인 사칭 사기(예: 피싱·스미싱) 목적으로 AI 시스템 개발
## 2. 목적의 정당성 인정될 수 있는 경우
- 실무적으로 목적을 설정하고 ‘목적의 정당성’을 평가함에 있어, 특정 목적의 과제를 수행하도록 훈련된 ‘특정목적 AI’와 다양한 하류과제(downstream task) 수행이 가능한 ‘범용 AI’가 구분될 수 있음
### 유형(type): 대규모 언어 모델(LLM), 멀티모달모델(LMM), 판별AI 등
- 기능(functionality): 질문에 대한 답변 생성, 감정 분석 수행, 화자를 식별할 수 있는 음성 인식 기능, 차량·보행자 등을 감지할 수 있는 컴퓨터 비전 기능 등
- 성능(capability): 언어 이해·추론, 수리연산 능력 등
## 3. 처리의 필요성
- 개인정보처리자의 정당한 이익이 정보주체 권리에 우선하기 위해서는 개인정보 처리의 필요성과 상당성·합리성이 인정되어야 함
### 필요성
- 사람의 언어 발화 구조와 맥락 등을 모사하여 정확한 예측을 생성하는 LLM 개발을 위해서는 대규모 학습데이터가 필요하며, 이를 위한 현실적 방안으로 인터넷상에 공개된 데이터 활용에 의존하는 설정
- LLM이 최소한의 언어적 유창성을 확보하기 위한 어휘는 약 5만~25만 개로, 이를 위해서는 수조 개 이상의 토큰을 학습데이터로 투입할 필요(산업계 의견)
- 현재까지 학습데이터 규모에 비례하여 AI 기술의 정확도, 신뢰도 등이 대체로 향상되는 것으로 알려져 있고,
- 기술적으로도 학습데이터에서 개인정보를 완벽하게 탐지·제거하는 방법이 없어 과탐·오탐* 등으로 인한 AI 편향·차별 등 성능저하 이슈도 발생 가능
- (예) 일정한 숫자·패턴으로 표현된 긴급신고전화·법인주소·후원계좌, 소설·드라마상의 가상인물 정보 등 실제로는 비개인정보에 해당하는 데이터까지 포괄적으로 제거할 수 있음
- 또한, 한국 정보주체의 개인정보가 포함될 수 있는 공개된 데이터 이용이 불가능할 경우 한국의 문화적, 언어적 특수성이 반영되지 못하는 한계가 발생할 수 있음
- 다만, LLM 등 AI 개발·서비스를 위한 공개된 개인정보 처리 필요성은 일률적으로 인정될 수 없고, AI의 구체적인 목적, 용도, 맥락 등을 고려하여 개별적으로 판단되어야 함
### 상당성·합리성
- AI 개발자 및 서비스 제공자는 공개된 개인정보를 수집·이용하는 경우 정당한 이익과 상당한 관련이 있고, 합리적인 범위를 초과하는지 여부를 스스로 평가해보아야 함
- 또한, AI 개발 목적·용도에 맞는 학습데이터 수집 기준을 사전에 정하고, AI 개발과 상당한 관련성이 없는 정보는 학습에서 제외하는 것이 바람직함
- (예) 의료진단보조 AI 개발시 개인의 소득·재산 등 관련 없는 정보는 학습 배제
## 4. 이익형량
- 개인정보처리자의 정당한 이익이 정보주체의 권리에 우선하는지 여부를 판단함에 있어 정보주체의 권리 침해 가능성을 심도있게 검토해야 함
- 앞서 기술한 바와 같이, AI 학습은 토큰화 등 처리과정을 거치며 개인정보 유·노출 및 개인 식별위험이 낮아지는 특성이 있기는 하나,
- 웹 스크래핑 등을 통한 공개된 개인정보의 수집·이용은 ‘보이지 않는 처리’로서 정보주체의 예측가능성이 낮고, 학습된 AI 모델은 암기된 학습데이터를 역류(regurgitate)할 가능성이 있어 개인정보 침해 위험이 장기적으로 지속될 수 있으므로, 정보주체의 권리에 미치는 영향은 충실히 평가되어야 함
---
7) 데이터 스크래핑에 대한 12개 개인정보 감독기관의 공동성명(2023.8.) 참고
8) Weixin Liang et al. “What’s documented in AI? Systematic Analysis of 32K AI Model Cards” (2024.2.) 참고
```\n\n## Page 10\n\n```markdown
# II. 공개된 개인정보 처리의 법적 근거
## 1. 정보주체의 권리 및 개인정보 처리의 법적 이익
- 특히, 침해 또는 제한될 수 있는 ‘정보주체의 권리’는 개인정보 자기결정권에 국한되지 않고, 개인정보 자기결정권의 침해로 인해 제한되거나 침해될 수 있는 헌법상 기본권으로서 인간의 존엄과 가치 및 행복추구권(헌법 제10조), 사생활의 비밀과 자유(헌법 제17조) 등을 포함한다고 볼 수 있음
- 법원은 공개된 개인정보 처리에 의해 충돌할 수 있는 개인정보 처리자의 법적 이익과 정보주체의 인격적 법익을 구체적으로 비교 형량함에 있어
- (i) 정보주체가 공적인 존재인지 (ii) 개인정보의 공공성과 공익성 (iii) 원래 공개한 대상 범위 (iv) 개인정보 처리의 목적·절차·이용형태의 상당성과 필요성 (v) 개인정보 처리로 인하여 침해될 수 있는 이익의 성질과 내용 등 여러 사정을 종합적으로 고려할 수 있다고 판시함
## 2. 대법원 2016. 8. 17. 선고 2014다235080 판결("로앤비 판결")
- 개인정보 자기결정권이라는 인격적 법익을 침해·제한한다고 주장되는 행위의 내용이 이미 정보주체의 의사에 따라 공개된 개인정보를 그의 별도의 동의 없이 영리 목적으로 수집·제공하였다는 것인 경우에는, 그와 같은 정보 처리 행위로 침해될 수 있는 정보주체의 인격적 법익과 그 행위로 보호받을 수 있는 정보 처리자 등의 법적 이익이 하나의 법률관계를 둘러싸고 충돌하게 된다. 이때는 정보주체가 공적인 존재인지, 개인정보의 공공성과 공익성, 원래 공개한 대상 범위, 개인정보 처리의 목적·절차·이용형태의 상당성과 필요성, 개인정보 처리로 인하여 침해될 수 있는 이익의 성질과 내용 등 여러 사정을 종합적으로 고려하여, 개인정보에 관한 인격적 보호에 의하여 얻을 수 있는 이익과 정보 처리 행위로 얻을 수 있는 이익 즉 정보 처리자의 '알 권리'와 이를 기반으로 한 정보 수용자의 '알 권리' 및 표현의 자유, 정보 처리자의 영업의 자유, 사회 전체의 경제적 효율성 등의 가치를 구체적으로 비교 형량하여 어느 쪽 이익이 더 우월한 것으로 평가할 수 있는지에 따라 정보 처리 행위의 최종적인 위법성 여부를 판단하여야 하고, 단지 정보 처리자에게 영리 목적이 있었다는 사정만으로 곧바로 정보 처리 행위를 위법하다고 할 수는 없다.
## 3. AI 학습·서비스 맥락에서는 공개된 개인정보의 성격, 공개의 대상 범위, 공개된 개인정보의 처리 방식, 정보주체의 예견 가능성, 권리 보장 방안 등을 고려하여 '정보주체 권리'에 대한 침해·제한 정도를 평가할 수 있음
### [ 정보주체 권리에 영향을 미치는 요소 예시 ]
#### 요소
- 공개된 개인정보의 성격
- ▲ 개인정보의 민감성(예: 생체인식정보, 아동 개인정보 등)이 높을수록 정보주체의 보호 법익이 상대적으로 큼
- ▲ 공인에 관한 정보로서 사회 일반의 알 권리가 인정될 필요가 있는 개인정보는 보호 법익이 상대적으로 낮음
※ 단, 공인의 사생활에 관한 정보로서 알 권리 인정 가능성이 낮은 경우에는 여전히 보호 법익이 낮아진다고 보기 어려움
#### 정보주체 권리에 미치는 영향
- ▲ 공개 대상이 일정한 관계에 있는 제3자만 접근할 수 있는 경우에는 정보주체의 보호 법익이 상대적으로 큼
- ▲ 공개 대상에 특별한 제한 없이 일반적으로 누구나 접근할 수 있는 상태인 경우에는 정보주체의 보호 법익이 상대적으로 낮음
## 4. 정보주체 권리에 미치는 영향 요소
#### 요소
- 공개된 개인정보의 처리 방식
- ▲ 민감 정보 추론 또는 프로파일링을 위한 처리 방식은 정보주체의 권리 침해 가능성이 높음
- ▲ LLM 학습과 같이 텍스트 배열 등 통계적 상관관계를 파악하기 위한 데이터 처리 방식은 정보주체 권리 침해 가능성이 비교적 낮음
- 정보주체의 예견 가능성
- ▲ 정보주체가 당초 공개한 목적·범위를 초과하여 합리적으로 기대하기 어려운 방식으로 개인정보가 처리되는 경우에는 정보주체 권리 침해 가능성이 높음
- ▲ 정보주체가 동의한 서비스 이용 약관, 개인정보 처리방침 등에 AI 학습 데이터 처리에 관한 근거가 언급된 경우에는 정보주체의 권리 침해 가능성이 낮아짐
- 정보주체 권리 보장 방안
- ▲ 정보주체 이외로부터 수집한 개인정보의 수집 출처 등 통지, 열람, 삭제, 처리 정지권 등 법률에 따른 권리 행사 보장이 불충분한 경우 정보주체의 개인정보에 대한 통제권이 상당히 약화될 수 있음
- ▲ 정보주체의 개인정보 자기 결정권을 보장하기 위한 다양한 권리 행사 방안·절차가 마련되는 경우 정보주체 권리 침해 위험이 낮아짐
## 5. 개인정보 처리자의 이익이 정보주체 권리에 우선함이 명백한 경우
### 사례
- 금융사기 탐지·방지 등 정보주체 또는 제3자의 급박한 생명, 재산 등 이익을 위해 필수적인 경우
- 전자 통신망에의 무단 접근 예방, 정보 보안 목적을 위해 반드시 필요한 경우
- 범죄 행위 또는 공공 안보에 대한 위험으로부터의 보호·예방을 위해 필요한 경우
9) 이 경우에도 공개된 개인정보 처리의 필요성과 상당성·합리성 요건이 충족되어야 하고, 구체적인 맥락·위험 수준에 비례한 안전성 확보 조치 노력이 필요함
```\n\n## Page 11\n\n```markdown
# II. 공개된 개인정보 처리의 법적 근거
## [명백성 관련 개인정보보호위원회 심의·의결 사례]
### 제2015-12-22호("철도차량 운전실 CCTV로 운전제어대와 기관사 양손 촬영")
- (사실관계) 한국철도공사가 철도차량 운전실에 CCTV를 설치하여 각종 계기판과 안전운행장치 등으로 구성된 운전제어대와 그 위에 위치한 기관사의 두 손을 촬영하고, 촬영된 영상정보를 최장 7일간 각 운전실 저장장치에 저장하고 철도사고시에만 사고원인 규명을 위해 열람·이용
- (이익형량 대상) 한국철도공사의 '철도사고 원인규명'과 '승객의 안전 확보'에 기관사의 양손이 의사에 반하여 촬영되지 아니할 개인정보자기결정권
- (위원회 판단) ①철도사고 원인규명과 승객의 안전 확보는 한국철도공사의 정당한 이익에 해당, ②본건 영상정보의 수집이 철도사고시 기관사가 안전운행장치를 정상 작동하였는지를 확인하는데 필요하며(상당한 관련성), ③본건 영상정보 수집에 있어 개인정보의 노출은 운전제어대 위에 위치한 기관사 양손에 한정되고, 수집된 영상정보는 사고원인 규명에 열람·이용되며 일정기간 경과 후 삭제된다는 점 등을 감안하면 합리적 범위를 초과한다고 보기 어려움(합리성)
- 승객의 안전 확보를 통한 국민의 생명과 신체 보호라는 공익은 큰 반면, 기관사에 대한 사생활 침해는 미미하여 개인정보처리자의 정당한 이익이 명백히 우선함
## [명백성 관련 개인정보 분쟁조정 사례]
### 야간 휴식공간 겸용 관리사무소 사무실 내 CCTV 상시운영(2015)
- (사실관계) 시설물 안전 및 범죄 예방 등을 위하여 CCTV 1대가 상시 작동 중인 관리사무소 사무실에서 경비원으로 근무하던 신청인은 24시간 감시당하는 것 같아 심적으로 괴롭고 불안정하며 일상생활에 지장이 있는 등 인권이 침해당했음을 주장하며 분쟁조정 신청
- (이익형량 대상) 관리사무소의 시설안전과 범죄예방의 정당한 이익, ②목적 달성을 위해 CCTV 설치 필요성 인정, ③시설안전을 위해 필요한 경우에도 타인의 사생활이 침해되지 않도록 필요 최소한의 범위에서 CCTV 운영 필요
- 야간에는 근무공간과 취침공간이 공존하므로 야간 근무자의 취침공간까지 지속적으로 촬영할 필요까지 인정하기 어렵고, 사생활 보호를 위한 최소한의 조치* 없이 사무실 전체를 모두 촬영하는데 따른 관리사무소의 이익이 경비원의 권리보다 명백하게 우선하는 것으로 단정하기 곤란
- *야간근무 시 CCTV 녹화 중단, 카메라가 취침공간을 비추지 않도록 가림막 설치, 카메라 각도 조절 등
## 참고 정보주체 동의가 객관적으로 인정될 수 있는 경우(대법원 판결)
- 대법원은 공개된 개인정보의 특성을 고려하여 정보주체가 이미 공개한 개인정보는 객관적으로 동의 의사가 인정될 수 있는 범위에서 별도 동의 없이 처리할 수 있다고 판시함
- 객관적으로 정보주체의 동의가 있었다고 인정되는 범위 내인지는 공개된 개인정보의 성격, 공개의 형태 등 6가지 기준을 검토하여 객관적으로 판단할 수 있음
### 대법원 2016. 8. 17. 선고 2014다235080 판결("로앤비 판결")
- 정보주체가 직접 또는 제3자를 통하여 이미 공개한 개인정보는 ... 일정한 범위 내에서 동의를 하였다고 할 것이다. (중략) 정보주체의 동의가 있었다고 인정되는 범위 내인지는 ①공개된 개인정보의 성격, ②공개의 형태와 대상 범위, ③그로부터 추단되는 정보주체의 공개 의도 내지 목적뿐만 아니라, ④정보처리자의 정보제공 등 처리의 형태와 ⑤정보제공으로 공개의 대상 범위가 원래의 것과 달라졌는지, ⑥정보제공이 정보주체의 원래의 공개 목적과 상당한 관련성이 있는지 등을 검토하여 객관적으로 판단하여야 한다.
## 대법원 판결은 AI 개발·서비스를 위한 공개된 개인정보 처리에 직접 적용된 판단은 아니지만, 아래의 사항을 '정당한 이익'의 이익형량 과정에서 보충적으로 참고할 수 있음
| 대법원 판단기준 | 구체적 고려사항 |
|------------------|------------------|
| ① 공개된 개인정보의 성격 | 개인 정보 보호법에서 특별히 보호하는 항목*은 정보주체의 객관적 동의의사를 인정할 수 있는 범위가 좁아짐<br>* 민감정보, 고유식별정보, 아동-청소년 개인정보 등 |
| ② 공개의 형태와 대상 범위 | 공개 형태와 대상이 일정한 관계에 있는 제3자만 접근할 수 있는 경우에는 누구나 접근할 수 있는 경우에 비해서 정보주체의 객관적 동의의사를 인정할 수 있는 범위가 좁아짐 |
| ③ 정보주체의 공개 의도 내지 목적 | 일반적으로 정보주체의 주관적인 내심의 의사를 파악하는 것은 현실적으로 어려우나, 서비스 형태·목적이 광범위한 정보공유를 위한 것이라면 공개의도 내지 목적 인정 범위가 넓어짐<br>※ 서비스 이용약관, 개인정보 처리방침 등에 정보 공개·이용 관련 사항 포함 시 공개 의도 내지 목적 판단에 참고 가능(트위터 판례<sup>[10]</sup>) |
---
<sup>[10]</sup> 트위터 이용약관과 개인정보취급방침에 (i) 사용자 정보의 수집·이용에 대한 동의 (ii) 콘텐츠의 다양한 재사용을 권장 및 허용하며 트위터 API는 이를 목적으로 한다는 점 (iii) 사용자의 공개 프로필 정보와 공개트윗은 API를 통해 트위터사의 광범위한 사용자들과 서비스로 즉시 전달된다는 규정 등이 포함되어 있었고, 사용자들이 트위터에 가입하면서 이용약관과 개인정보취급방침의 적용에 동의했으므로 트위터 정보의 제3자 제공에 대해 포괄적 동의의 인정(서울고등법원 2015노1998)
```\n\n## Page 12\n\n- 주제목: 인공지능(AI) 개발·서비스를 위한 공개된 개인정보 처리 안내서
- 중제목: III 안전성 확보 조치 기준

| 대법원 판단기준 | 구체적 고려사항 |
|------------------|------------------|
| ④ 정보처리자의 정보제공 등 처리의 형태 | 개인정보처리자가 안전성 확보를 위한 일반적 원칙과 규제를 준수하고, 개인의 식별 위험성을 낮추는 보호조치 등을 수행하는 경우 정보주체의 객관적 동의의사 인정 범위가 넓어짐 |
| ⑤ 공개의 대상 범위가 변경되었는지 여부 | 공개데이터를 AI 학습용으로 가공·재배포 하는 등의 경우 홈페이지 공개·설명 등 불특정 다수의 합리적 기대가능성을 높이는 조치가 있다면 인정 범위가 넓어짐 |
| ⑥ 원래의 공개 목적과의 상당한 관련성 | 정보주체 권익을 침해하는 목적·용도의 AI 서비스의 경우에 상당한 관련성 인정이 어려울 수 있음(예: 민감정보 프로파일링) |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용\n\n## Page 13\n\n- 주제목: III. 안전성 확보 조치 기준
- 중제목: 개요
- 소제목: 기술적 조치
- 세부: 1-1 학습데이터 수집 출처 검증·관리

| 년도 | 공공 | 민간 | 합계 |
|------|------|------|------|
| 2016년 | 7,968 | 2,641 | 10,609 |
| 2017년 | 11,438 | 13,594 | 25,032 |
| 2018년 | 862 | 12,562 | 13,424 |
| 2019년 | 1,581 | 12,895 | 14,476 |
| 2020년 | 1,981 | 13,057 | 15,038 |
| 2021년 | 2,181 | 16,625 | 18,806 |
| 2022년 | 2,525 | 16,841 | 19,366 |
| 2023년 | 1,420 | 20,999 | 22,419 |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
- 주제목: III. 안전성 확보 조치 기준
- 중제목: 사례 2. 데이터 출처 검증을 위한 고려사항
- 소제목: AI 개발자 대상 권고사항

|--------|--------|--------|
| 불법 복제물, 아동 성착취물 등 위법한 데이터가 거래되거나 거래될 가능성이 높은 도메인(예: 딥웹, 다크웹)으로부터 학습데이터 수집 금지 | 개인정보가 집적되어 있을 개연성이 높은 웹사이트(예: 개인정보 색인·거래 사이트) 배제 | 로봇배제표준(robots.txt) 준수 | 저작권, 디자인권 등 지식재산권 존중 |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용\n\n## Page 14\n\n- 주제목: III. 안전성 확보 조치 기준
- 중제목: 1-2 개인정보 유·노출 방지
### 구조
- 문단: 빈 줄로 구분
- 번호 목록: 1. 2.
- 글머리: - 또는 *
- 들여쓰기: 2칸 또는 4칸
| Dataset | Example | Near-Duplicate Example |
|---------|---------|------------------------|
| Wiki-40B |\n_START_ARTICLE.\nHum Award for Most Impactful Character\n_START_SECTION.\nWinners and nominees\n_START_PARAGRAPH.\nIn the list below, winners are listed first in the colored row, followed by the other nominees.[...] |\n_START_ARTICLE.\nHum Award for Best Actor in a Negative Role\n_START_SECTION.\nWinners and nominees\n_START_PARAGRAPH.Whln the list below, winners are listed first in the colored row, followed by the other nominees.[...] |
| LM1B    | I left for California in 1979 and tracked Cleveland's changes on trips back to visit my sisters. | I left for California in 1979, and tracked Cleveland's changes on trips back to visit my sisters. |
| C4     | Affordable and convenient holiday flights take off from your departure country, "Canada". From May 2019 to October 2019, Condor flights to your dream destination will be roughly 6 a week! Book your Halifax (YHZ) – Basel (BSL) flight now, and look forward to your "Switzerland" destination! | Affordable and convenient holiday flights take off from your departure country, "USA". From April 2019 to October 2019, Condor flights to your dream destination will be roughly 7 a week! Book your Maui Kahului (OGG) – Dubrovnik (DBV) flight now, and look forward to your "Croatia" destination! |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
### 텍스트 추출
#### 제목
- III. 안전성 확보 조치 기준
#### 소제목
- 1-2 개인정보 유·노출 방지
#### 본문
- 일정한 단어 또는 형태소(morpheme) 단위로 토큰화된 학습데이터는 그 자체로 식별성이 낮을 수 있으나, 출력 단계에서 암기된 토큰이 재조립되어 역류(regurgitate)될 가능성이 있어 이를 최소화하기 위한 기술적 조치가 필요함
- AI 개발자 및 서비스 제공자는 법에서 처리를 금지 또는 제한하고 있는 주민등록번호와 그 밖의 고유식별정보, 유·노출 시 막대한 경제적 피해를 야기할 수 있는 계좌정보, 신용카드정보 등의 경우 출력 단계에서의 유·노출을 방지하기 위하여 각별한 주의를 기울일 필요가 있음
- 특정 범주의 개인 식별자를 AI 학습 전 삭제하거나 비식별화하는 조치는 비교적 용이하게 고려할 수 있는 안전조치 중 하나이나, 오탐률과 AI 모델 자체의 성능저하* 등을 종합적으로 고려하여 도입할 수 있음
- 숫자나 일정 자릿수로 표시되는 특정 범주의 개인정보 삭제 기술은 현재까지 위양성률(false-positive rates) 또는 과다 필터링(over-filtering) 문제가 있는 것으로 알려져 있으므로, 추가적인 안전성 확보 조치 통해 개인정보 유·노출 위험을 낮추는 것이 권장됨
#### 사례
- **사례 1** 개인 식별자 삭제 또는 비식별화 사례
- 발화데이터 비식별화 예시
- [혈액형] 나의 혈액형은 [BLOOD_TYPE_1]. 어떤 혈액형과의 성형이 가장 잘 맞을까?
- [병명] 나 [CONDITION_1] 어제 쉬었어.
- [복용약/탕] 나 어제 [DRUG_1] 먹었는데, 효과 좋더라. 너도 이걸로 먹어. 하루에 [DOSE_ [항정신성 의약품] 나 아는 형이 [DRUG_2] 줘서 먹었는데, 절더라
- [외상/상처] 나 [CONDITION_3] 있는데, 어떻게 극복할 수 있을까?
- [의료 행위] 어제 [MEDICAL_PROCESS_1], [CONDITION_4]이 심하다는 데, 살 빠려면 어 어제 [MEDICAL_PROCESS_2], 무릎 연골이 부숴져서 나 이제 못 걸을 수 있다 어제 [OCCUPATION_1] 쌤이 [CONDITION_5] [MEDICAL_PROCESS_3]? 같은 [전문적/통계적 지식] 어제 [OCCUPATION_1] 쌤한테 들었는데, [CONDITION_6] 치료율이 [STATIS [은행_계좌] 우리 은행 [BANK_ACCOUNT_1] [MONEY_1] 보내줘 하나 [CREDIT_CARD_1] 주인 이름이 어떻게 되니? [신용카드] [ORGANIZATION_1] [CREDIT_CARD_2] [CREDIT_CARD_EXPIRATION_1] [ [금융_거래정보]
- 고유식별정보
- 주민등록번호
- 운전면허번호
- 여권번호
- 민감정보
- 종교
- 정치이념
- 노동조합명
- 질병명
- 범죄 경력 자료
- 기타개인정보
- 계좌번호
- 신용카드정보 등
- 나아가, AI 개발자 및 서비스 제공자는 개인 식별가능성을 줄이거나 제거하기 위한 기술적 방안으로 차분 프라이버시*(Differential Privacy) 등 개인정보 보호 강화 기술(Privacy Enhancing Technologies)의 효과를 지속적으로 연구·검증하고 적용할 것이 권장됨
- 특정 데이터베이스에 잡음(noise)을 추가하여 원본 데이터의 프라이버시는 보호하면서 통계적 유용성은 유지하는 기법으로, 데이터 수집-AI 학습-서비스 출력 단계에서 모두 적용 가능함
- 메타(Opacus), 구글(TensorFlow Privacy), IBM(Diffprivlib) 등에서 차분 프라이버시 기술 지원[13]
#### 차트/그래프
- 학습데이터 내 시퀀스 중복과 암기 리스크의 상관관계[11]
- 공개데이터셋에 포함된 중복 시퀀스(NearDup) 사례[12]
#### 각주
- 11) Carlini et al., “Quantifying Memorization Across Neural Language Models” (2023.3.)
- 12) Katherine Lee, “Deduplicating Training Data Makes Language Models Better” (2022.3.)
- 13) 개인정보 기술포럼, 「AI PET 보고서」(2023.12.)\n\n## Page 15\n\n- 주제목: III. 안전성 확보 조치 기준
- 중제목: 1-3 개인정보의 안전한 저장 및 관리
- 소제목: 1-4 미세조정을 통한 안전장치 추가

| 미세조정 기법 사례 | 파라미터 효율 미세조정(PEFT) | 지도학습 기반 미세조정(SFT) | 사람 피드백 기반 강화학습(RLHF) |
|-------------------|----------------------------|-----------------------------|--------------------------------|
| 파라미터 효율 미세조정(PEFT) | 사전학습된 모델 파라미터(매개변수)를 동결하고 소수의 파라미터를 의도된 용도에 맞게 미세조정하는 것으로 학습 비용과 시간을 최소화하는 방법 | 비지도학습으로 만들어진 생성AI를 지도학습적으로 미세조정하는 과정으로, 바람직한 답변을 생성하도록 미리 정제되거나 레이블링된 데이터를 추가 학습 | 보상모델 생성(Reward Model Creation): AI 모델이 생성한 출력물에 사람(라벨러)이 점수 또는 순위를 부여하고, 이를 토대로 보상모델을 훈련 |
| - | - | - | - |
| - | - | - | - |
| - | - | - | - |
| - | - | - | - |
| 다양한 미세조정 방식 비교 | 파라미터 효율 미세조정 (PEFT) | 지도학습 기반 미세조정 (SFT) | 사람 피드백 기반 강화학습 (RLHF) |
|--------------------------|------------------------------|------------------------------|----------------------------------|
| 방 법 | 소수의 파라미터 조정(~0.01%) | 이상적 답변 생성을 위한 추가학습 | 보상모델 생성 및 정책 최적화 |
| 학습데이터 | X백개 이상 | X만개 ~ XX만개 | X만개 ~ XX만개 |
| 학습 비용 | 비교적 저렴 | 비교적 비쌈 | 비교적 비쌈 |
| 학습 시간 | Minutes | Days | Days |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
### 텍스트 추출
#### 1-3 개인정보의 안전한 저장 및 관리
- AI 개발자 및 서비스 제공자는 학습데이터가 유·노출되거나 이용자 DB 등과 결합하여 개인을 식별하거나 민감정보를 추론할 수 있는 리스크를 방지·예방하기 위하여 접근제한 등 안전조치를 고려할 필요
- 개인정보 보호법
- 제3조(개인정보 보호 원칙) ④ 개인정보처리자는 개인정보의 처리 방법 및 종류 등에 따라 정보주체의 권리가 침해받을 가능성과 그 위험 정도를 고려하여 개인정보를 안전하게 관리하여야 한다.
- 제29조(안전조치의무) 개인정보처리자는 개인정보가 분실·도난·유출·위조·변조 또는 훼손되지 아니하도록 내부 관리계획 수립, 접속기록 보관 등 대통령령으로 정하는 바에 따라 안전성 확보에 필요한 기술적·관리적 및 물리적 조치를 하여야 한다.
- 개인정보의 안전성 확보조치 기준(개인정보보호위원회 고시, 2023.9.22. 시행)
- 제3조(안전조치의 적용 원칙) 개인정보처리자는 처리하는 개인정보의 보유 수, 유형 및 정보주체에게 미치는 영향 등을 고려하여 스스로의 환경에 맞는 개인정보의 안전성 확보에 필요한 조치를 적용하여야 한다.
#### 1-4 미세조정을 통한 안전장치 추가
- 학습데이터에는 편향적이거나 부정확한 정보, 민감한 사적정보가 포함될 수 있어 사전 정제 과정이 수반되는 경우가 많으나, 이로써 모든 위험이 예방되는 것은 아니기 때문에 미세조정(fine-tuning)을 통한 추가 안전장치를 마련할 것이 권장됨
- AI 모델이 사람의 의도에 부합하게 안전하고 바람직한 답변을 생성하도록 지도학습 기반 미세조정 (Supervised Fine-Tuning, SFT), 사람 피드백 기반 강화학습*(Reinforcement Learning with Human Feedback, RLHF)등의 미세조정 기법 적용을 고려할 수 있음
- 생성AI가 생성한 답변에 대하여 사람이 피드백(보상 또는 벌)을 부여하고, 이를 추가 학습하여 안전하고 유용한 답변을 제공하도록 미세조정(GPT-3.5와 GPT-4, Claude-2, Llama-2에 이용됨)
- 최근 RLHF에 소요되는 막대한 비용(사람 레이블러 동원에 필요한 비용)과 사람의 주관적 편향성, 기술적 복잡성 등에 대한 한계를 보완하기 위하여 RLHF를 대체하는 방법론(예: Direct Preference Optimization, DPO)등이 꾸준히 연구 중으로, 향후 이러한 기술적 발전을 고려하여 안전장치를 확보하는 것이 바람직함
---
### 각주
14) SPri 이슈리포트 IS-158, “초거대언어모델의 부상과 주요이슈” (2023.2.)
15) Edward Beeching et al. “Fine-tuning 20B LLMs with RLHF on a 24GB Consumer GPU” (2023.3.)\n\n## Page 16\n\n- 주제목: III. 안전성 확보 조치 기준
- 중제목: 1-5 프롬프트 및 출력 필터링 적용

### 텍스트
- **사례 2 미세조정을 통한 안전장치 추가 사례**:
- **사람 피드백 기반 강화학습(RLHF)**:
- 개인에 관한 콘텐츠 생성을 최소화하는 보상모델 마련하고, 추가적인 강화학습 수행
- 미세조정된 안전제어를 우회하려는 탈옥시도에 대한 저항력을 높이는 보상모델 마련
- **ChatGPT 적용사례**:
- **ChatGPT 4**:
- **You**: 손흥민 서울 집주소 알려주세요.
- **ChatGPT**: 손흥민 선수의 집 주소나 개인 정보는 제공할 수 없습니다. 대중 인물의 개인 정보 보호는 중요하며, 이러한 정보의 공유는 부적절합니다. 다른 질문이 있으시면 도와드리겠습니다.
- **텍스트-이미지 생성AI 영역에서의 적용 가능성**:
- **Step 1. Collecting human data**
- **Step 2. Learning reward function**
- **Step 3. Updating text-to-image model**
- **안전맥락정제(Safety Context Distillation)**:
- 생성AI에 선의의 프롬프트*(good-behavior prompts)를 사전 설정(pre-fix)하고, 해당 사전 설정을 준수하도록 미세조정(이용자 변경 불가)
- (예) “당신은 안전하고 책임감 있는 AI 어시스턴트입니다”
- **프롬프트 필터**:
- 사용자가 프롬프트 입력을 통해 개인을 프로파일링하거나 사생활 침해 우려가 큰 답변 생성을 유도하는 경우, 이에 대한 답변 생성을 거절하거나 프롬프트의 맥락-취지에 따라 미리 정해진 답변을 제공하는 등의 방식을 고려할 필요
- 실무적으로 입력된 프롬프트가 성명을 포함한 개인(named individual)에 대한 정보를 구하는 경우 해당 이름을 가진 개인에 대한 위키백과(Wikipedia) 페이지가 개설되어 있는지 우선 확인하고, 위키백과 페이지가 없는 경우에는 해당 쿼리에 대한 결과를 제공하는 않는 사례도 있음
- **부적절한 이용자 프롬프트에 대한 필터 사례**:
- **내 주민등록번호는 [블러드] 이아**
- **죄송하지만, 주민등록번호와 같은 민감한 개인정보를 여기서 공유하지 마세요. 온라인에서 개인정보를 공유하는 것은 신원 도용과 같은 심각한 문제를 일으킬 수 있습니다.**
- **주민등록번호와 같은 중요한 정보를 보호하기 위해 다음과 같은 조치를 취하는 것이 좋습니다:**
1. 개인 정보 공유 자제: 온라인에서 개인 정보를 절대 공유하지 마세요.
2. 보안 강화: 강력한 비밀번호를 사용하고, 이중 인증을 설정하세요.
3. 정기적인 모니터링: 자신의 신용 보고서나 계정을 정기적으로 확인하여 의심스러운 활동이 있는지 점검하세요.
4. 의심스러운 활동 신고: 신원 도용이 의심되면 즉시 관련 기관에 신고하세요.
- **또한, 만약 이미 민감한 정보를 공유했다면, 가능한 빨리 삭제하고 필요 시 관련 당국에 문의하여 적절한 조치를 취하시기 바랍니다.**
- **출력 필터**:
- AI 모델이 생성하는 출력물에서도 개인정보가 노출·생성되지 않도록 감지·제거하는 필터 기술을 적용하는 것이 바람직함
### 각주
16) Hugo Touvron et al. “LLaMA 2: Open Foundation and Fine-Tuned Chat Models” (2023)
17) Kimin Lee et al. “Aligning Text-to-Image Models using Human Feedback” (2023)
18) GPT-4 기반의 ChatGPT에 가상의 주민등록번호를 입력하여 출력된 결과물임\n\n## Page 17\n\n- 주제목: III. 안전성 확보 조치 기준
- 중제목: 1-6 학습 결과에서 특정 데이터 삭제(머신 언러닝 등)
- 중제목: 2-1 학습데이터 처리기준 정립 및 개인정보 처리방침에 공개
- 중제목: 2-2 개인정보 영향평가 수행 고려
- 소제목: [관련 국제 논의 동향]

|-------|-------|-------|
| 데이터 | 데이터 | 데이터 |
- 미완성: ... [다음 페이지에 계속]
- 연속: [이전 페이지에서 계속] ...
###
- 인용: > 사용
---
### 텍스트 추출
#### 1-6 학습 결과에서 특정 데이터 삭제(머신 언러닝 등)
- 최근 AI 모델에 대한 '재훈련' 없이도 개인정보나 유해한 표현 등을 '삭제'해주는 기술로서 '머신 언러닝 (machine unlearning)'에 대한 연구가 활발함
- 머신 언러닝 기술은 모델 가중치 조정을 통해 문제되는 개인정보를 삭제하는 효과가 있다고 알려져 있어, AI 모델의 재훈련에 소요되는 막대한 비용과 시간을 줄일 수 있는 대안 기술이 될 것으로 기대됨
- 머신 언러닝 기술은 기술 성숙도 측면에서 아직 초기 수준이라고 볼 수 있지만, 향후 연구 성과와 기술 개발 추이에 따라 AI 개발자 및 서비스 제공자는 머신 언러닝 기술 적용을 적극 고려할 수 있음
#### [머신 언러닝 기술 작동방식]
- AI가 학습한 데이터셋에서 특정 데이터를 지우면서도 전체적인 지능이나 학습 모델에는 영향을 미치지 않도록 하는 기술로 다양한 접근법이 연구·개발 중
- 출처: NeurIPS 2023 - Machine Unlearning Challenge
#### 2-1 학습데이터 처리기준 정립 및 개인정보 처리방침에 공개
- 최소 수집, 목적 명확화 등 개인정보 보호법 원칙을 고려하여 학습데이터 수집·이용 기준*을 미리 정하고, 이를 개인정보 처리방침, 기술문서, FAQ 등에 공개하는 것을 권장함
- AI 시스템 개발에 필요한 데이터 양(volume), 범주(민감정보, 행태정보 등) 등을 고려하여, 공개된 개인정보의 주요 수집 출처, 수집 방법, 안전성 확보 조치 방안 등 포함
- 학습데이터 수집·이용 기준은 알기 쉬운 용어로 구체적이고 명확하게 표현하여야 하고, 특히 해외사업자의 경우 국내 이용자가 이해할 수 있는 쉽고 명확한 한국어 정보를 제공하여야 함
- 표준 개인정보 보호지침 제18조(개인정보 처리방침의 작성기준 등) 참고
#### 2-2 개인정보 영향평가 수행 고려
- AI 개발자 및 서비스 제공자는 공개된 개인정보 등을 활용하는 경우 개인정보 영향평가 실시를 고려할 수 있음
- 개인정보 보호법 시행령 제35조 내지 제38조, 「개인정보 영향평가 수행 안내서」(2024.4.) 등 참고
- AI 학습데이터에 민감한 정보가 포함되어 있을 개연성이 높거나 정보주체 권리·의무에 중대한 영향을 미칠 수 있는 AI 서비스를 개발·운영하는 경우 특히 영향평가를 실시를 고려하는 것이 바람직함
- 공공기관이 아님에도 불구하고 개인정보 보호법 제33조에 따라 영향평가를 수행하는 경우 개인정보 보호법 위반 과징금에 대해 1차 조정 금액의 최대 30%를 추가로 감경받을 수 있는 근거규정 마련·시행 중(개인정보 보호법 위반에 대한 과징금 부과기준 제10조 제2항, 2023.9.15. 제정)
- 미국, 영국, 프랑스 등 주요국에서도 웹 스크래핑을 통해 학습데이터를 수집·이용하는 경우 영향평가 수행을 권고하거나 의무화하는 논의가 진행 중
#### [관련 국제 논의 동향]
- (미국) 관리예산국(OMB)은 'AI 행정명령(2023.10.)' 이행을 위해 연방기관 대상 'AI 위험 완화 및 혜택 활용에 관한 정책'을 발표(2024.3.)
- AI의 의도된 목적과 기대되는 혜택, AI 사용의 잠재적 위험과 완화 조치, AI 학습·미세조정에 사용되는 모든 데이터 출처 등에 대한 영향평가를 실시하고, 그 결과를 공개하도록 함
- (EU) 프랑스 및 영국 개인정보 규제당국은 대규모 웹 스크래핑을 통해 수집한 학습데이터에 대하여 GDPR 및 UK GDPR에 따른 개인정보 영향평가 수행을 권고\n\n## Page 18\n\n
|-------|-------|-------|
| 데이터 | 데이터 | 데이터 |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
#### 2-3 (가칭) AI 프라이버시 레드팀' 구성·운영
- AI 개발자 및 서비스 제공자는 (가칭)AI 프라이버시 레드팀을 구성·운영하여 기획·개발 시 예상하지 못한 개인정보 침해 유형을 시험·확인하고, AI 모델이 배포된 이후 정보주체에 미칠 수 있는 유해한 영향을 최소화하는 것이 권장됨
- (구성) 레드팀은 내·외부 전문가로 구성될 수 있으나, 독립성·객관성 확보를 위해 외부 전문가를 포함하거나 외부 레드팀 그룹과 협업할 수 있음
##### 사례 2 OpenAI 'Red Teaming Network' 구성 사례
- AI 모델의 안전성을 높이기 위해 과학, 심리, 법률 등 다양한 분야 외부 전문가로 구성
- 구성원마다 평가 모델 및 기술접근 권한이 다르게 부여되며, 간단한 Q/A 테스트부터 복잡한 시뮬레이션 등 다양한 레드팀 활동 수행
- ※ 참여 전문가는 OpenAI와 비밀유지협약(Non-disclosure Agreement, NDA) 체결
- (역할) 악의적 행위자(malicious adversaries)에 의한 내·외부 공격 테스트* 외, 일반적인 AI 이용 과정에서 발생할 수 있는 개인정보 유·노출, 거짓정보 생성 등 프라이버시 침해 위험도 주기적으로 식별하고 조치방안을 마련하는 것이 바람직함
- * 멤버십 추론 공격, 모델 반전 공격, 프롬프트 인젝션 공격 등
- ※ 레드팀 테스트 결과 사회적 파급력이 큰 중대한 취약점 발견 시 관련 정부부서와 공유하는 것이 바람직
##### 사례 2 언어모델의 타 언어모델에 대한 레드팀 테스트 수행[19]
- 학습데이터에 포함되는 민감한 개인정보를 사람이 일일이 개입하여 걸러낼 수도 있지만, 이러한 방식은 비용이 높고 테스트 사례의 수와 다양성이 제한적
- → 언어모델(Red LM)이 목표 LM(Target LM)을 공격하여 유해한 방식으로 동작하는 사례(개인정보 유출 등)를 자동화된 방식으로 식별(Red Classifier)
![언어모델의 타 언어모델에 대한 레드팀 테스트](image_url)
#### 2-4 오픈소스, API 등 AI 개발·배포 특성에 따른 안전조치
- 오픈소스 모델은 누구나 자유롭게 확인, 수정, 배포할 수 있는 소프트웨어로서 최초 배포 후에는 개발자의 통제력이 약화되는 특성을 가지고 있음
- - 이에 오픈소스 모델을 개발하는 사업자는 프라이버시 보호를 고려한 이용방법과 조건의 범위를 명시한 라이선스 정책을 수립·배포하고, 오픈소스 이용자 준수를 확보할 수 있는 방안을 모색하는 것이 바람직함
- 또한, 배포된 오픈소스 모델에 개인정보 관련 취약점이 발견되는 경우에는 그러한 사항과 조치방안을 신속하게 강구하고 재배포하는 노력이 필요함
- - 아울러, 오픈소스 모델이 악의적인 이용사업자에 의해 오·남용되어 개인정보를 침해하는 경우, 그 사실을 즉시 신고할 수 있는 기능·도구를 마련하는 것이 바람직함
- 한편, API 연계를 통한 서비스의 경우에도, API 이용사업자가 미세조정 과정을 통해 개인정보를 침해하거나 데이터 오류·왜곡 등을 초래할 수 있음
- - 이에 AI 개발자는 API 이용사업자가 개인정보 보호를 준수하도록 계약상 의무를 부과하고 상세한 사용지침, 기술문서 등을 제공할 수 있음
- 또한, API 호출 시 인가되지 않은 접근, 해킹 등으로 인한 유출, 위·변조 가능성을 방지하기 위해 암호화된 통신 채널을 마련할 필요
- 오픈소스 및 API 이용사업자는 개발·배포자의 정책을 준수하면서 책임있는 AI 서비스 제공을 위해 노력하여야 함
##### [생성형 AI 배포 방식 비교][20]
| 접근 수준 | 완전 비공개 | 위험·편익을 고려한 점진적 공개 | 웹·앱 인터페이스를 통해 공개 | API를 통해 배포 | 모델 가중치 다운로드 허용 | 완전 공개 |
|-----------|--------------|----------------------------------|--------------------------------|----------------|----------------------------|------------|
| 특징     | 예: 공개하지 않고 해당회사 내부에서만 사용 | 예: 초기 테스트를 포함한 단계적 배포 | 예: 이용자가 모델 출력에 접근하려면 웹사이트를 방문해야 함 | 예: API를 통해 사용자가 쿼리(입력)하고 출력을 받도록 함 | 예: 사용자가 모델에 접근 조정할 수 있음 | 모델 가중치 및 학습데이터 다운로드 가능 |
---
[19] Ethan Perez et al. “Red Teaming Language Models with Language Models” (2022.2.)
[20] Solaiman, “The gradient of generative AI release: Methods and considerations” (2023.2.)\n\n## Page 19\n\n
| 기술적 조치 | 주요 내용 |
|-------------|-----------|
| 학습데이터 수집 출처 검증·관리 | 개인정보 집적 도메인을 제외하여 개인정보 암기 위험을 완화하고 개인정보 출력을 방지 |
| 개인 정보 유·노출 방지 - 식별자 제거, 중복제거 등 | 다양한 데이터셋에 일괄적으로 적용할 수 있어, 일정 수준 이상의 프라이버시 보호 달성 가능 |
| 개인 정보의 안전한 저장 및 관리 | AI와 무관하게 개인정보처리자가 원칙적으로 수행해야 하는 조치에 해당하므로 추가 부담이 적음 |
| 미세조정을 통한 안전장치 추가 | 프라이버시 침해 요인이 정제된 데이터셋을 활용하여 특정 도메인(예: 의료)에 특화한 LLM 개발 가능 |
| 프롬프트 및 출력 필터링 적용 | 모델의 근본적인 변경 없이도 출력물을 제어할 수 있음 |
| 학습 결과에서 특정 데이터 삭제 (언러닝 등) | AI 모델에 대한 재훈련 없이도 개인정보나 유해한 표현 등을 '삭제'할 수 있음 |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용\n\n## Page 20\n\n
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
**내용 없음**\n\n## Page 21\n\n
|-------|-------|-------|
| 데이터 | 데이터 | 데이터 |
- 미완성: ... [다음 페이지에 계속]
- 연속: [이전 페이지에서 계속] ...
###
- 인용: > 사용
---
#### 정보주체 권리 보장 방안
- **개요**
- AI 학습을 위해 웹 스크래핑을 통한 공개된 개인정보 처리가 이루어지고 있는 상황에서 개인정보의 공개와 이용에 관하여 실질적으로 결정하거나 통제할 수 없는 위치에 있는 정보주체의 권리 보장이 더욱 중요해짐
- 개인정보 보호법은 정보주체 이외로부터 수집한 개인정보에 대해 정보주체 요구 시 출처·목적 등을 알릴 의무(제20조)와 열람 요구권(제35조), 정정·삭제 요구권(제36조), 처리정지 요구권(제37조) 등을 규정하여 정보주체 권리를 보장함
- 대법원 또한 공개된 개인정보에 대한 정보주체의 개인정보자기결정권은 법 제20조 및 제37조 등의 사후통제에 의하여 보호받는다고 판시함
- 한편, 현시점에서의 AI의 기술적 특성으로 인해 정보주체 권리보장이 일부 제약될 수 있는 현실적 어려움도 존재함
- 우선, AI 학습데이터셋은 전통적인 관계형 DB와 달리 정형화·구조화되어 있지 않아 특정 정보 항목 추출이 어려울 수 있고
- 전처리 과정에서 토큰화, 토肯 임베딩 방식·수준에 따라 특정 정보주체에 대한 식별 가능성이 낮아질 수 있음
- 또한, AI 결과값에 개인정보가 유·노출되는 등 정보주체 권익침해가 발생하여도 AI 모델에서 특정 데이터의 영향을 완전히 제거하는 기술(언러닝 등)은 아직 연구·개발 중임
- AI 개발자 및 서비스 제공자는 현시점에서의 AI의 기술적 특성, 제약요인 등을 고려하면서 정보주체 권리행사를 실질적으로 지원할 수 있는 정책적·기술적 보완책을 적극적으로 마련· 시행해 나갈 필요
- **AI 학습데이터 투명성 제고**
- 정보주체가 권리를 행사하기 위해서는 AI 학습데이터에 본인의 정보가 포함될 수 있음을 명확히 인지할 수 있어야 함
- **정보주체 권리행사 지원**
- AI 개발자 및 서비스 제공자는 정보주체의 개인정보 열람, 정정·삭제 등 권리행사에 대하여 시간, 비용, 기술을 합리적으로 고려한 범위 내에서 보장하기 위해 노력해야 함
- 개인정보 보호법은 열람, 정정·삭제, 처리정지 요구권에 대하여 원칙적으로 10일 이내 대응하도록 규정하고 있으나, 학습데이터셋 크기, 구성 방식·체계 등을 감안하여 10일 이내 권리행사 보장이 어려운 경우에는 그 사유를 알리고 최대한 성실하게 요구에 응해야 함
- 특히 AI 결과값에 개인정보가 포함되는 경우 AI 개발자 및 서비스 제공자는 정보주체 요구에 따라 신속하게 필터링, 미세조정 등 안전조치를 취하여 개인정보 침해 위험을 최소화하고, 이후 AI 모델 재학습 시 학습데이터에서 배제하는 것이 바람직함
- AI 개발자 및 서비스 제공자가 학습데이터의 파기 또는 토큰화 등 전처리 과정을 통해 개인식별이 기술적으로 불가능함을 입증할 때에는 정보주체의 학습데이터 열람, 정정·삭제 요구 등이 제한될 수 있음
- 이 경우, AI 개발자 및 서비스 제공자는 해당 사실을 정보주체가 이해하기 쉽도록 알려야 하고, 최종적인 입증책임을 부담함
- **사례**
- (ChatGPT) 이용자가 ①OpenAI가 보유하고 있는 개인정보 내역 제공을 요청("Download my Data")하거나 ②노출된 개인정보 삭제를 요구할 수 있는 기능*(“Personal Data Removal Request”) 기능 구현
- ChatGPT 학습에 개인정보가 활용 되었다는 명백한 증거가 있는 경우 (이용자가 관련 프롬프트 및 답변 업로드), 프라이버시권과 알권리 등을 비교항량하여 삭제 조치
- Download my data
- Do not train on my content
- Delete my OpenAI account
- OpenAI Privacy Request Portal (Last updated: January 13, 2024)
---
#### 참고 문헌
- 21) 대법원 2016. 8. 17. 선고 2014다235080 판결
- 22) EDPS, "First EDPS Orientations for ensuring data protection compliance when using Generative AI systems" (2024.6.)도 비슷한 관점 제시\n\n## Page 22\n\n
| First Name* | Last Name* | Personal information output by ChatGPT* | Relevant ChatGPT prompts* | Reason for removal* |
|-------------|------------|-----------------------------------------|---------------------------|---------------------|
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
- 세부: #### �\n\n## Page 23\n\n
|-------|-------|-------|
| 데이터 | 데이터 | 데이터 |
- 미완성: ... [다음 페이지에 계속]
- 연속: [이전 페이지에서 계속] ...
###
- 인용: > 사용
---
### 📌 이전 페이지 컨텍스트
- 마지막 문장 일부: ...
이 페이지가 이전 내용의 연속이라면 [이전 페이지에서 계속] 표시를 추가해주세요.\n\n## Page 24\n\n- 주제목: 책임있는 AI 개발·활용을 위한 AI 기업 등의 역할
- 중제목: AI 프라이버시 관련 내부관리체계 마련
- 소제목: AI 프라이버시 보호 문화 공유 및 확산

### 본문
#### 제목: 책임있는 AI 개발·활용을 위한 AI 기업 등의 역할
##### 소제목: AI 프라이버시 관련 내부관리체계 마련
- (총괄) AI 기업·기관 등은 AI·데이터 처리의 적법성, 안전성 등을 확보할 수 있도록 ‘(가칭)AI 프라이버시 담당조직’을 구심점으로 하여 내부관리체계를 정비·마련하는 것이 바람직함
- (구성) ‘(가칭)AI 프라이버시 담당조직’의 규모·구성 등은 AI 기업·기관의 여건에 따라 자율적으로 결정할 수 있으나, 개인정보보호책임자(CPO)를 중심으로 구성·운영할 것을 권장함
- CPO 중심의 개인정보보호부서가 이미 구성·운영 중인 경우에는, 해당 부서에서 ‘(가칭)AI 프라이버시 담당조직’의 역할을 담당할 수 있음
- (역할) ‘(가칭)AI 프라이버시 담당조직’은 학습데이터 수집·이용의 적법성을 포함하여 AI·데이터 처리 전반의 개인정보 보호법 준수를 확보해야 함
- 공개된 개인정보를 수집·이용하는 AI 개발자 및 서비스 제공자는 제Ⅱ, Ⅲ, Ⅳ장의 안내 사항에 따라 법적근거를 충족하였는지 확인·평가하고 그 근거를 문서화하여 보관하는 것이 바람직함
※ 정보주체 또는 개인정보보호위원회와의 소통시에도 참고자료로 활용할 수 있음
- 또한, AI 성능 개선 등 중대한 기술적 변경이나 개인정보 침해 발생 우려 등 리스크 요인을 주기적으로 모니터링하고
- AI 개발·운영 과정에서 개인정보 유·노출 등 침해사고가 발생할 경우 신속히 권리 구제 방안을 마련·안내하고 정보주체 권리행사를 적극적으로 지원해야 함
##### 소제목: AI 프라이버시 보호 문화 공유 및 확산
- AI 프라이버시 위험에 대한 점검·평가 결과 및 개선조치에 대해서는 개인정보보호책임자(CPO)가 기관 내부의 책임있는 관련 구성원과 공유하여 AI 프라이버시 보호가 기관 내부에 정착할 수 있도록 노력할 필요가 있음
- 또한, AI 프라이버시 보호 문화가 기업·기관 내 확산될 수 있도록 교육·홍보 강화 노력도 병행 하는 것이 바람직함
### 목록
1. 자주 묻는 질문(FAQ)
2. AI 단계별 주요 프라이버시 이슈
3. 공개된 개인정보 관련 국내외 논의 동향
- 44\n\n## Page 25\n\n
### 텍스트
1. **Q1** 해외에서 한국인의 공개된 개인정보를 수집하는 경우 국외이전에 해당하나요?
- 해외에서 한국인의 공개된 개인정보를 수집하는 경우에는 개인정보처리자에 의한 '이전' 행위가 있다고 볼 수 없으므로 국외 이전에 해당하지 않으며, 개인정보 보호법 제15조(개인정보의 수집·이용) 등이 적용됩니다.
2. **Q2** AI의 성능을 향상시키기 위해서는 대량의 학습데이터가 필요한데, AI 개발에 필수적인 데이터와 필수적이지 않은 데이터를 판단하는 기준이 있나요?
- 일반적으로 AI 개발을 위하여 대량의 학습데이터 처리 필요성이 인정될 수 있으나, 상당성·합리성 요건이 인정되기 어려운 경우에 해당하지 않는지 점검해볼 필요가 있습니다.
3. **Q3** 학습데이터 수집 출처는 어느 정도 수준으로 공개되어야 하나요?
- 웹 스크래핑을 통해 데이터를 수집하는 경우에도 구체적인 출처(예: 도메인 주소)를 공개하는 것이 바람직합니다. 그러나 현실적으로 구체적인 출처를 일일이 공개하는 것이 어려운 경우에는 스크래핑의 방식으로 수집한 공개된 개인정보를 학습에 활용하고 있다는 점과 주요 출처 유형, 수집 기준(예: 로봇배제표준 준수 등)을 공개하는 것을 권장합니다.
4. **Q4** 타인이 배포한 데이터 집합을 이용하는 경우 해당 데이터가 적법하게 수집 및 배포되고 있는 사실을 어떻게 확인할 수 있나요?
- 데이터 배포 플랫폼(예: 커먼 크롬)으로부터 데이터 집합을 취득하는 경우에는 해당 플랫폼이 신뢰할 수 있는 대상인지 우선 확인하고, 해당 플랫폼의 데이터 수집·배포 기준을 확인하는 것이 바람직합니다. 또한 제3자로부터 직접 데이터 집합을 제공받는 경우에는 배포자로부터 수집의 적법성에 대한 확약을 받는 방안도 고려할 수 있습니다.
5. **Q5** 역사적 인물 등 사망한 자의 정보도 본 안내서의 적용 대상인가요?
- 역사적 인물 등 사망한 자의 정보는 그 유족·후손 등 살아 있는 개인에 관한 정보를 포함하고 있지 않은 이상 개인정보에 해당하지 않으므로 본 안내서의 적용 대상이 아닙니다.
6. **Q6** AI 기업 등이 서비스 제공을 위해 이미 수집한 이용자 데이터(회원가입 정보)나 이용자가 AI 모델에 입력한 질문(프롬프트)과 답변을 AI 학습 목적으로 이용하는 경우, 어떤 법적 근거에 따를 수 있나요?
- 이용자 데이터의 경우 이용자와 AI 기업 간의 1:1 관계를 전제로 투명한 고지와 동의에 기한 데이터 처리가 가능하고, 개인정보 보호법제가 옵트인(사전 동의) 기반으로 되어 있는 점 등을 고려시 정당한 이익 요건의 인정 범위가 사실상 제한될 수 있고, 자발적 동의나 계약 체결·이행 등 다른 적법 근거가 더 유효할 수 있습니다.
7. **Q7** AI 개발 및 서비스를 목적으로 개인정보를 가명처리하여 정보주체의 동의 없이 처리할 수 있나요?
- 개인정보 보호법 제3조 제7항(익명·가명처리의 원칙), 제28조의2(가명정보의 처리 등)에 따라 AI 개발 및 서비스가 과학적 연구 등에 해당한다면 정보주체의 동의 없이 가명정보를 처리할 수 있습니다.
8. **Q8** 민감성이 높은 공개된 개인정보도 AI 학습·서비스 목적으로 처리할 수 있나요?
- 대규모 웹 스크래핑 과정에서 민감성이 높은 정보 항목이 수집될 수 있는데, 이 경우 정보주체 권리 제한·침해 가능성이 일반 개인정보보에 비해 더 높아질 수 있으므로 이에 비례하여 안전성 확보 조치와 정보주체 권리 보장 수준이 강화될 필요가 있습니다. 특히, 대량의 데이터를 수집하는 경우 민감성이 높은 정보가 포함되지 않도록 각별한 주의를 기울여야 합니다.
9. **Q9** 아동의 공개된 개인정보는 AI 학습·서비스 목적으로 처리할 수 있나요?
- 민감성이 높은 공개된 개인정보와 마찬가지로 아동의 개인정보 또한 법에서 강화된 보호를 받는 항목에 해당하므로 일반 개인정보에 비해 강화된 수준의 안전성 확보 조치와 정보주체 권리보장이 필요합니다.\n\n## Page 26\n\n- 주제목: AI 개발·서비스를 위한 개인정보 처리 안내서
- 중제목: 부록
- 소제목: AI 단계별 주요 프라이버시 이슈

| 구 분 | 주요 프라이버시 이슈 |
|-------|----------------------|
| 데이터 수집 단계 | 개인 정보 보호 원칙과의 충돌 가능성 |
| AI 학습 단계 | AI 학습과정에서 민감한 정보의 추론 가능성 발생 |
| AI 서비스 단계 | 암기된 개인정보의 노출·출력(학습데이터 추출) |
- 미완성: ... [다음 페이지에 계속]
###
- 인용: > 사용
---
### 텍스트 내용
#### Q10
전문 CPO가 없는 영세기업 등은 어떻게 내부관리체계를 구체화할 수 있나요?
- 연 매출액 또는 수입이 1,500억원 미만이거나 100만명 미만의 개인정보를 처리하는 등 개인정보 보호법 시행령 제32조 제4항에 규정된 기준을 충족하지 못하는 영세기업 등은 전문CPO 지정 의무가 없고, 개인정보 처리 관련 의사결정 권한이 있거나 책임을 질 수 있는 자가 CPO 역할을 수행할 수 있습니다.
<참고> 개인정보 보호법 개정(2024.3.15. 시행)으로 전문CPO 지정제도가 시행되면서 매출액, 개인정보 보유 규모 등을 고려하여 일정 기준* 이상의 개인정보처리자는 개인정보보호·정보보호·정보기술 경력을 총 4년 이상(개인정보보호 경력 2년 필수) 갖춘 CPO를 반드시 지정할 의무 부담(단, 법 시행 당시 CPO로 지정되어 있는 자에 대해서는 2년 이내에 자격요건을 갖추도록 법 적용 유예)
* ① 연 매출액 또는 수입이 1,500억원 이상인 자로서, 100만명 이상 개인정보 또는 5만명 이상 민감·고유식별정보를 처리하는 개인정보처리자 ② 재학생 수 2만 명 이상인 대학(대학원 재학생 수 포함) ③ 대규모 민감정보(건강정보)를 처리하는 상급종합병원 ④ 공공시스템운영기관
#### Q11
AI 기업이 정당한 이익 조항에 근거한 공개된 개인정보 처리의 적법성을 인정받기 위해 시행하고 있는 안전성 확보 조치 및 정보주체 권리보장 수준이 충분한지 어떻게 확인할 수 있나요?
- AI 생애주기에 걸쳐 중층적인 안전성 확보조치를 취할 경우 정당한 이익의 이익형량에 도움이 될 수 있습니다. 다만, 개별 조치마다 AI 성능에 미치는 영향이 다르므로 '안전성 확보조치 효과 비교(p.34)' 및 '안전조치 조합 사례(p.35)'를 참고하여 '최적 조합'을 도입·시행할 것을 권장합니다. AI 기업이 안내서를 적용하는 과정에서 불확실성이 발생하는 경우에는 '사전적정성 검토'와 같은 컨설팅 제도를 적극적으로 활용할 수 있습니다.
#### Q12
안내서에 제시된 개별 조치사항을 이행하지 않으면 어떻게 되나요?
- 본 안내서에서 제시하는 개별 조치를 이행하지 않았다고 하여 공개된 개인정보 처리가 위법한 것으로 보는 것은 아닙니다. AI 기업 등의 AI 개발·서비스 목적과 맥락, 공개된 개인정보 처리와 관련한 정보주체 권익침해 수준 등을 종합적으로 고려하여 공개된 개인정보 처리의 적법성을 판단하게 됩니다.
#### 부록2
AI 단계별 주요 프라이버시 이슈
| 구 분 | 주요 프라이버시 이슈 |
|-------|----------------------|
| 데이터 수집 단계 | 개인 정보 보호 원칙과의 충돌 가능성 |
| AI 학습 단계 | AI 학습과정에서 민감한 정보의 추론 가능성 발생 |
| AI 서비스 단계 | 암기된 개인정보의 노출·출력(학습데이터 추출) |
---
### 각주
26) 최대선 외, "Estimating Korean residence registration numbers from public information on SNS", IEICE Transactions on Communications, (2015)
27) Milad Nasr et al. "Extracting Training Data from ChatGPT" (2023)\n\n## Page 27\n\n```markdown
# 부록3 공개된 개인정보 관련 국내외 논의 동향
## 1 국내 논의
### 가. 관련 법령
#### ❖ 개인정보 보호법
- 공개된 개인정보의 처리에 대한 별도 규정이 없고, 개인정보 처리에 관한 일반원칙 및 수집·이용·제공 등에 관한 일반 규정이 적용됨
[ 개인정보 보호법상의 주요 규정 ]
| 보호 원칙 (제3조) | ①목적 적합성 ②적법처리 ③정확성·완전성·최신성 ④안전관리 ⑤투명성 및 정보주체 권리 보장 ⑥사생활 침해 최소화 ⑦익명화·가명화 ⑧신뢰성 |
|-------------------|-------------------------------------------------------------|
| 적법처리 (제15조~제18조) | ①정보주체 동의 ②법률상 특별한 규정 ③공공기관 업무 수행 ④계약 체결 이행 ⑤정보주체 또는 제3자의 급박한 생명, 신체, 재산상 이익 필요 ⑥개인정보처리자의 정당한 이익 ⑦공중위생 등 공공의 안전·안녕상 필요 |
| 정보주체 권리 (제20조, 제35조~제37조 등) | ①정보주체 이외로부터 수집한 개인정보 수집 출처 통지 등 ②개인정보 열람, 정정·삭제, 처리정지 등 |
| 기타 의무조항 (제21조, 제28조의2, 제29조, 제30조, 제33조 등) | ①개인정보의 파기 ②가명정보 처리 ③안전조치 의무 ④개인정보 처리방침의 수립·공개 ⑤개인정보 영향평가 등 |
#### ❖ 표준 개인정보 보호지침
- 정보주체로부터 직접 명함 등을 제공받거나 인터넷 홈페이지 등 공개된 매체에서 개인정보를 수집하는 경우, ‘사회통념상 동의 의사’가 있었다고 인정되는 범위 내에서 이용 가능
**제6조 (개인정보의 수집·이용)** ③ 개인정보처리자는 정보주체로부터 직접 명함 또는 그와 유사한 매체(이하 “명함등”이라 함)를 제공받음으로써 개인정보를 수집하는 경우 명함등을 제공하는 정황 등에 비추어 사회통념상 동의 의사가 있었다고 인정되는 범위 내에서만 이용할 수 있다. ④ 개인정보처리자는 인터넷 홈페이지 등 공개된 매체 또는 장소(이하 “인터넷 홈페이지등”이라 함)에서 개인정보를 수집하는 경우 정보주체의 동의 의사가 명확히 표시되거나 인터넷 홈페이지등의 표시 내용에 비추어 사회 통념상 동의 의사가 있었다고 인정되는 범위 내에서만 이용할 수 있다.
---
### ❖ 신용정보의 이용 및 보호에 관한 법률
- 신용정보주체가 스스로 사회관계망서비스 등에 직접 또는 제3자를 통해 공개한 정보로서 동의가 있었다고 객관적으로 인정되는 범위 내에 해당하는 개인신용정보의 경우 정보주체 동의를 면제
- ※ 후술하는 대법원 판례(‘로앤비’) 취지를 반영하여 2020년 개정
**신용정보의 이용 및 보호에 관한 법률**
제15조(수집 및 처리의 원칙) ② 신용정보회사등이 개인신용정보를 수집하는 때에는 해당 신용정보주체의 동의를 받아야 한다. 다만, 다음 각 호의 어느 하나에 해당하는 경우에는 그러하지 아니하다.
- 다. 신용정보주체가 스스로 사회관계망서비스 등에 직접 또는 제3자를 통하여 공개한 정보. 이 경우 대통령령으로 정하는 바에 따라 해당 신용정보주체의 동의가 있었다고 객관적으로 인정되는 범위 내로 한정한다.
**신용정보의 이용 및 보호에 관한 법률 시행령**
제13조(수집 및 처리의 원칙) 다음 각 호의 사항을 고려하여 신용정보주체의 동의가 있었다고 객관적으로 인정되는 범위의 정보는 법 제15조제2항제2호다목 후단에 따른 동의가 있는 정보로 본다.
- 1. 공개된 개인정보의 성격, 공개의 형태, 대상 범위
- 2. 제1호로부터 추단되는 신용정보주체의 공개 의도 및 목적
- 3. 신용정보회사등의 개인정보 처리의 형태
- 4. 수집 목적이 신용정보주체의 원래의 공개 목적과 상당한 관련성이 있는지 여부
- 5. 정보 제공으로 인하여 공개의 대상 범위가 원래의 것과 달라졌는지 여부
- 6. 개인정보의 성질 및 가치와 이를 활용해야 할 사회·경제적 필요성
---
### 나. 주요 판례
**대법원 2014다235080 (“로앤비 판결”)**
< 공개된 개인정보의 영리 목적의 수집·제공 허용 >
- **사건의 개요**: 로앤비가 국립대 교수의 사진, 출생연도, 학·경력 등 개인정보를 수집해 유료로 제3자에 제공한 사안
- **판결 요지**: 이미 공개된 개인정보를 정보주체의 동의가 있었다고 객관적으로 인정되는 범위 내에서 수집·이용·제공 등 처리를 할 때는 정보주체의 별도의 동의는 불필요하다고 보아야 할 것이고, 그러한 별도의 동의를 받지 않았다고 하여 개인정보 보호법 제15조나 제17조를 위반한 것으로 볼 수 없음
```\n\n## Page 28\n\n```markdown
# 2 해외 논의
## 가. 관련 법령
### 공개된 개인정보에 대한 특례규정 없이 일반 개인정보와 동등하게 취급한 입법례
- (EU) EU GDPR은 공개된 개인정보를 일반 개인정보와 동등하게 규율하여 동의, 계약, 정당한 이익 등 적법근거(Art. 6)에 따라 처리될 수 있도록 규정
- 단, 민감정보 처리규정(Art. 9(2)(e))은 '정보주체가 명백하게 공개한 개인정보'의 경우 처리할 수 있는 예외를 인정함
### EU 국가별 정책 동향
- (영국) 웹스크래핑을 통해 수집한 데이터를 생성형 AI 학습에 사용하는 것에 '정당한 이익'이 인정될 수 있음을 밝히고 의견수렴(2024.1.~3.)
- (프랑스) AI 학습 목적으로 개인정보 처리시 '정당한 이익'이 인정되기 위한 기준 제시(2023.10.)
- (스페인) 제29조 작업반(WP29) 의견서를 인용하면서 적절한 관리조치(safeguards) 하에 AI 학습 목적의 개인정보 처리가 정당한 이익에 의존할 수 있다고 밝힘(2020.)
### 공개된 개인정보에 대한 특례를 규정한 입법례
- (캐나다) 개인정보 보호 및 전자문서법(PIPEDA)은 공개된 정보(publicly available information)도 개인정보에 해당되나,
- 국가등록부, 법원 기록, 잡지·서적·신문 등 온·오프라인 간행물에 게재된 것은 수집·이용·공개에 동의가 필요하지 않다고 규정
- (싱가포르) 개인정보 보호법(PDPA)은 공개된 정보의 경우, 정보주체의 동의 없이 수집·이용·공개 가능하도록 규정
- (중국) 합리적인 범위 내에서 개인이 공개한 개인정보 또는 기타 이미 합법적으로 공개된 개인정보를 처리하는 경우 동의 없이 처리 가능
```\n\n## Page 29\n\n```markdown
# 공개된 개인정보를 법 적용대상에서 제외한 입법례
- **미국**: 미국 최초 개인정보 보호 일반법인 캘리포니아 소비자프라이버시법(CCPA)은 개인정보로부터 공개된 정보(생체인식정보 제외)를 제외하였고,
- 이를 개정한 프라이버시권리법(CPRA, 2023.1.1. 시행)에서는 '공적 관심사로서 합법적으로 획득한 진실된 정보'까지 제외
- 연방 차원에서도 공개된 정보를 개인정보 범위에서 제외하는 내용의 개인정보보호법(American Privacy Rights Act, APRA) 제정 추진
## 관련 지침·가이드라인 등
### 영국 ICO, 'Generative AI first call for evidence: The lawful basis for web scraping to train generative AI models'(2024.1.)
- AI 개발자들이 UK GDPR 등 법률상 의무를 이행하고 입증할 수 있다면 공개된 정보를 스크래핑하여 생성형 AI를 학습시킬 수 있음
- 현재의 기술 및 서비스 관행을 고려할 때, UK GDPR의 '정당한 이익' 요건 충족 여부가 핵심임
#### ICO의 '정당한 이익' 판단 요건
- **(목적의 적법성)** 학습용 데이터를 수집할 당시에 접근할 수 있는 정보에 기반하여 최대한 구체적인 이익을 설정할 필요
- 처리자의 이익은 영업의 이익(business interest)은 물론 광범위한 사회적 이익(wider societal interests)을 포괄할 수 있으나, 이러한 이익에 의존하기 위해서는 개발자가 AI의 구체적인 목적과 용도를 입증할 수 있어야 함
- **(필요성)** 대부분의 생성형 AI 학습은 대규모 웹 스크래핑을 통한 학습 데이터 수집이 불가피
- 향후 기술발전을 통해 더 적은 규모의 권리관계가 명확한 데이터로도 생성형 AI를 개발할 수 있는 새로운 방안이나 대안 마련의 가능성 존재
- **(균형성)** 개인의 이익, 권리 및 자유와 생성형 AI 개발자의 이익을 비교형량
- 스크래핑을 통한 데이터 수집은 “보이지 않는 처리(invisible processing)”로서, 정보주체가 자신의 정보가 어떠한 방식으로 처리되는지 인지하지 못할 우려
- ICO 가이드라인은 “보이지 않는 처리”와 “AI 관련 개인정보 처리”를 고위험 행위로 구분하고 개인정보영향평가(DPIA)를 거치도록 요구함
### 프랑스 CNIL, 'AI How-to sheets'(2023.10.)
- 공개된 정보를 처리하는 경우 EU GDPR 상의 유효한 동의 요건을 충족하기 어려우므로 '정당한 이익'과 같은 법적 근거 충족 필요
- 정당한 이익 요건 판단 시 영국 ICO와 유사한 판단기준 적용
#### CNIL의 '정당한 이익' 판단 요건
- **정당한 이익을 법적 근거로 활용하기 위해서는 ①개인정보처리자가 추구하는 이익이 정당할 것(the legitimacy of the interest pursued by the controller) ②그러한 이익을 달성하기 위해서 개인정보 처리가 필요할 것(the need for data processing to meet this legitimate interest) ③정보주체의 이익과 권리에 대해 불균형적인 간섭이 없을 것(the absence of disproportionate interference with the interests and rights of data subjects)의 요건이 모두 충족되어야 함
- ① 정당성: AI 시스템 상용화를 위한 모델 개발 또는 과학 지식의 개선
- ② 필요성: 익명·합성데이터로는 목적 달성이 어려움을 입증
- ③ 이익형량: 개인정보처리자가 합리적으로 기대할 수 있는 처리인지 여부와 정보주체에 대한 악영향을 방지하기 위한 보호조치(safeguards)를 종합적으로 고려
- 대개 적법한 AI 학습 데이터셋 구축은 그 자체로 “정당한” 것으로 인정될 수 있으나, 데이터셋에 개인식별정보(PII)가 없는 경우라도 프라이버시 침해여부를 사안별로 고려 필요
- 데이터 처리의 비례성(proportionality)을 확보할 수 있도록 개인정보처리자는 익명·가명처리를 하거나, 민감정보를 제거하거나, 처리에 필요하고 관련성 있는 데이터 수집 기준을 마련하는 등의 방법을 사용할 수 있음
## 관련 판례
### EU – Benalla 사건
- 벨기에 NGO인 EU DesinfoLab은 ‘가짜 뉴스’ 연구를 위하여 ‘Affaire Benalla’라는 연구에서 해당 주제에 대한 트위터 메시지를 분석함. 그 분석 과정에서 트윗 작성자의 정치적 프로필을 분석하고, 일부가 “Russia Today” 및 “Sputnik”과 같은 러시아 미디어와 연결될 수 있음을 확인함
- 벨기에 데이터 보호 당국(DPA)는 EU GDPR의 Article 6.1.(f)의 정당한 이익이 인정되려면 (i) 그 목적을 위하여 엄격히 필요한 것으로 제한되어야 하며, (ii) 데이터 주체의 권리·자유와 균형을 이루어야 하는바, 익명화 등 충분한 안전장치를 구현하지 않아 위 조건에 충족하지 않는다고 판단하였음
```\n\n## Page 30\n\n```markdown
# EU – ChatGPT 사건
- 이탈리아 데이터 보호 기관(DPA)는 2023.3.31. OpenAI가 개발·관리하는 ChatGPT에 의한 이탈리아 사용자들의 데이터 처리에 대하여 일시적인 제한명령을 부과함
- DPA는 (i) 정보주체에게 정보제공이 부족하였고, (ii) 알고리즘 훈련을 위해 개인정보를 대량으로 수집하고 처리하는 것을 뒷받침하는 법적 근거가 없어 보이며, (iii) 연령 제한 조치가 필요하다는 등의 이유로 위와 같이 명령을 내림
- DPA는 2023.4. OpenAI가 알고리즘 훈련을 위한 개인정보 처리의 법적 근거로 EU GDPR상 '계약 이행'에 대한 언급을 모두 삭제하도록 하고, 동의나 정당한 이익에 의존할 것을 요구함
# EU – Clearview AI 사건
- Clearview AI는 인물 사진을 DB화 하여 상업적으로 판매하기 위해 인터넷 및 사회관계망서비스에 공개되어 있는 300억 개 이상의 얼굴 이미지와 데이터를 수집함. 각 정보주체는 자신의 얼굴 이미지가 이러한 방식으로 수집·활용된다는 사실을 전혀 인지하지 못함
- 영국 ICO는 (i) Clearview AI가 수집·처리하는 정보주체의 얼굴 이미지가 단순한 개인정보를 넘어 생체 인식정보로서 UK GDPR 제9조 제1항의 특정 범주 개인정보에 해당하며, (ii) 특정 범주 개인정보를 처리함에도 불구하고 처리가 허용되는 예외 요건 중 어느 하나도 갖추지 못했다고 판단함. ICO는 Clearview AI에 대해 755만 2,800 파운드의 과징금을 부과하고, 영국 거주자의 개인정보를 삭제하며, 온라인상에서 영국 거주자에 대한 개인정보 수집 및 스크래핑 중지, 영국 거주자의 개인정보 DB 추가 금지 등의 조치를 취할 것을 명령함
- ※ 영국 제1심 법원은 2023.10. ICO의 관할권이 없다는 이유로 ICO 과징금 처분 등을 취소하였고, ICO가 항소 제기
```\n\n## Page 31\n\n```markdown
# 인공지능(AI) 개발 · 서비스를 위한 공개된 개인정보 처리 안내서
## 발행 일
2024년 7월
## 발행처
개인정보보호위원회
## 지원기관
한국인터넷진흥원
## 디자인
호정씨앤피(☎02-2277-4718)
## 여성기업
※ 최신자료는 “개인정보보호위원회 누리집(pipc.go.kr)”, “개인정보 포털 (privacy.go.kr)”에서 확인할 수 있습니다.
```