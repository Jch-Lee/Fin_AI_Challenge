AI 학습데이터 모델 보안 관리 적대적공격 탐지 적대적공격 탐지 기법 적용 AI 모델 적대적공격 취약 공격 발생 경우 차단 학습 조치 필요 적대적공격 탐지 방안 고려 적대적공격 탐지 위하 기법 노이즈 탐지 입력 데이터 인코딩 중요도 활용 AI 모델 보안 고려 사항 AI 개발주기 점검 항목 데이터수집 AI 학습데이터 대하 정보 관리 데이터전처리 학습데이터 이상 Outlier 식별 관리 학습데이터 변조 여부 확인 예상 적대적예제 생성 학습 설계 학습 AI 모델 설계 알고리즘 선택 고려 모델 튜닝 확보 조치 사전 학습 활용 사전 학습 모델 신뢰 출처 연합학습 활용 비잔티움 에러 대처 방법 적용 검증 테스트 검증 테스트 이용 데이터 AI 모델 매개변수 정보 관리 AI 모델 대상 적대적공격 수행 성능 수준 확인 최종 출력 확인 모델 출력 횟수 제한 모델 정보 노출 최소 적대적공격 탐지 기법 적용 Kwon Hyun Hyunsoo Yoon and Ki Woong Park. Acoustic decoy Detection of adversarial examples through audio modification on speech recognition system Weiling Xu Feature Squeezing Detecting Adversarial Examples in Deep Neural Networks G.Ko and G.Lim Unsupervised Detection of Adversarial Examples with Model Explanations