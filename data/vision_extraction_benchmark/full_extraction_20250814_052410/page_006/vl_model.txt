금융분야 AI 보안 가이드라인

제1장
가이드라인 개요

본 가이드라인은 금융권에서 사용하는 인공지능(AI) 서비스의 안전한 활용에 필요한 사항을 안내하여, 금융회사의 AI 활용에 있어 안전성을 높이고자 한다.

1 추진 배경 및 목적

- 최근 디지털 금융산업의 발전과 함께, 인공지능(AI)을 활용한 서비스의 도입이 확대됨에 따라 개인정보 유출 등 다양한 보안 위험이 발생하고 있다.

참고 인공지능 관련 사고 사례

| 구 분       | 특 징                             |
|-------------|----------------------------------|
| AI 챗봇 '이루다' ('21.1.) | 실명, 계좌번호, 주소 등 개인정보 유출 발생<br>특정 소수자 차별 등으로 출시 1달여 만에 서비스 일시 중단 |
| AI 헬스케어 'GPT-3' ('20.10.) | 정신과 챗봇으로 출시전 모의 환자에게 자살 권유 |
| AI 성별식별 '젠더리파이' ('20.7.) | 여성, 유색인종, 노인 등 소수자 차별 |
| MIT의 '사이코패스AI' ('18.6.) | 연구를 통해 부정·편향된 인공지능 학습 결과, 반사회·반인륜적인 행위 증명 |

2