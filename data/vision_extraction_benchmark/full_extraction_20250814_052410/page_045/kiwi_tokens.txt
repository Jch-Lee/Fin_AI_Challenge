### 모델추출 공격 #### 모델추출 공격 은 원본 AI 모델 로부터 유사 하 ᆫ 모델 을 추출 하 어 복제 하 는 공격 이 다 . - 원본 AI 모델 에 대하 ᆫ 대량 의 쿼리 를 통하 어 입력 · 출력 값 을 수집 하 고 이 를 학습 하 어 원본 AI 모델 과 유사 도 가 높 은 모델 을 복제 하 ᆫ다 . #### 모델추출 공격 프로세스 ! [ 모델추출 공격 다이어그램 ] ( https://i.imgur.com/example.png) - ** 데이터 소유자 ** : 모델학습 을 위하 어 데이터 를 제공 하 ᆸ니다 . - ** 인공지능 서비스 ** : 데이터 를 학습데이터 로 사용 하 어 모델 을 학습 하 ᆸ니다 . - ** 모델추출 ** : 학습 되 ᆫ 모델 을 다른 장치 에서 사용 하 어 유사 하 ᆫ 모델 을 생성 하 ᆸ니다 . #### 아마존 ( Amazon ) 및 BigML 이 MLaaS 형태 로 제공 하 는 유료 AI 모델 을 몇 분 만 에 99 % 이상 유사 도로 복제 가능 하 다는 것 이 관련 연구 로 증명 되 ᆫ 바 있 다 . #### 다음 과 같 은 방법 을 통하 어서 모델추출 공격 을 예방 하 ᆯ 수 있 다 . - ** ( 출력 값 제한 ) ** : 출력 횟수 와 시간 을 제한 하 어 공격 자 의 입력 · 출력 정보 수집 을 어렵 게 하 ᆫ다 . - ** ( 예측 결과 변환 ) ** : 비 식별 처리 등 을 통하 어 출력 값 을 변환 하 면 , 입력 · 출력 값 으로부터 유사 모델 을 생성 하 기 어렵 어 지 어 모델추출 공격 을 예방 하 ᆯ 수 있 다 . - ** ( DP - SGD 기법 ) ** : 학습 과정 에서 차 등 프라이버시 기법 을 적용 하 ᆷ 으로써 , 경사도 등 모델 과 관련 되 ᆫ 정보 노출 을 최소 화 하 는 기법 이 다 .