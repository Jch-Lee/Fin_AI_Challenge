### 모델 추출 공격

#### 모델 추출 공격은 원본 AI 모델로부터 유사한 모델을 추출하여 복제하는 공격이다.
- 원본 AI 모델에 대한 대량의 쿼리를 통해 입력·출력값을 수집하고 이를 학습하여 원본 AI 모델과 유사도가 높은 모델을 복제한다.

#### 모델 추출 공격 프로세스

![모델 추출 공격 다이어그램](https://i.imgur.com/example.png)
- **데이터 소유자**: 모델 학습을 위해 데이터를 제공합니다.
- **인공지능 서비스**: 데이터를 학습 데이터로 사용하여 모델을 학습합니다.
- **모델 추출**: 학습된 모델을 다른 장치에서 사용하여 유사한 모델을 생성합니다.

#### 아마존(Amazon) 및 BigML이 MLaaS 형태로 제공하는 유료 AI 모델을 몇 분만에 99% 이상 유사도로 복제 가능하다는 것이 관련 연구로 증명된 바 있다.

#### 다음과 같은 방법을 통해서 모델 추출 공격을 예방할 수 있다.
- **(출력값 제한)**: 출력 횟수와 시간을 제한하여 공격자의 입력·출력 정보 수집을 어렵게 한다.
- **(예측 결과 변환)**: 비식별 처리 등을 통해 출력값을 변환하면, 입력·출력값으로부터 유사 모델을 생성하기 어려워져 모델 추출 공격을 예방할 수 있다.
- **(DP-SGD 기법)**: 학습 과정에서 차등 프라이버시 기법을 적용함으로써, 경사도 등 모델과 관련된 정보 노출을 최소화하는 기법이다.