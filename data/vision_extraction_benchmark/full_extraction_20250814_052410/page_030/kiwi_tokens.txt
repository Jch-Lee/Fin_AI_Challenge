## 금융분야 AI 보안 가이드라인 ### ② ( 데이터 변조 확인 ) 학습데이터 의 전반 적 이 ᆫ 추이 또는 샘플링 한 값 을 분석 하 어 데이터 변조 여부 를 확인 하 ᆫ다 . - 레이블 변조 및 의미 적 이 ᆫ 개념 의 변조 는 이상 하 지 검출 기법 으로 데이터 를 발견 하 기 가 어렵 기 때문 에 보다 세밀 하 ᆫ 분석 이 필요 하 다 . - 데이터 가 변조 되 면 데이터중독 공격 등 을 통하 어 AI 모델 자체 가 손상 되 ᆯ 수 있 으므로 학습데이터 를 변조 로부터 안전 하 게 보호 하 어야 하 ᆫ다 . ### ③ ( 적대적예제 생성 ) 적대적예제 * 를 생성 하 어 AI 모델 의 학습데이터 에 포함 · 학습 하 어 , AI 모델 을 적대적공격 ** 으 로부터 보호 하 ᆫ다 . * AI 모델 이 잘못 되 ᆫ 예측 을 하 도록 의도 적 으로 변조 하 ᆫ 데이터 ** 적대적예제 를 활용 하 어 AI 모델 이 잘못 판단 하 도록 조작 하 는 공격 - AI 모델 은 회피공격 * 등 의 적대적공격 에 취약 하 기 때문 에 이 를 탐지 하 는 방안 을 고려 하 어야 하 ᆫ다 . * [ 참고 5 ] 회피공격 참조 - 공격자 는 AI 모델 을 파악 하 기 위하 어 AI 모델 의 입 · 출력 * 을 수집 하 는데 이러 하 ᆫ 공격 자 의 행동 방식 을 탐지 에 참고 하 ᆯ 수 있 다 . ### 참고 * 공격자 의 입 · 출력 수집 방식 - 공격자 는 입 · 출력 값 수집 을 위하 어 데이터 내 에 노이즈 를 삽입 하 거나 변조 하 ᆫ 레이블 을 넣 어 다양 하 ᆫ 데이터 를 수집 하 ᆫ다 . - 공격자 는 입력 값 을 다양 하 게 변조 하 어 수집 하 ᆫ 출력 값 으로부터 AI 모델 에 대하 ᆫ 정보 를 유추 * 하 고 이 를 통하 어 다양 하 ᆫ 적대적예제 를 생성 하 ᆫ다 . * AI 모델 의 종류 유추 , 결정 경계 ( Decision Boundary ) 등