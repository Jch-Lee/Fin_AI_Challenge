●●●금융분야 AI 보안 가이드라인
26
□
2  (데이터 변조 확인) 학습 데이터의 전반적인 추이 또는 샘플링한 값을 분석하여 데이터 
변조 여부를 확인한다.
레이블 변조 및 의미적인 개념의 변조는 이상치 검출 기법으로 데이터를 발견하기가 
어렵기 때문에 보다 세밀한 분석이 필요하다.
데이터가 변조되면 데이터 중독 공격 등을 통해 AI 모델 자체가 손상될 수 있으므로 
학습 데이터를 변조로부터 안전하게 보호해야 한다.
□
3  (적대적 예제 생성) 적대적 예제*를 생성하여 AI 모델의 학습 데이터에 포함･학습하여, 
AI 모델을 적대적 공격**으로부터 보호한다.
 * AI 모델이 잘못된 예측을 하도록 의도적으로 변조한 데이터
** 적대적 예제를 활용하여 AI 모델이 잘못 판단하도록 조작하는 공격
AI 모델은 회피 공격* 등의 적대적 공격에 취약하기 때문에 이를 탐지하는 방안을 
고려해야 한다.
* [참고5] 회피 공격 참조
공격자는 AI 모델을 파악하기 위해 AI 모델의 입･출력*을 수집하는데 이러한 공격자의 
행동 방식을 탐지에 참고할 수 있다.
참고
* 공격자의 입･출력 수집 방식
✓ 공격자는 입･출력값 수집을 위해 데이터 내에 노이즈를 삽입하거나 변조한 레이블을 
넣어 다양한 데이터를 수집한다.
✓ 공격자는 입력값을 다양하게 변조하여 수집한 출력값으로부터 AI 모델에 대한 정보를 
유추*하고 이를 통해 다양한 적대적 예제를 생성한다.
* AI 모델의 종류 유추, 결정경계(Decision Boundary) 등
