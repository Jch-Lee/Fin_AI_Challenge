모델 오염 공격 정의 모델 오염 공격 연합학습 클라이언트 학습 생성 악의 모델 중앙 서버 AI 모델 적용 성능 저하 오작동 유발 공격 서버 클라이언트 전달 모델 신뢰 오염 여부 확인 어렵 때문 모델 오염 공격 탐지 어렵 방어 방법 FoolsGold 기법 집계 알고리즘 적용 통하 모델 오염 공격 예방 집계 알고리즘 적용 알리 알고리즘 Krum Bulyan Trimmed Mean 사용 비잔티움 에러 완화 FoolsGold 기법 적용 연합학습 FoolsGold 기법 통하 악성 클라이언트 판별 배제 정상 클라이언트 악성 클라이언트 경사도 비교 업데이트 양상 확인 악성 판별 기법 Feature Squeezing AI 모델 예측 결과 Squeezer 알고리즘 적용 예측 결과 비교 적대적예제 탐지 기존 입력 인코딩 평활 필터 적용 특징 축소 참고 문헌 Peva Balachard Rachid Guerraoui Julien Stainer et al. Machine Learning with Adversaries Byzantine Tolerant Gradient Descent El Mahdi El Mhamdi Rachid Guerraoui and Sebastien Rouault The Hidden Vulnerability of Distributed Learning in Byzantium Dong Yin Yudong Chen Kannan Ramchandran and Peter Bartlett Byzantine Robust Distributed Learning Towards Optimal Statistical Rates Fung Clement Chris JM Yoon and Ivan Beschas tnikh. Mitigating Sybils in Federated Learning Poisoning Weiling Xu Feature Squeezing Detecting Adversarial Examples in Deep Neural Networks