### 모델 오염 공격 #### 정의 모델 오염 공격 은 연합학습 시 클라이언트 에서 학습 · 생성 되 ᆫ 악의 적 이 ᆫ 모델 이 중앙 서버 의 AI 모델 에 적용 되 어 성능 저하 및 오작동 을 유발 하 는 공격 이 다 . - 서버 가 각 클라이언트 에서 전달 되 는 모델 의 신뢰 성 및 오염 여부 를 확인 하 는 것 이 어렵 기 때문 에 모델 오염 공격 은 탐지 하 기 어렵 다 . #### 방어 방법 FoolsGold 기법 , 집계 알고리즘 적용 등 을 통하 어 모델 오염 공격 을 예방 하 ᆯ 수 있 다 . - ( 집계 알고리즘 적용 ) 알리 어 지 ᆫ 집 계 알고리즘 ( Krum ^ 20 ) , Bulyan ^ 21 ) , Trimmed Mean ^ 22 ) ) 을 사용 하 어 비잔티움 에러 를 완화 하 ᆫ다 . - ( FoolsGold 기법 적용 ) 연합학습 시 FoolsGold 기법 을 통하 어서 악성 클라이언트 를 판별 하 고 배제 하 ᆫ다 . ^ 23 ) - 정상 클라이언트 와 악성 클라이언트 간 경사도 를 비교 하 어서 서로 다른 업데이트 양상 을 확인 하 어 악성 을 판별 하 는 기법 - ( Feature Squeezing ) AI 모델 의 예측 결과 와 Squeezer 알고리즘 ^ 24 ) 을 적용 하 ᆫ 예측 결과 를 비교 하 ᆷ 으로써 , 적대적예제 를 탐지 하 ᆫ다 . ^ 24 ) - 기존 입력 값 의 인코딩 단순 화 , 평활 화 필터 등 을 적용 하 어 특징 축소 --- ** 참고 문헌 ** 20) Peva Balachard , Rachid Guerraoui , Julien Stainer , et al. " Machine Learning with Adversaries : Byzantine Tolerant Gradient Descent " , 2017. 21 ) El Mahdi El Mhamdi , Rachid Guerraoui , and Sebastien Rouault , " The Hidden Vulnerability of Distributed Learning in Byzantium " , 2018. 22 ) Dong Yin , Yudong Chen , Kannan Ramchandran , and Peter Bartlett , " Byzantine - Robust Distributed Learning : Towards Optimal Statistical Rates " , 2018. 23 ) Fung , Clement , Chris JM Yoon , and Ivan Beschas tnikh. , " Mitigating Sybils in Federated Learning Poisoning " , 2018. 24 ) Weiling Xu , " Feature Squeezing : Detecting Adversarial Examples in Deep Neural Networks " , 2017.