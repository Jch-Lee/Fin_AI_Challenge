참고 회피공격 참고 회피공격 노이즈 추가 적대 데이터 입력 AI 모델 판단 유도 공격 참고 적대적예제 인하 분류 Panda × 노이즈 Gibbon 회피공격 입력 사람 구분 어렵 노이즈 추가 결과 영향 미치 때문 데이터 관찰 통하 탐지 적대적예제 학습 경사도 마스 방법 통하 회피공격 예방 차단 적대적예제 학습 사전 적대적예제 생성 학습 적대적예제 통하 회피공격 방어 경사도 마스 공격자 데이터 입력 AI 모델 학습 방향 변화 정도 기반 적대적예제 생성 AI 모델 학습 방향 데이터 입력 AI 모델 경사도 통하 확인 공개 마스 범주 기법 활용 모델 정보 노출 최소 출처 Ian J. Goodfellow et. al. Explaining and Harnessing Adversarial Examples Zhang Lemoine and Mitchell Mitigating Unwanted Biases with Adversarial Learning Anish Athalye at al. Obfuscated Gradients Give a False Sense of Security Circumventing Defenses to Adversarial Examples