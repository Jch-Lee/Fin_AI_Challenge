참고 5. 회피 공격●●●
45
참고5
▶회피 공격
회피 공격31)은 노이즈를 추가한 적대적 데이터를 입력하여, AI 모델이 잘못된 판단을 
하도록 유도하는 공격이다.
참고
적대적 예제로 인한 오분류31)
※ 회피 공격은 입력값에 사람의 눈으로는 구분하기 어려운 노이즈의 추가로 결괏값에 영향을 미치기 때문에, 데이터 
관찰을 통한 탐지가 쉽지 않음
적대적 예제 학습, 경사도 마스킹 등의 방법을 통해서 회피 공격을 예방하고 차단할 수 
있다.
(적대적 예제 학습32)) 사전에 적대적 예제를 생성하여 학습함으로써, 적대적 예제를 
통한 회피 공격을 방어할 수 있다.
(경사도(Gradient) 마스킹33)) 공격자는 데이터를 입력하였을 시에 AI 모델의 학습 
방향 등 변화되는 정도를 기반으로 적대적 예제를 생성할 수 있다.
- AI 모델의 학습 방향은 데이터 입력 시에 AI 모델의 경사도를 통하여 확인할 수 
있으며, 이를 공개하지 않거나 마스킹, 범주화 등의 기법을 활용하여 모델의 정보 
노출을 최소화한다.
31) lan J. Goodfellow et. al., “Explaining and Harnessing Adversarial Examples”, 2015.
32) Zhang, Lemoine, and Mitchell, “Mitigating Unwanted Biases with Adversarial Learning”, 2018.
33) Anish Athalye at al., “Obfuscated Gradients Give a False Sense of Security : Circumventing Defenses 
to Adversarial Examples”, 2018.
