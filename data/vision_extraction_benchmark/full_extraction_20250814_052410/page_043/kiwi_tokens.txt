### 추출 되 ᆫ 정보 #### 1 급 ( 반드시 추출 ) : - ** AI 모델 이 오염 되 ᆫ 데이터 를 학습 하 면 모델 의 정확도 가 저하 되 ᆫ다는 것 은 다수 의 연구 ( 16 ) 를 통하 어 증명 되 ᆫ 바 있 다 . ( 17 ) ** - ** 오염 되 ᆫ 데이터 학습 으로 인하 어 경계 면 변경 및 탐지 성능 저하 ( 17 ) ** - ** 데이터 오염 공격 은 이 상치 처리 등 의 방법 을 통하 어서 예방 하 거나 차단 하 ᆯ 수 있 다 . ** - ** ( 이상 치 처리 ) 임계 치 를 이상 점수 ( Outlier Score ) 로 정하 고 이상 점수 밖 에 위치 하 는 오염 되 ᆫ 데이터 를 찾 거나 ( 18 ) , 클러스터링 기법 을 활용 하 어 클러스터 밖 에 위치 하 는 오염 되 ᆫ 데이터 를 찾 는 방식 을 활용 하 ᆯ 수 있 다 . ( 19 ) ** #### 2 급 ( 요약 하 어 추출 ) : - ** 그림 : 공격 전 과 공격 후 의 데이터 분포 ** - ** 측정 항목 ** : y = + 1 , y = - 1 - ** 기간 / 범위 ** : 공격 전 과 공격 후 - ** 핵심 발견 ** : 공격 전 에 는 두 집단 사이 의 경계 가 명확 하 지만 , 공격 후 에 는 경계 가 흐리 어 지 고 오염 데이터 가 추가 되 ᆷ - ** 주요 수치 ** : 공격 전 경계선 이 선명 하 며 , 공격 후 에 는 경계선 이 희미 하 어 지 ᆷ #### 3 급 ( 제외 ) : - ** 그림 1 ** , ** 표 2 ** - ** 출처 ** : Shafahi Ali et al. , " Poison frogs ! targeted clean - label poisoning attacks on neural networks " , 2018. - ** 출처 ** : https://towardsdatascience.com/poisoning-attacks-on-machine-learning-1ff247c254db - ** 출처 ** : Paudice , Andrea , et al. , " Detection of Adversarial Training Examples in Poisoning Attacks through Anomaly Dete ction. " , 2018. - ** 출처 ** : Steinhardt , Jacob , Pang Wei W. Koh , and Percy S. Liang. , " Certified Defenses for Data Poisoning At tacks. " , 2017. --- ### 검증 - 각 추출 항목 이 독립 적 으로 의미 가 있 으며 , 컨 텍스트 없이 도 이해 가능 하 다 . - RAG 검색 시 유용 하 ᆫ 정보 로 인식 되 ᆫ다 .