참고 1. 데이터 오염 공격●●●
39
AI 모델이 오염된 데이터를 학습하면 모델의 정확도가 저하된다는 것은 다수의 연구16)를 
통해 증명된 바 있다.17)
참고
오염된 데이터 학습으로 인하여 경계면 변경 및 탐지 성능 저하17)
데이터 오염 공격은 이상치 처리 등의 방법을 통해서 예방하거나 차단할 수 있다.
(이상치 처리) 임계치를 이상 점수(Outlier Score)로 정하고 이상 점수 밖에 위치하는 
오염된 데이터를 찾거나18), 클러스터링 기법을 활용하여 클러스터 밖에 위치하는 
오염된 데이터를 찾는 방식을 활용할 수 있다.19)
16) Shafahi Ali et al. “Poison frogs! targeted clean-label poisoning attacks on neural networks”, 2018.
17) https://towardsdatascience.com/poisoning-attacks-on-machine-learning-1ff247c254db
18) Paudice, Andrea, et al., “Detection of Adversarial Training Examples in Poisoning Attacks through 
Anomaly Detection.”, 2018.
19) Steinhardt, Jacob, Pang Wei W. Koh, and Percy S. Liang., “Certified Defenses for Data Poisoning 
Attacks.” , 2017.
