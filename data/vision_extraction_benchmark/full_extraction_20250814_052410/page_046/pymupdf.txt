●●●금융분야 AI 보안 가이드라인
42
참고
* DP-SGD(Differential Privacy – Stochastic Gradient Descent) 기법
✓SGD는 AI 모델을 학습* 방식의 대표적인 방법으로 입력 데이터를 작은 크기로 
분할 집합(Mini Batch)하여 학습 진행
* AI 모델 학습은 새로운 데이터 입력으로 AI 모델 내의 노드 등의 수치가 최적화(Optimize)되는 과정으로 해석
✓DP-SGD는 SGD방식에서 차등 프라이버시 기법을 적용하여 학습 진행
   ∙ 분할 집합마다 각 가중치를 구하고 최대 기울기 제한(Clip Gradient) 및 통계적 
기반의 노이즈(Gaussian Noise)를 추가하여 학습 진행
✓해당 기법으로 공격자는 출력값을 기반으로 입력값을 유추, 모델 유추 등이 어려움
(목표 함수 노이즈27)) 목표 함수(Object Function)*에 차등 프라이버시 기법 적용을 
통해서, 입력값을 유추할 수 없도록 한다.
* 학습 과정에서 입력 데이터에서의 실제 정답(레이블)과 AI 모델의 예측값 사이의 차이
(손실값)를 판단하는 수식 함수
(데이터 분할 방식28)) 민감 데이터를 분할하고 각 민감 데이터마다 각기 다른 분류기로 
학습 및 각 분류기를 조합하여 학습하는 방식을 제안하였다.
- 이 방식을 통해서, 출력값으로 원 입력값을 유추할 수 없도록 한다.
27) Chaudhuri, Kamalika, and Claire Monteleoni, “Privacy-preserving logistic regression”, 2009.
28) Papernot, Nicolas, et al., “Scalable private learning with pate”, 2018.
