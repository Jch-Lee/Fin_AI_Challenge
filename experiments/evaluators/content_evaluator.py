#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ ëª¨ë“ˆ
VL ëª¨ë¸ê³¼ ê¸°ì¡´ ë°©ë²•ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ í’ˆì§ˆì„ í‰ê°€
"""

import re
import json
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass
from pathlib import Path
import difflib
from collections import Counter
import numpy as np


@dataclass
class ContentQualityMetrics:
    """ì½˜í…ì¸  í’ˆì§ˆ ë©”íŠ¸ë¦­"""
    # ê¸°ë³¸ í†µê³„
    total_chars: int
    total_words: int
    total_sentences: int
    unique_words: int
    
    # ë„ë©”ì¸ íŠ¹í™” ë©”íŠ¸ë¦­
    financial_terms_count: int
    regulatory_terms_count: int
    technical_terms_count: int
    
    # ì‹œê°ì  ì½˜í…ì¸  ê´€ë ¨
    visual_references: int
    table_indicators: int
    chart_indicators: int
    diagram_indicators: int
    
    # êµ¬ì¡°ì  ìš”ì†Œ
    headers_detected: int
    lists_detected: int
    numbered_items: int
    
    # í’ˆì§ˆ ì§€í‘œ
    readability_score: float
    coherence_score: float
    completeness_score: float
    
    def to_dict(self) -> Dict:
        return {
            "basic_stats": {
                "total_chars": self.total_chars,
                "total_words": self.total_words,
                "total_sentences": self.total_sentences,
                "unique_words": self.unique_words,
                "vocabulary_diversity": self.unique_words / max(self.total_words, 1)
            },
            "domain_coverage": {
                "financial_terms": self.financial_terms_count,
                "regulatory_terms": self.regulatory_terms_count,
                "technical_terms": self.technical_terms_count
            },
            "visual_content": {
                "visual_references": self.visual_references,
                "table_indicators": self.table_indicators,
                "chart_indicators": self.chart_indicators,
                "diagram_indicators": self.diagram_indicators
            },
            "structure": {
                "headers_detected": self.headers_detected,
                "lists_detected": self.lists_detected,
                "numbered_items": self.numbered_items
            },
            "quality_scores": {
                "readability": self.readability_score,
                "coherence": self.coherence_score,
                "completeness": self.completeness_score
            }
        }


class ContentQualityEvaluator:
    """ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ê¸°"""
    
    def __init__(self):
        self.financial_terms = self._load_financial_terms()
        self.regulatory_terms = self._load_regulatory_terms()
        self.technical_terms = self._load_technical_terms()
        self.visual_keywords = self._load_visual_keywords()
    
    def _load_financial_terms(self) -> Set[str]:
        """ê¸ˆìœµ ê´€ë ¨ ìš©ì–´ ë¡œë“œ"""
        terms = {
            # ê¸°ë³¸ ê¸ˆìœµ ìš©ì–´
            "ê¸ˆìœµ", "ì€í–‰", "íˆ¬ì", "ìì‚°", "ë¶€ì±„", "ìë³¸", "ìˆ˜ìµ", "ì†ì‹¤",
            "ë¦¬ìŠ¤í¬", "ìœ„í—˜", "ìˆ˜ìµë¥ ", "ê¸ˆë¦¬", "ì´ì", "ëŒ€ì¶œ", "ì˜ˆê¸ˆ",
            "ë³´í—˜", "ì—°ê¸ˆ", "í€ë“œ", "ì£¼ì‹", "ì±„ê¶Œ", "íŒŒìƒìƒí’ˆ",
            
            # í•€í…Œí¬ ìš©ì–´
            "í•€í…Œí¬", "ë””ì§€í„¸ë±…í‚¹", "ëª¨ë°”ì¼ë±…í‚¹", "ì „ìê²°ì œ", "ì•”í˜¸í™”í",
            "ë¸”ë¡ì²´ì¸", "ë””ì§€í„¸ìì‚°", "ê°€ìƒí™”í", "ë””ì§€í„¸í™”í",
            
            # ê·œì œ ê´€ë ¨
            "ê¸ˆìœµìœ„ì›íšŒ", "ê¸ˆìœµê°ë…ì›", "ë°”ì ¤", "IFRS", "íšŒê³„ê¸°ì¤€",
            "ìê¸°ìë³¸", "ìœ ë™ì„±", "ì‹ ìš©ìœ„í—˜", "ì‹œì¥ìœ„í—˜", "ìš´ì˜ìœ„í—˜",
            
            # ì˜ì–´ ìš©ì–´
            "fintech", "banking", "investment", "asset", "liability",
            "risk", "compliance", "regulation", "aml", "kyc"
        }
        return {term.lower() for term in terms}
    
    def _load_regulatory_terms(self) -> Set[str]:
        """ê·œì œ ê´€ë ¨ ìš©ì–´ ë¡œë“œ"""
        terms = {
            # ê·œì œ ê¸°ê´€
            "ê¸ˆìœµìœ„ì›íšŒ", "ê¸ˆìœµê°ë…ì›", "í•œêµ­ì€í–‰", "ì˜ˆê¸ˆë³´í—˜ê³µì‚¬",
            "ê¸ˆìœµì •ë³´ë¶„ì„ì›", "ê¸ˆìœµë³´ì•ˆì›",
            
            # ê·œì œ ìš©ì–´
            "ê·œì œ", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "ì¤€ìˆ˜", "ê°ë…", "ê²€ì‚¬", "ì œì¬",
            "ë²•ë ¹", "ê·œì •", "ì§€ì¹¨", "ê°€ì´ë“œë¼ì¸", "ê¸°ì¤€", "í‘œì¤€",
            "ì¸ê°€", "í—ˆê°€", "ì‹ ê³ ", "ë³´ê³ ", "ê³µì‹œ", "ê³µê°œ",
            
            # ë³´ì•ˆ ê´€ë ¨
            "ë³´ì•ˆ", "ê°œì¸ì •ë³´", "ì •ë³´ë³´í˜¸", "ì‚¬ì´ë²„ë³´ì•ˆ", "ë°ì´í„°ë³´í˜¸",
            "ì•”í˜¸í™”", "ì¸ì¦", "ì ‘ê·¼ì œì–´", "ê°ì‚¬", "ëª¨ë‹ˆí„°ë§",
            
            # ì˜ì–´ ìš©ì–´
            "compliance", "regulation", "supervision", "security",
            "privacy", "gdpr", "sox", "basel", "mifid"
        }
        return {term.lower() for term in terms}
    
    def _load_technical_terms(self) -> Set[str]:
        """ê¸°ìˆ  ê´€ë ¨ ìš©ì–´ ë¡œë“œ"""
        terms = {
            # AI/ML ìš©ì–´
            "ì¸ê³µì§€ëŠ¥", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ì‹ ê²½ë§", "ì•Œê³ ë¦¬ì¦˜",
            "ëª¨ë¸", "í•™ìŠµ", "í›ˆë ¨", "ì˜ˆì¸¡", "ë¶„ë¥˜", "íšŒê·€",
            "ìì—°ì–´ì²˜ë¦¬", "ì»´í“¨í„°ë¹„ì „", "ë°ì´í„°ë§ˆì´ë‹",
            
            # ë°ì´í„° ê´€ë ¨
            "ë¹…ë°ì´í„°", "ë°ì´í„°ë² ì´ìŠ¤", "ë°ì´í„°ì›¨ì–´í•˜ìš°ìŠ¤", "ETL",
            "ë°ì´í„°ë ˆì´í¬", "ë°ì´í„°íŒŒì´í”„ë¼ì¸", "ìŠ¤íŠ¸ë¦¬ë°",
            
            # í´ë¼ìš°ë“œ/ì¸í”„ë¼
            "í´ë¼ìš°ë“œ", "ì„œë²„", "ë„¤íŠ¸ì›Œí¬", "API", "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤",
            "ì»¨í…Œì´ë„ˆ", "ë„ì»¤", "ì¿ ë²„ë„¤í‹°ìŠ¤", "DevOps",
            
            # ì˜ì–´ ìš©ì–´
            "ai", "ml", "nlp", "api", "cloud", "server",
            "algorithm", "model", "training", "prediction"
        }
        return {term.lower() for term in terms}
    
    def _load_visual_keywords(self) -> Dict[str, Set[str]]:
        """ì‹œê°ì  ì½˜í…ì¸  í‚¤ì›Œë“œ ë¡œë“œ"""
        return {
            "charts": {
                "ì°¨íŠ¸", "ê·¸ë˜í”„", "ë„í‘œ", "ê·¸ë¦¼", "figure", "chart",
                "graph", "plot", "ë§‰ëŒ€ê·¸ë˜í”„", "ì„ ê·¸ë˜í”„", "ì›ê·¸ë˜í”„",
                "íˆìŠ¤í† ê·¸ë¨", "ì‚°ì ë„", "ë°•ìŠ¤í”Œë¡¯"
            },
            "tables": {
                "í‘œ", "í…Œì´ë¸”", "ëª©ë¡", "ë¦¬ìŠ¤íŠ¸", "table", "list",
                "í–‰", "ì—´", "ì…€", "row", "column", "cell"
            },
            "diagrams": {
                "ë‹¤ì´ì–´ê·¸ë¨", "êµ¬ì¡°ë„", "íë¦„ë„", "ì¡°ì§ë„", "ì‹œìŠ¤í…œë„",
                "ì•„í‚¤í…ì²˜", "diagram", "flowchart", "structure",
                "architecture", "workflow"
            }
        }
    
    def evaluate_content_quality(self, text: str, method_name: str = "") -> ContentQualityMetrics:
        """í…ìŠ¤íŠ¸ì˜ ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€"""
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        basic_stats = self._calculate_basic_stats(text)
        
        # ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ê³„ì‚°
        domain_stats = self._calculate_domain_coverage(text)
        
        # ì‹œê°ì  ì½˜í…ì¸  ê´€ë ¨ ê³„ì‚°
        visual_stats = self._calculate_visual_content(text)
        
        # êµ¬ì¡°ì  ìš”ì†Œ ê³„ì‚°
        structure_stats = self._calculate_structural_elements(text)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        quality_scores = self._calculate_quality_scores(text, basic_stats)
        
        return ContentQualityMetrics(
            # ê¸°ë³¸ í†µê³„
            total_chars=basic_stats["chars"],
            total_words=basic_stats["words"],
            total_sentences=basic_stats["sentences"],
            unique_words=basic_stats["unique_words"],
            
            # ë„ë©”ì¸ íŠ¹í™”
            financial_terms_count=domain_stats["financial"],
            regulatory_terms_count=domain_stats["regulatory"],
            technical_terms_count=domain_stats["technical"],
            
            # ì‹œê°ì  ì½˜í…ì¸ 
            visual_references=visual_stats["visual_refs"],
            table_indicators=visual_stats["tables"],
            chart_indicators=visual_stats["charts"],
            diagram_indicators=visual_stats["diagrams"],
            
            # êµ¬ì¡°ì  ìš”ì†Œ
            headers_detected=structure_stats["headers"],
            lists_detected=structure_stats["lists"],
            numbered_items=structure_stats["numbered"],
            
            # í’ˆì§ˆ ì§€í‘œ
            readability_score=quality_scores["readability"],
            coherence_score=quality_scores["coherence"],
            completeness_score=quality_scores["completeness"]
        )
    
    def _calculate_basic_stats(self, text: str) -> Dict[str, int]:
        """ê¸°ë³¸ í…ìŠ¤íŠ¸ í†µê³„ ê³„ì‚°"""
        chars = len(text)
        words = text.split()
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        unique_words = len(set(word.lower().strip('.,!?;:"()[]{}') for word in words))
        
        return {
            "chars": chars,
            "words": len(words),
            "sentences": len(sentences),
            "unique_words": unique_words
        }
    
    def _calculate_domain_coverage(self, text: str) -> Dict[str, int]:
        """ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ì»¤ë²„ë¦¬ì§€ ê³„ì‚°"""
        text_lower = text.lower()
        
        financial_count = sum(1 for term in self.financial_terms if term in text_lower)
        regulatory_count = sum(1 for term in self.regulatory_terms if term in text_lower)
        technical_count = sum(1 for term in self.technical_terms if term in text_lower)
        
        return {
            "financial": financial_count,
            "regulatory": regulatory_count,
            "technical": technical_count
        }
    
    def _calculate_visual_content(self, text: str) -> Dict[str, int]:
        """ì‹œê°ì  ì½˜í…ì¸  ê´€ë ¨ ì§€í‘œ ê³„ì‚°"""
        text_lower = text.lower()
        
        visual_refs = 0
        tables = 0
        charts = 0
        diagrams = 0
        
        for category, keywords in self.visual_keywords.items():
            count = sum(1 for keyword in keywords if keyword in text_lower)
            
            if category == "charts":
                charts = count
            elif category == "tables":
                tables = count
            elif category == "diagrams":
                diagrams = count
            
            visual_refs += count
        
        return {
            "visual_refs": visual_refs,
            "tables": tables,
            "charts": charts,
            "diagrams": diagrams
        }
    
    def _calculate_structural_elements(self, text: str) -> Dict[str, int]:
        """êµ¬ì¡°ì  ìš”ì†Œ ê³„ì‚°"""
        
        # í—¤ë” ê°ì§€ (markdown styleì´ë‚˜ ë²ˆí˜¸ íŒ¨í„´)
        headers = len(re.findall(r'^#{1,6}\s+.+$|^\d+\.?\s+[ê°€-í£A-Za-z].+$', text, re.MULTILINE))
        
        # ë¦¬ìŠ¤íŠ¸ ê°ì§€
        lists = len(re.findall(r'^\s*[-*+â€¢]\s+.+$|^\s*\d+\.\s+.+$', text, re.MULTILINE))
        
        # ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ í•­ëª©
        numbered = len(re.findall(r'^\s*\d+\.\s+.+$|^\s*\(\d+\)\s+.+$', text, re.MULTILINE))
        
        return {
            "headers": headers,
            "lists": lists,
            "numbered": numbered
        }
    
    def _calculate_quality_scores(self, text: str, basic_stats: Dict[str, int]) -> Dict[str, float]:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        
        # ê°€ë…ì„± ì ìˆ˜ (ë‹¨ì–´ ê¸¸ì´ì™€ ë¬¸ì¥ ê¸¸ì´ ê¸°ë°˜)
        readability = self._calculate_readability(text, basic_stats)
        
        # ì¼ê´€ì„± ì ìˆ˜ (ë°˜ë³µ íŒ¨í„´ê³¼ êµ¬ì¡° ê¸°ë°˜)
        coherence = self._calculate_coherence(text)
        
        # ì™„ì„±ë„ ì ìˆ˜ (ì½˜í…ì¸  í’ë¶€í•¨ ê¸°ë°˜)
        completeness = self._calculate_completeness(text, basic_stats)
        
        return {
            "readability": max(0.0, min(1.0, readability)),
            "coherence": max(0.0, min(1.0, coherence)),
            "completeness": max(0.0, min(1.0, completeness))
        }
    
    def _calculate_readability(self, text: str, basic_stats: Dict[str, int]) -> float:
        """ê°€ë…ì„± ì ìˆ˜ ê³„ì‚° (í•œêµ­ì–´ ì ì‘)"""
        if basic_stats["words"] == 0 or basic_stats["sentences"] == 0:
            return 0.0
        
        # í‰ê·  ë‹¨ì–´ ê¸¸ì´
        avg_word_length = basic_stats["chars"] / basic_stats["words"]
        
        # í‰ê·  ë¬¸ì¥ ê¸¸ì´ (ë‹¨ì–´ ìˆ˜)
        avg_sentence_length = basic_stats["words"] / basic_stats["sentences"]
        
        # ì–´íœ˜ ë‹¤ì–‘ì„±
        vocab_diversity = basic_stats["unique_words"] / basic_stats["words"]
        
        # í•œêµ­ì–´ íŠ¹ì„±ì„ ê³ ë ¤í•œ ê°€ë…ì„± ì ìˆ˜
        # ë„ˆë¬´ ê¸´ ë‹¨ì–´ë‚˜ ë¬¸ì¥ì€ ê°€ë…ì„±ì„ ë–¨ì–´ëœ¨ë¦¼
        word_score = max(0, 1 - (avg_word_length - 3) / 10)  # 3ê¸€ì ê¸°ì¤€
        sentence_score = max(0, 1 - (avg_sentence_length - 15) / 30)  # 15ë‹¨ì–´ ê¸°ì¤€
        diversity_score = min(1, vocab_diversity * 2)  # ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤
        
        return (word_score + sentence_score + diversity_score) / 3
    
    def _calculate_coherence(self, text: str) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip() and len(s.split()) > 3]
        
        if len(sentences) < 2:
            return 0.5
        
        # ë¬¸ì¥ ê°„ ì–´íœ˜ ì¤‘ë³µë„ ê³„ì‚°
        coherence_scores = []
        
        for i in range(len(sentences) - 1):
            words1 = set(sentences[i].lower().split())
            words2 = set(sentences[i + 1].lower().split())
            
            if len(words1) > 0 and len(words2) > 0:
                overlap = len(words1 & words2) / len(words1 | words2)
                coherence_scores.append(overlap)
        
        return np.mean(coherence_scores) if coherence_scores else 0.5
    
    def _calculate_completeness(self, text: str, basic_stats: Dict[str, int]) -> float:
        """ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°"""
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì ìˆ˜
        length_score = min(1.0, basic_stats["chars"] / 10000)  # 10,000ì ê¸°ì¤€
        
        # êµ¬ì¡°ì  ì™„ì„±ë„ (í—¤ë”, ë¦¬ìŠ¤íŠ¸ ë“±ì˜ ì¡´ì¬)
        has_headers = bool(re.search(r'^#{1,6}\s+.+$|^\d+\.?\s+[ê°€-í£A-Za-z].+$', text, re.MULTILINE))
        has_lists = bool(re.search(r'^\s*[-*+â€¢]\s+.+$|^\s*\d+\.\s+.+$', text, re.MULTILINE))
        has_paragraphs = len(text.split('\n\n')) > 3
        
        structure_score = sum([has_headers, has_lists, has_paragraphs]) / 3
        
        # ë„ë©”ì¸ ì»¤ë²„ë¦¬ì§€ ì ìˆ˜
        domain_coverage = self._calculate_domain_coverage(text)
        domain_score = min(1.0, sum(domain_coverage.values()) / 20)  # 20ê°œ ìš©ì–´ ê¸°ì¤€
        
        return (length_score + structure_score + domain_score) / 3
    
    def compare_content_quality(self, 
                              traditional_text: str, 
                              vl_text: str) -> Dict[str, any]:
        """ë‘ ì¶”ì¶œ ë°©ë²•ì˜ ì½˜í…ì¸  í’ˆì§ˆ ë¹„êµ"""
        
        # ê°ê°ì˜ í’ˆì§ˆ í‰ê°€
        traditional_metrics = self.evaluate_content_quality(traditional_text, "traditional")
        vl_metrics = self.evaluate_content_quality(vl_text, "vl")
        
        # ë¹„êµ ë¶„ì„
        comparison = {
            "traditional_quality": traditional_metrics.to_dict(),
            "vl_quality": vl_metrics.to_dict(),
            "improvements": self._calculate_improvements(traditional_metrics, vl_metrics),
            "content_overlap": self._calculate_content_overlap(traditional_text, vl_text),
            "unique_content": self._identify_unique_content(traditional_text, vl_text),
            "overall_assessment": self._assess_overall_quality(traditional_metrics, vl_metrics)
        }
        
        return comparison
    
    def _calculate_improvements(self, traditional: ContentQualityMetrics, vl: ContentQualityMetrics) -> Dict[str, float]:
        """ê°œì„  ì •ë„ ê³„ì‚°"""
        def safe_percentage(new_val, old_val):
            if old_val == 0:
                return 100.0 if new_val > 0 else 0.0
            return ((new_val - old_val) / old_val) * 100
        
        return {
            "content_volume": {
                "chars_improvement": safe_percentage(vl.total_chars, traditional.total_chars),
                "words_improvement": safe_percentage(vl.total_words, traditional.total_words),
                "sentences_improvement": safe_percentage(vl.total_sentences, traditional.total_sentences)
            },
            "domain_coverage": {
                "financial_improvement": safe_percentage(vl.financial_terms_count, traditional.financial_terms_count),
                "regulatory_improvement": safe_percentage(vl.regulatory_terms_count, traditional.regulatory_terms_count),
                "technical_improvement": safe_percentage(vl.technical_terms_count, traditional.technical_terms_count)
            },
            "visual_content": {
                "visual_refs_improvement": safe_percentage(vl.visual_references, traditional.visual_references),
                "charts_improvement": safe_percentage(vl.chart_indicators, traditional.chart_indicators),
                "tables_improvement": safe_percentage(vl.table_indicators, traditional.table_indicators)
            },
            "quality_scores": {
                "readability_improvement": vl.readability_score - traditional.readability_score,
                "coherence_improvement": vl.coherence_score - traditional.coherence_score,
                "completeness_improvement": vl.completeness_score - traditional.completeness_score
            }
        }
    
    def _calculate_content_overlap(self, text1: str, text2: str) -> Dict[str, float]:
        """ì½˜í…ì¸  ì¤‘ë³µë„ ê³„ì‚°"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return {"overlap_ratio": 0.0, "unique_to_text1": 0.0, "unique_to_text2": 0.0}
        
        overlap = words1 & words2
        unique_to_1 = words1 - words2
        unique_to_2 = words2 - words1
        
        total_unique = len(words1 | words2)
        
        return {
            "overlap_ratio": len(overlap) / total_unique,
            "unique_to_text1": len(unique_to_1) / total_unique,
            "unique_to_text2": len(unique_to_2) / total_unique,
            "jaccard_similarity": len(overlap) / len(words1 | words2)
        }
    
    def _identify_unique_content(self, traditional_text: str, vl_text: str) -> Dict[str, List[str]]:
        """ê° ë°©ë²•ì˜ ê³ ìœ  ì½˜í…ì¸  ì‹ë³„"""
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        trad_sentences = set(re.split(r'[.!?]+', traditional_text))
        vl_sentences = set(re.split(r'[.!?]+', vl_text))
        
        # ì •ë¦¬
        trad_sentences = {s.strip() for s in trad_sentences if s.strip() and len(s) > 10}
        vl_sentences = {s.strip() for s in vl_sentences if s.strip() and len(s) > 10}
        
        # ê³ ìœ  ì½˜í…ì¸  ì‹ë³„
        unique_to_traditional = list(trad_sentences - vl_sentences)[:10]  # ìƒìœ„ 10ê°œ
        unique_to_vl = list(vl_sentences - trad_sentences)[:10]  # ìƒìœ„ 10ê°œ
        
        return {
            "unique_to_traditional": unique_to_traditional,
            "unique_to_vl": unique_to_vl
        }
    
    def _assess_overall_quality(self, traditional: ContentQualityMetrics, vl: ContentQualityMetrics) -> Dict[str, any]:
        """ì „ì²´ì ì¸ í’ˆì§ˆ í‰ê°€"""
        
        # ê° ë°©ë²•ì˜ ì¢…í•© ì ìˆ˜ ê³„ì‚°
        def calculate_overall_score(metrics: ContentQualityMetrics) -> float:
            # ê°€ì¤‘ í‰ê·  (ì™„ì„±ë„ë¥¼ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤)
            return (
                metrics.completeness_score * 0.4 +
                metrics.coherence_score * 0.3 +
                metrics.readability_score * 0.2 +
                min(1.0, (metrics.financial_terms_count + metrics.regulatory_terms_count) / 50) * 0.1
            )
        
        trad_score = calculate_overall_score(traditional)
        vl_score = calculate_overall_score(vl)
        
        # ì¶”ì²œì‚¬í•­ ê²°ì •
        score_diff = vl_score - trad_score
        
        if score_diff > 0.2:
            recommendation = "VL_STRONGLY_RECOMMENDED"
            reason = "VL ë°©ë²•ì´ í’ˆì§ˆ ì¸¡ë©´ì—ì„œ ìƒë‹¹í•œ ê°œì„ ì„ ë³´ì„"
        elif score_diff > 0.1:
            recommendation = "VL_RECOMMENDED"
            reason = "VL ë°©ë²•ì´ í’ˆì§ˆ ê°œì„ ì„ ë³´ì„"
        elif score_diff > -0.1:
            recommendation = "COMPARABLE"
            reason = "ë‘ ë°©ë²•ì˜ í’ˆì§ˆì´ ë¹„ìŠ·í•¨"
        else:
            recommendation = "TRADITIONAL_PREFERRED"
            reason = "ê¸°ì¡´ ë°©ë²•ì´ í’ˆì§ˆ ì¸¡ë©´ì—ì„œ ë” ë‚˜ìŒ"
        
        return {
            "traditional_overall_score": trad_score,
            "vl_overall_score": vl_score,
            "score_difference": score_diff,
            "recommendation": recommendation,
            "reason": reason,
            "quality_summary": {
                "content_richness": "VL" if vl.total_chars > traditional.total_chars * 1.1 else "Traditional",
                "domain_coverage": "VL" if (vl.financial_terms_count + vl.regulatory_terms_count) > (traditional.financial_terms_count + traditional.regulatory_terms_count) else "Traditional",
                "structural_quality": "VL" if (vl.headers_detected + vl.lists_detected) > (traditional.headers_detected + traditional.lists_detected) else "Traditional",
                "visual_content_handling": "VL" if vl.visual_references > traditional.visual_references else "Traditional"
            }
        }


def main():
    """ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ê¸° í…ŒìŠ¤íŠ¸"""
    
    evaluator = ContentQualityEvaluator()
    
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸
    sample_traditional = """
    ê¸ˆìœµë¶„ì•¼ AI ë³´ì•ˆ ê°€ì´ë“œë¼ì¸
    1. ê°œìš”
    ë³¸ ê°€ì´ë“œë¼ì¸ì€ ê¸ˆìœµíšŒì‚¬ì˜ AI ì‹œìŠ¤í…œ ë³´ì•ˆì„ ìœ„í•œ ê¸°ì¤€ì„ ì œì‹œí•œë‹¤.
    
    2. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­
    - ë°ì´í„° ì•”í˜¸í™”
    - ì ‘ê·¼ ì œì–´
    - ê°ì‚¬ ì¶”ì 
    """
    
    sample_vl = """
    ê¸ˆìœµë¶„ì•¼ AI ë³´ì•ˆ ê°€ì´ë“œë¼ì¸
    
    1. ê°œìš”
    ë³¸ ê°€ì´ë“œë¼ì¸ì€ ê¸ˆìœµíšŒì‚¬ì˜ AI ì‹œìŠ¤í…œ ë³´ì•ˆì„ ìœ„í•œ ê¸°ì¤€ì„ ì œì‹œí•œë‹¤.
    ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì— ë”°ë¼ ê¸ˆìœµê¶Œì—ì„œì˜ AI í™œìš©ì´ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°,
    ì´ì— ë”°ë¥¸ ë³´ì•ˆ ìœ„í—˜ ê´€ë¦¬ê°€ í•„ìš”í•˜ë‹¤.
    
    [Figure 1: AI ë³´ì•ˆ ìœ„í—˜ ë§¤íŠ¸ë¦­ìŠ¤]
    ìœ„í—˜ë„: ë†’ìŒ - ë°ì´í„° ìœ ì¶œ, ëª¨ë¸ ì¡°ì‘
    ìœ„í—˜ë„: ì¤‘ê°„ - í¸í–¥ì„± ë¬¸ì œ, ì„¤ëª…ê°€ëŠ¥ì„± ë¶€ì¡±
    ìœ„í—˜ë„: ë‚®ìŒ - ì„±ëŠ¥ ì €í•˜, í˜¸í™˜ì„± ë¬¸ì œ
    
    2. ë³´ì•ˆ ìš”êµ¬ì‚¬í•­
    - ë°ì´í„° ì•”í˜¸í™”: AES-256 ì´ìƒ ì•”í˜¸í™” ì ìš©
    - ì ‘ê·¼ ì œì–´: ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´(RBAC) êµ¬í˜„
    - ê°ì‚¬ ì¶”ì : ëª¨ë“  AI ëª¨ë¸ ì ‘ê·¼ ê¸°ë¡ ë³´ê´€
    
    [Table 1: ë³´ì•ˆ í†µì œ ë§¤íŠ¸ë¦­ìŠ¤]
    í†µì œ í•­ëª© | ì ìš© ìˆ˜ì¤€ | ê²€ì¦ ë°©ë²•
    ì•”í˜¸í™” | í•„ìˆ˜ | ê¸°ìˆ  ê²€í† 
    ì ‘ê·¼ì œì–´ | í•„ìˆ˜ | ì •ì±… ê²€í†   
    ëª¨ë‹ˆí„°ë§ | ê¶Œì¥ | í”„ë¡œì„¸ìŠ¤ ê²€í† 
    """
    
    # í’ˆì§ˆ í‰ê°€ ì‹¤í–‰
    print("=== ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸ ===\n")
    
    comparison = evaluator.compare_content_quality(sample_traditional, sample_vl)
    
    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ“Š í’ˆì§ˆ ë¹„êµ ê²°ê³¼:")
    print(f"- ê¸°ì¡´ ë°©ë²• ì¢…í•© ì ìˆ˜: {comparison['overall_assessment']['traditional_overall_score']:.3f}")
    print(f"- VL ë°©ë²• ì¢…í•© ì ìˆ˜: {comparison['overall_assessment']['vl_overall_score']:.3f}")
    print(f"- ì ìˆ˜ ì°¨ì´: {comparison['overall_assessment']['score_difference']:+.3f}")
    print(f"- ì¶”ì²œì‚¬í•­: {comparison['overall_assessment']['recommendation']}")
    print(f"- ì‚¬ìœ : {comparison['overall_assessment']['reason']}")
    
    print("\nğŸ“ˆ ê°œì„  ì •ë„:")
    improvements = comparison['improvements']
    print(f"- ë¬¸ì ìˆ˜ ì¦ê°€: {improvements['content_volume']['chars_improvement']:+.1f}%")
    print(f"- ê¸ˆìœµ ìš©ì–´ ì¦ê°€: {improvements['domain_coverage']['financial_improvement']:+.1f}%")
    print(f"- ì‹œê°ì  ì°¸ì¡° ì¦ê°€: {improvements['visual_content']['visual_refs_improvement']:+.1f}%")
    
    print(f"\nğŸ“‹ JSON ê²°ê³¼ ì €ì¥...")
    with open("content_quality_test.json", "w", encoding="utf-8") as f:
        json.dump(comparison, f, indent=2, ensure_ascii=False)
    
    print("ì™„ë£Œ!")


if __name__ == "__main__":
    main()