#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì™„ì „í•œ RAG ì‹œìŠ¤í…œ í†µí•© ê²€ì¦
ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì˜ ì •í™•í•œ ì‘ë™ í™•ì¸
"""

import os
import sys
import json
import time
import numpy as np
import faiss
import torch
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€ (../../ ìƒëŒ€ê²½ë¡œ ì‚¬ìš©)
sys.path.append(str(Path(__file__).parent.parent.parent))

# UTF-8 ì¶œë ¥ ì„¤ì •
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


class CompleteRAGValidator:
    """ì™„ì „í•œ RAG ì‹œìŠ¤í…œ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.results = {}
        self.errors = []
        
    def validate_pdf_processing(self):
        """PDF ì²˜ë¦¬ ê²€ì¦"""
        print("\n" + "="*80)
        print("1. PDF ì²˜ë¦¬ ê²€ì¦")
        print("="*80)
        
        try:
            from packages.preprocessing.pdf_processor_advanced import AdvancedPDFProcessor
            
            pdf_path = "ê¸ˆìœµë¶„ì•¼ AI ë³´ì•ˆ ê°€ì´ë“œë¼ì¸.pdf"
            if not Path(pdf_path).exists():
                self.errors.append(f"PDF íŒŒì¼ ì—†ìŒ: {pdf_path}")
                return None
                
            processor = AdvancedPDFProcessor()
            result = processor.extract_pdf(pdf_path)
            
            text = result.text
            self.results['pdf'] = {
                'success': True,
                'text_length': len(text),
                'pages': result.metadata.get('total_pages', 0)
            }
            
            print(f"âœ… PDF ì²˜ë¦¬ ì„±ê³µ")
            print(f"   - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text):,}ì")
            print(f"   - ìƒ˜í”Œ: {text[:100]}...")
            
            return text
            
        except Exception as e:
            self.errors.append(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            print(f"âŒ PDF ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def validate_chunking(self, text):
        """ì²­í‚¹ ê²€ì¦"""
        print("\n" + "="*80)
        print("2. ì²­í‚¹ ê²€ì¦")
        print("="*80)
        
        try:
            from packages.preprocessing.chunker import DocumentChunker
            
            chunker = DocumentChunker(chunk_size=1000, chunk_overlap=100)
            chunks = chunker.chunk_document(text, metadata={"doc_id": "test"})
            
            self.results['chunking'] = {
                'success': True,
                'num_chunks': len(chunks),
                'avg_length': np.mean([len(c.content) for c in chunks])
            }
            
            print(f"âœ… ì²­í‚¹ ì„±ê³µ")
            print(f"   - ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
            print(f"   - í‰ê·  ê¸¸ì´: {self.results['chunking']['avg_length']:.0f}ì")
            
            return chunks
            
        except Exception as e:
            self.errors.append(f"ì²­í‚¹ ì‹¤íŒ¨: {e}")
            print(f"âŒ ì²­í‚¹ ì‹¤íŒ¨: {e}")
            return None
    
    def validate_e5_embeddings(self, chunks):
        """E5 ì„ë² ë”© ê²€ì¦"""
        print("\n" + "="*80)
        print("3. E5 ì„ë² ë”© ê²€ì¦")
        print("="*80)
        
        try:
            from packages.preprocessing.embedder_e5 import E5Embedder
            
            embedder = E5Embedder()
            print(f"   ëª¨ë¸: {embedder.model_name}")
            print(f"   ì°¨ì›: {embedder.embedding_dim}")
            
            # ë¬¸ì„œ ì„ë² ë”©
            chunk_texts = [c.content for c in chunks]
            doc_embeddings = embedder.encode(chunk_texts, is_query=False, batch_size=32)
            
            # ì¿¼ë¦¬ ì„ë² ë”©
            test_query = "AI ë³´ì•ˆ"
            query_embedding = embedder.encode([test_query], is_query=True)
            
            self.results['embeddings'] = {
                'success': True,
                'model': embedder.model_name,
                'dimension': embedder.embedding_dim,
                'doc_shape': doc_embeddings.shape,
                'query_shape': query_embedding.shape
            }
            
            print(f"âœ… E5 ì„ë² ë”© ì„±ê³µ")
            print(f"   - ë¬¸ì„œ ì„ë² ë”©: {doc_embeddings.shape}")
            print(f"   - ì¿¼ë¦¬ ì„ë² ë”©: {query_embedding.shape}")
            
            return embedder, doc_embeddings
            
        except Exception as e:
            self.errors.append(f"E5 ì„ë² ë”© ì‹¤íŒ¨: {e}")
            print(f"âŒ E5 ì„ë² ë”© ì‹¤íŒ¨: {e}")
            return None, None
    
    def validate_faiss_index(self, embeddings):
        """FAISS ì¸ë±ìŠ¤ ê²€ì¦"""
        print("\n" + "="*80)
        print("4. FAISS ì¸ë±ìŠ¤ ê²€ì¦")
        print("="*80)
        
        try:
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatIP(dimension)
            index.add(embeddings.astype('float32'))
            
            # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            test_vector = embeddings[0:1]
            D, I = index.search(test_vector, k=5)
            
            self.results['faiss'] = {
                'success': True,
                'num_vectors': index.ntotal,
                'dimension': dimension,
                'search_test': {'distances': D[0].tolist(), 'indices': I[0].tolist()}
            }
            
            print(f"âœ… FAISS ì¸ë±ìŠ¤ ì„±ê³µ")
            print(f"   - ì¸ë±ì‹±ëœ ë²¡í„°: {index.ntotal}ê°œ")
            print(f"   - ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: Top-1 ê±°ë¦¬ = {D[0][0]:.4f}")
            
            return index
            
        except Exception as e:
            self.errors.append(f"FAISS ì¸ë±ìŠ¤ ì‹¤íŒ¨: {e}")
            print(f"âŒ FAISS ì¸ë±ìŠ¤ ì‹¤íŒ¨: {e}")
            return None
    
    def validate_bm25(self, chunks):
        """BM25 ê²€ì¦"""
        print("\n" + "="*80)
        print("5. BM25 ê²€ìƒ‰ ê²€ì¦")
        print("="*80)
        
        try:
            from packages.retrieval.bm25_retriever import BM25Retriever
            
            bm25 = BM25Retriever()
            chunk_texts = [c.content for c in chunks]
            doc_ids = [f"doc_{i}" for i in range(len(chunks))]
            
            bm25.build_index(chunk_texts, doc_ids)
            
            # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            test_query = "AI ë³´ì•ˆ"
            results = bm25.search(test_query, k=5)
            
            self.results['bm25'] = {
                'success': True,
                'num_docs': len(chunk_texts),
                'search_results': len(results)
            }
            
            print(f"âœ… BM25 ì¸ë±ìŠ¤ ì„±ê³µ")
            print(f"   - ì¸ë±ì‹±ëœ ë¬¸ì„œ: {len(chunk_texts)}ê°œ")
            print(f"   - í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            
            return bm25
            
        except Exception as e:
            self.errors.append(f"BM25 ì‹¤íŒ¨: {e}")
            print(f"âŒ BM25 ì‹¤íŒ¨: {e}")
            return None
    
    def validate_hybrid_search(self, embedder, faiss_index, bm25, chunks):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²€ì¦"""
        print("\n" + "="*80)
        print("6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²€ì¦")
        print("="*80)
        
        try:
            # ì§ì ‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„
            test_query = "ê¸ˆìœµ AI ì‹œìŠ¤í…œì˜ ë³´ì•ˆ ì¡°ì¹˜"
            
            # BM25 ê²€ìƒ‰
            bm25_results = bm25.search(test_query, k=10)
            print(f"   BM25 ê²€ìƒ‰: {len(bm25_results)}ê°œ ê²°ê³¼")
            
            # Vector ê²€ìƒ‰
            query_embedding = embedder.encode([test_query], is_query=True)
            D, I = faiss_index.search(query_embedding.astype('float32'), k=10)
            print(f"   Vector ê²€ìƒ‰: {len(I[0])}ê°œ ê²°ê³¼")
            
            # ì ìˆ˜ ê²°í•© (ê°„ë‹¨í•œ ë°©ì‹)
            alpha = 0.3  # BM25 ê°€ì¤‘ì¹˜
            beta = 0.7   # Vector ê°€ì¤‘ì¹˜
            
            combined_scores = {}
            
            # BM25 ì ìˆ˜ ì¶”ê°€
            for i, result in enumerate(bm25_results):
                doc_idx = int(result.doc_id.split('_')[1])
                normalized_score = 1.0 / (i + 1)  # ìˆœìœ„ ê¸°ë°˜ ì •ê·œí™”
                combined_scores[doc_idx] = alpha * normalized_score
            
            # Vector ì ìˆ˜ ì¶”ê°€
            for i, (idx, score) in enumerate(zip(I[0], D[0])):
                if idx not in combined_scores:
                    combined_scores[idx] = 0
                normalized_score = score  # ì´ë¯¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                combined_scores[idx] += beta * normalized_score
            
            # ìƒìœ„ 5ê°œ ì„ íƒ
            top_results = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:5]
            
            self.results['hybrid'] = {
                'success': True,
                'bm25_results': len(bm25_results),
                'vector_results': len(I[0]),
                'combined_results': len(top_results),
                'top_score': top_results[0][1] if top_results else 0
            }
            
            print(f"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ê³µ")
            print(f"   - ìµœì¢… ê²°ê³¼: {len(top_results)}ê°œ")
            print(f"   - ìµœê³  ì ìˆ˜: {top_results[0][1]:.4f}")
            
            # ê²°ê³¼ ë°˜í™˜
            search_results = []
            for idx, score in top_results:
                if 0 <= idx < len(chunks):
                    search_results.append((chunks[idx].content, score))
            
            return search_results
            
        except Exception as e:
            self.errors.append(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def validate_qwen_llm(self, query, contexts):
        """Qwen LLM ê²€ì¦"""
        print("\n" + "="*80)
        print("7. Qwen2.5-7B LLM ê²€ì¦")
        print("="*80)
        
        try:
            from scripts.integrate_qwen_llm import QwenLLM
            from packages.llm.prompt_templates import FinancePromptTemplate
            
            # GPU í™•ì¸
            use_gpu = torch.cuda.is_available()
            print(f"   GPU ì‚¬ìš©: {use_gpu}")
            
            # LLM ì´ˆê¸°í™”
            llm = QwenLLM(
                use_4bit=use_gpu,
                max_new_tokens=256,
                temperature=0.3
            )
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            q_type = FinancePromptTemplate.detect_question_type(query)
            print(f"   ì§ˆë¬¸ ìœ í˜•: {q_type.value}")
            
            # ë‹µë³€ ìƒì„±
            start = time.time()
            answer = llm.generate(query, contexts[:3])
            gen_time = time.time() - start
            
            self.results['llm'] = {
                'success': True,
                'model': 'Qwen2.5-7B-Instruct',
                'use_gpu': use_gpu,
                'answer_length': len(answer),
                'generation_time': gen_time
            }
            
            print(f"âœ… LLM ë‹µë³€ ìƒì„± ì„±ê³µ")
            print(f"   - ë‹µë³€ ê¸¸ì´: {len(answer)}ì")
            print(f"   - ìƒì„± ì‹œê°„: {gen_time:.2f}ì´ˆ")
            print(f"\n[ìƒì„±ëœ ë‹µë³€]")
            print("-"*60)
            print(answer[:500] + "..." if len(answer) > 500 else answer)
            print("-"*60)
            
            return answer
            
        except Exception as e:
            self.errors.append(f"LLM ì‹¤íŒ¨: {e}")
            print(f"âŒ LLM ì‹¤íŒ¨: {e}")
            # LLM ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜
            return f"[LLM ì˜¤ë¥˜: {e}]"
    
    def run_complete_validation(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤í–‰"""
        print("\n" + "â–ˆ"*80)
        print(" RAG ì‹œìŠ¤í…œ ì™„ì „ ê²€ì¦ ì‹œì‘")
        print("â–ˆ"*80)
        
        start_time = time.time()
        
        # 1. PDF ì²˜ë¦¬
        text = self.validate_pdf_processing()
        if not text:
            print("\nâš ï¸ PDF ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ê²€ì¦ ì¤‘ë‹¨")
            return False
        
        # 2. ì²­í‚¹
        chunks = self.validate_chunking(text)
        if not chunks:
            print("\nâš ï¸ ì²­í‚¹ ì‹¤íŒ¨ë¡œ ê²€ì¦ ì¤‘ë‹¨")
            return False
        
        # 3. E5 ì„ë² ë”©
        embedder, embeddings = self.validate_e5_embeddings(chunks)
        if embedder is None or embeddings is None:
            print("\nâš ï¸ E5 ì„ë² ë”© ì‹¤íŒ¨ë¡œ ê²€ì¦ ì¤‘ë‹¨")
            return False
        
        # 4. FAISS ì¸ë±ìŠ¤
        faiss_index = self.validate_faiss_index(embeddings)
        if not faiss_index:
            print("\nâš ï¸ FAISS ì¸ë±ìŠ¤ ì‹¤íŒ¨ë¡œ ê²€ì¦ ì¤‘ë‹¨")
            return False
        
        # 5. BM25
        bm25 = self.validate_bm25(chunks)
        if not bm25:
            print("\nâš ï¸ BM25 ì‹¤íŒ¨ë¡œ ê²€ì¦ ì¤‘ë‹¨")
            return False
        
        # 6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        test_query = "ê¸ˆìœµ AI ì‹œìŠ¤í…œì˜ ë³´ì•ˆì„ ìœ„í•´ ì–´ë–¤ ì¡°ì¹˜ê°€ í•„ìš”í•œê°€?"
        search_results = self.validate_hybrid_search(embedder, faiss_index, bm25, chunks)
        if not search_results:
            print("\nâš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨ë¡œ ê²€ì¦ ì¤‘ë‹¨")
            return False
        
        # 7. LLM ë‹µë³€ ìƒì„±
        contexts = [doc for doc, score in search_results]
        answer = self.validate_qwen_llm(test_query, contexts)
        
        total_time = time.time() - start_time
        
        # ìµœì¢… ê²°ê³¼
        print("\n" + "â–ˆ"*80)
        print(" ê²€ì¦ ê²°ê³¼ ìš”ì•½")
        print("â–ˆ"*80)
        
        success_count = sum(1 for r in self.results.values() if r.get('success', False))
        total_count = len(self.results)
        
        print(f"\nì„±ê³µ: {success_count}/{total_count} ì»´í¬ë„ŒíŠ¸")
        
        for component, result in self.results.items():
            status = "âœ…" if result.get('success', False) else "âŒ"
            print(f"  {status} {component}")
        
        if self.errors:
            print(f"\nì˜¤ë¥˜ ëª©ë¡:")
            for error in self.errors:
                print(f"  - {error}")
        
        print(f"\nì´ ê²€ì¦ ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()
        
        return success_count == total_count
    
    def save_results(self):
        """ê²€ì¦ ê²°ê³¼ ì €ì¥"""
        output_dir = Path("rag_results")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"validation_{timestamp}.json"
        
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ íƒ€ì… ë³€í™˜
        def convert_to_serializable(obj):
            if isinstance(obj, np.float32):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_serializable(item) for item in obj]
            return obj
        
        report = {
            'timestamp': timestamp,
            'results': convert_to_serializable(self.results),
            'errors': self.errors,
            'success': all(r.get('success', False) for r in self.results.values())
        }
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nê²°ê³¼ ì €ì¥: {output_file}")


def test_multiple_questions():
    """ì—¬ëŸ¬ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*80)
    print(" ì¶”ê°€ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
    from packages.preprocessing.embedder_e5 import E5Embedder
    from packages.retrieval.bm25_retriever import BM25Retriever
    import faiss
    
    index_dir = Path("data/e5_embeddings/latest")
    if not index_dir.exists():
        print("ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # ì»´í¬ë„ŒíŠ¸ ë¡œë“œ
    embedder = E5Embedder()
    index = faiss.read_index(str(index_dir / "faiss_index.bin"))
    
    with open(index_dir / "chunks.json", "r", encoding="utf-8") as f:
        chunks_data = json.load(f)
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "AI ëª¨ë¸ì˜ ì ëŒ€ì  ê³µê²©ì´ë€?",
        "ì±—ë´‡ ì„œë¹„ìŠ¤ì˜ ë³´ì•ˆ ì ê²€ í•­ëª©ì€?",
        "AI í•™ìŠµ ë°ì´í„° ê´€ë¦¬ ë°©ë²•ì€?",
        "ê¸ˆìœµ AI ì‹œìŠ¤í…œì˜ ê·œì œ ìš”êµ¬ì‚¬í•­ì€?"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\nì§ˆë¬¸ {i}: {question}")
        
        # ê²€ìƒ‰
        query_embedding = embedder.encode([question], is_query=True)
        D, I = index.search(query_embedding.astype('float32'), k=3)
        
        print(f"  ìµœê³  ìœ ì‚¬ë„: {D[0][0]:.4f}")
        if I[0][0] < len(chunks_data):
            print(f"  ê´€ë ¨ ë‚´ìš©: {chunks_data[I[0][0]]['content'][:100]}...")


if __name__ == "__main__":
    # ë©”ì¸ ê²€ì¦ ì‹¤í–‰
    validator = CompleteRAGValidator()
    success = validator.run_complete_validation()
    
    if success:
        print("\n" + "ğŸ‰"*20)
        print(" ëª¨ë“  RAG ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")
        print("ğŸ‰"*20)
        
        # ì¶”ê°€ í…ŒìŠ¤íŠ¸
        response = input("\nì¶”ê°€ ì§ˆë¬¸ì„ í…ŒìŠ¤íŠ¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() == 'y':
            test_multiple_questions()
    else:
        print("\nâš ï¸ ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")