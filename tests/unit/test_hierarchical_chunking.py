#!/usr/bin/env python3
"""
HierarchicalMarkdownChunker ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

ê³„ì¸µì  ë§ˆí¬ë‹¤ìš´ ì²­í‚¹ ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ëŠ¥ ê²€ì¦:
- ë§ˆí¬ë‹¤ìš´ êµ¬ì¡° íŒŒì‹±
- ê³„ì¸µë³„ ì²­í¬ í¬ê¸°/ì˜¤ë²„ë©
- í˜ì´ì§€ ê²½ê³„ ë§ˆì»¤ ì²˜ë¦¬
- DocumentChunk í˜¸í™˜ì„±
- ë©”íƒ€ë°ì´í„° ìƒì„±
"""

import unittest
import sys
import os
from pathlib import Path
from typing import List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from packages.preprocessing.hierarchical_chunker import HierarchicalMarkdownChunker
    from packages.preprocessing.chunker import DocumentChunk
    HIERARCHICAL_CHUNKER_AVAILABLE = True
except ImportError as e:
    print(f"Warning: HierarchicalMarkdownChunker not available: {e}")
    HIERARCHICAL_CHUNKER_AVAILABLE = False


class TestHierarchicalMarkdownChunker(unittest.TestCase):
    """HierarchicalMarkdownChunker ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì¤€ë¹„"""
        if not HIERARCHICAL_CHUNKER_AVAILABLE:
            self.skipTest("HierarchicalMarkdownChunker not available")
        
        self.chunker = HierarchicalMarkdownChunker()
        
        # í…ŒìŠ¤íŠ¸ìš© ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ
        self.test_markdown = """
# ê¸ˆìœµë³´ì•ˆ ê°€ì´ë“œë¼ì¸

## ì œ1ì¥ ì´ì¹™

### ì œ1ì¡° (ëª©ì )
ì´ ê°€ì´ë“œë¼ì¸ì€ ê¸ˆìœµê¸°ê´€ì˜ ì •ë³´ë³´í˜¸ ë° ì‚¬ì´ë²„ë³´ì•ˆ ê°•í™”ë¥¼ ìœ„í•œ ê¸°ë³¸ ì›ì¹™ê³¼ ì„¸ë¶€ ì‹¤í–‰ë°©ì•ˆì„ ì œì‹œí•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.

ê¸ˆìœµë¶„ì•¼ì—ì„œ ë””ì§€í„¸ ì „í™˜ì´ ê°€ì†í™”ë˜ë©´ì„œ ì‚¬ì´ë²„ ë³´ì•ˆì˜ ì¤‘ìš”ì„±ì´ ë”ìš± ì»¤ì§€ê³  ìˆë‹¤.

### ì œ2ì¡° (ì •ì˜)
1. "ê¸ˆìœµê¸°ê´€"ì´ë€ ì€í–‰ë²•ì— ë”°ë¥¸ ì€í–‰, ê¸ˆìœµì§€ì£¼íšŒì‚¬ë²•ì— ë”°ë¥¸ ê¸ˆìœµì§€ì£¼íšŒì‚¬ë¥¼ ë§í•œë‹¤.
2. "ì‚¬ì´ë²„ ìœ„í˜‘"ì´ë€ ì •ë³´í†µì‹ ë§ì„ í†µí•˜ì—¬ ê¸ˆìœµê¸°ê´€ì˜ ì •ë³´ìì‚°ì— í”¼í•´ë¥¼ ì¤„ ìˆ˜ ìˆëŠ” ëª¨ë“  í–‰ìœ„ë¥¼ ë§í•œë‹¤.
3. "ì •ë³´ë³´í˜¸"ë€ ì •ë³´ì˜ ìˆ˜ì§‘, ê°€ê³µ, ì €ì¥, ê²€ìƒ‰, ì†¡ì‹ , ìˆ˜ì‹  ì¤‘ì— ì •ë³´ì˜ í›¼ì†, ë³€ì¡°, ìœ ì¶œ ë“±ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê´€ë¦¬ì , ê¸°ìˆ ì , ë¬¼ë¦¬ì  ì¡°ì¹˜ë¥¼ ë§í•œë‹¤.

[ë‹¤ìŒ í˜ì´ì§€ì— ê³„ì†]

[ì´ì „ í˜ì´ì§€ì—ì„œ ê³„ì†]

## ì œ2ì¥ ë³´ì•ˆ ìš”êµ¬ì‚¬í•­

### ì œ3ì¡° (ì ‘ê·¼í†µì œ)

ëª¨ë“  ì‹œìŠ¤í…œ ì ‘ê·¼ì€ ë‹¤ìŒê³¼ ê°™ì€ í†µì œ ì ˆì°¨ë¥¼ ê±°ì³ì•¼ í•œë‹¤:

| êµ¬ë¶„ | ìš”êµ¬ì‚¬í•­ | ì¤‘ìš”ë„ |
|------|----------|--------|
| ì¸ì¦ | ë‹¤ìš”ì†Œ ì¸ì¦ í•„ìˆ˜ | ë†’ìŒ |
| ê¶Œí•œ | ìµœì†Œ ê¶Œí•œ ì›ì¹™ | ë†’ìŒ |
| ëª¨ë‹ˆí„°ë§ | ì‹¤ì‹œê°„ ê°ì‹œ | ì¤‘ê°„ |

#### ì„¸ë¶€ ê·œì •
- ëª¨ë“  ì‹œìŠ¤í…œ ì ‘ê·¼ì€ ë¡œê·¸ë¥¼ ë‚¨ê²¨ì•¼ í•œë‹¤
- ë¹„ì •ìƒ ì ‘ê·¼ ì‹œë„ëŠ” ì¦‰ì‹œ ì°¨ë‹¨í•œë‹¤
- ê¶Œí•œ ë³€ê²½ì€ ìŠ¹ì¸ ì ˆì°¨ë¥¼ ê±°ì³ì•¼ í•œë‹¤

**ì¤‘ìš”**: 2024ë…„ 1ì›” 1ì¼ë¶€í„° ëª¨ë“  ê¸ˆìœµê¸°ê´€ì€ ì œë¡œíŠ¸ëŸ¬ìŠ¤íŠ¸ ë³´ì•ˆ ëª¨ë¸ì„ ì ìš©í•´ì•¼ í•œë‹¤.
""".strip()

    def test_chunker_initialization(self):
        """ì²­í‚¹ê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        self.assertIsInstance(self.chunker, HierarchicalMarkdownChunker)
        
        # ê³„ì¸µ ì„¤ì • í™•ì¸
        self.assertIn(1, self.chunker.hierarchy_configs)
        self.assertIn(2, self.chunker.hierarchy_configs)
        self.assertIn(3, self.chunker.hierarchy_configs)
        
        # ê° ë ˆë²¨ë³„ ì„¤ì • í™•ì¸
        level_1 = self.chunker.hierarchy_configs[1]
        self.assertEqual(level_1.chunk_size, 1024)
        self.assertEqual(level_1.chunk_overlap, 100)
        
        level_2 = self.chunker.hierarchy_configs[2]
        self.assertEqual(level_2.chunk_size, 512)
        self.assertEqual(level_2.chunk_overlap, 50)
        
        level_3 = self.chunker.hierarchy_configs[3]
        self.assertEqual(level_3.chunk_size, 256)
        self.assertEqual(level_3.chunk_overlap, 30)

    def test_page_boundary_merging(self):
        """í˜ì´ì§€ ê²½ê³„ ë§ˆì»¤ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # í˜ì´ì§€ ë§ˆì»¤ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸
        text_with_markers = """
        ì²« ë²ˆì§¸ ë¬¸ë‹¨ì…ë‹ˆë‹¤.
        
        [ë‹¤ìŒ í˜ì´ì§€ì— ê³„ì†]
        
        [ì´ì „ í˜ì´ì§€ì—ì„œ ê³„ì†]
        
        ë‘ ë²ˆì§¸ ë¬¸ë‹¨ì…ë‹ˆë‹¤.
        """
        
        processed = self.chunker._merge_page_boundaries(text_with_markers)
        
        # í˜ì´ì§€ ë§ˆì»¤ê°€ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
        self.assertNotIn('[ë‹¤ìŒ í˜ì´ì§€ì— ê³„ì†]', processed)
        self.assertNotIn('[ì´ì „ í˜ì´ì§€ì—ì„œ ê³„ì†]', processed)
        
        # ë‚´ìš©ì€ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸
        self.assertIn('ì²« ë²ˆì§¸ ë¬¸ë‹¨', processed)
        self.assertIn('ë‘ ë²ˆì§¸ ë¬¸ë‹¨', processed)

    def test_header_level_detection(self):
        """í—¤ë” ë ˆë²¨ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        # ë‹¤ì–‘í•œ í—¤ë” ë ˆë²¨ í…ŒìŠ¤íŠ¸
        test_cases = [
            ({'h1': 'Title'}, 1),
            ({'h2': 'Section'}, 2),
            ({'h3': 'Subsection'}, 3),
            ({'h4': 'Sub-subsection'}, 4),
            ({}, 2),  # í—¤ë” ì—†ìŒ -> ê¸°ë³¸ ë ˆë²¨ 2
            ({'h1': 'Title', 'h2': 'Section'}, 1),  # ì—¬ëŸ¬ í—¤ë” -> ê°€ì¥ ë†’ì€ ë ˆë²¨
        ]
        
        for metadata, expected_level in test_cases:
            level = self.chunker._detect_header_level(metadata)
            self.assertEqual(level, expected_level, f"Failed for metadata: {metadata}")

    def test_hierarchy_path_building(self):
        """ê³„ì¸µ ê²½ë¡œ ìƒì„± í…ŒìŠ¤íŠ¸"""
        test_cases = [
            ({}, "Root"),
            ({'h1': 'Chapter 1'}, "Chapter 1"),
            ({'h1': 'Chapter 1', 'h2': 'Section 1.1'}, "Chapter 1 > Section 1.1"),
            ({'h1': 'A', 'h2': 'B', 'h3': 'C'}, "A > B > C"),
        ]
        
        for metadata, expected_path in test_cases:
            path = self.chunker._build_hierarchy_path(metadata)
            self.assertEqual(path, expected_path)

    def test_chunk_creation_with_overlap(self):
        """ì˜¤ë²„ë©ì„ í¬í•¨í•œ ì²­í‚¹ í…ŒìŠ¤íŠ¸"""
        test_text = "ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. " * 50  # ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸
        
        config = self.chunker.hierarchy_configs[2]  # ë ˆë²¨ 2 ì„¤ì • (512/50)
        chunks = self.chunker._create_chunks_with_overlap(test_text, config)
        
        self.assertGreater(len(chunks), 1, "ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• ë˜ì–´ì•¼ í•¨")
        
        # ê° ì²­í¬ í¬ê¸° í™•ì¸
        for chunk in chunks:
            self.assertLessEqual(len(chunk), config.chunk_size + 50, "ì²­í¬ê°€ ë„ˆë¬´ í¼")
            self.assertGreater(len(chunk.strip()), 0, "ë¹ˆ ì²­í¬ê°€ ìƒì„±ë¨")

    def test_document_chunking(self):
        """ì „ì²´ ë¬¸ì„œ ì²­í‚¹ í…ŒìŠ¤íŠ¸"""
        chunks = self.chunker.chunk_document(self.test_markdown)
        
        # ê¸°ë³¸ ê²€ì¦
        self.assertIsInstance(chunks, list)
        self.assertGreater(len(chunks), 0, "ì²­í¬ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        
        # ëª¨ë“  ì²­í¬ê°€ DocumentChunk ì¸ìŠ¤í„´ìŠ¤ì¸ì§€ í™•ì¸
        for chunk in chunks:
            self.assertIsInstance(chunk, DocumentChunk)
            self.assertIsInstance(chunk.content, str)
            self.assertIsInstance(chunk.metadata, dict)
            self.assertIsInstance(chunk.chunk_id, str)
            self.assertIsInstance(chunk.doc_id, str)
            self.assertIsInstance(chunk.chunk_index, int)

    def test_chunk_metadata(self):
        """ì²­í¬ ë©”íƒ€ë°ì´í„° ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        chunks = self.chunker.chunk_document(
            self.test_markdown, 
            metadata={'source': 'test_document'}
        )
        
        for chunk in chunks:
            metadata = chunk.metadata
            
            # í•„ìˆ˜ ë©”íƒ€ë°ì´í„° í™•ì¸
            self.assertIn('hierarchy_level', metadata)
            self.assertIn('hierarchy_path', metadata)
            self.assertIn('chunking_method', metadata)
            self.assertIn('chunk_size', metadata)
            self.assertIn('chunk_overlap', metadata)
            self.assertIn('content_length', metadata)
            self.assertIn('processed_boundaries', metadata)
            
            # ê°’ íƒ€ì… í™•ì¸
            self.assertIsInstance(metadata['hierarchy_level'], int)
            self.assertIsInstance(metadata['hierarchy_path'], str)
            self.assertEqual(metadata['chunking_method'], 'hierarchical_markdown')
            self.assertIsInstance(metadata['chunk_size'], int)
            self.assertIsInstance(metadata['chunk_overlap'], int)
            self.assertEqual(metadata['content_length'], len(chunk.content))
            self.assertTrue(metadata['processed_boundaries'])
            
            # ì‚¬ìš©ì ì œê³µ ë©”íƒ€ë°ì´í„° í™•ì¸
            self.assertEqual(metadata['source'], 'test_document')

    def test_page_boundary_removal(self):
        """í˜ì´ì§€ ê²½ê³„ ë§ˆì»¤ ì™„ì „ ì œê±° í™•ì¸"""
        chunks = self.chunker.chunk_document(self.test_markdown)
        
        # ëª¨ë“  ì²­í¬ì—ì„œ í˜ì´ì§€ ë§ˆì»¤ê°€ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
        for chunk in chunks:
            self.assertNotIn('[ë‹¤ìŒ í˜ì´ì§€ì— ê³„ì†]', chunk.content)
            self.assertNotIn('[ì´ì „ í˜ì´ì§€ì—ì„œ ê³„ì†]', chunk.content)

    def test_hierarchy_stats(self):
        """ê³„ì¸µ í†µê³„ ì •ë³´ í…ŒìŠ¤íŠ¸"""
        chunks = self.chunker.chunk_document(self.test_markdown)
        stats = self.chunker.get_hierarchy_stats(chunks)
        
        # í†µê³„ êµ¬ì¡° í™•ì¸
        self.assertIsInstance(stats, dict)
        self.assertIn('total_chunks', stats)
        self.assertIn('by_level', stats)
        self.assertIn('avg_chunk_size', stats)
        self.assertIn('hierarchy_paths', stats)
        
        # ê°’ í™•ì¸
        self.assertEqual(stats['total_chunks'], len(chunks))
        self.assertGreater(stats['avg_chunk_size'], 0)
        self.assertIsInstance(stats['hierarchy_paths'], list)
        
        # ë ˆë²¨ë³„ í†µê³„ í™•ì¸
        for level, level_stats in stats['by_level'].items():
            self.assertIsInstance(level, int)
            self.assertIn('count', level_stats)
            self.assertIn('avg_size', level_stats)
            self.assertGreater(level_stats['count'], 0)
            self.assertGreater(level_stats['avg_size'], 0)

    def test_empty_document(self):
        """ë¹ˆ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        empty_chunks = self.chunker.chunk_document("")
        self.assertEqual(len(empty_chunks), 0)
        
        whitespace_chunks = self.chunker.chunk_document("   \n\n  \t  ")
        self.assertEqual(len(whitespace_chunks), 0)

    def test_no_header_document(self):
        """í—¤ë” ì—†ëŠ” ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        no_header_text = """
        ì´ê²ƒì€ ë§ˆí¬ë‹¤ìš´ í—¤ë”ê°€ ì—†ëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
        ê¸ˆìœµ AI ì‹œìŠ¤í…œì˜ ë³´ì•ˆì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
        ì—¬ëŸ¬ ì¤„ì˜ í…ìŠ¤íŠ¸ê°€ ìˆì§€ë§Œ êµ¬ì¡°ê°€ ì—†ìŠµë‹ˆë‹¤.
        """
        
        chunks = self.chunker.chunk_document(no_header_text)
        
        self.assertGreater(len(chunks), 0)
        
        # ê¸°ë³¸ ë ˆë²¨(2)ì´ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
        for chunk in chunks:
            self.assertEqual(chunk.metadata['hierarchy_level'], 2)
            self.assertEqual(chunk.metadata['hierarchy_path'], 'Root')

    def test_deep_nested_structure(self):
        """ê¹Šì€ ì¤‘ì²© êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        deep_nested = """
# Level 1
## Level 2
### Level 3
#### Level 4
##### Level 5
###### Level 6
ì´ê²ƒì€ ê¹Šì€ ì¤‘ì²© êµ¬ì¡° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.
"""
        
        chunks = self.chunker.chunk_document(deep_nested)
        
        # ë ˆë²¨ 4ê¹Œì§€ë§Œ ì§€ì›í•˜ë¯€ë¡œ ìµœëŒ€ ë ˆë²¨ 4ì—¬ì•¼ í•¨
        for chunk in chunks:
            level = chunk.metadata['hierarchy_level']
            self.assertLessEqual(level, 4, f"Level {level} exceeds maximum supported level")

    def test_special_characters(self):
        """íŠ¹ìˆ˜ ë¬¸ì í¬í•¨ ë¬¸ì„œ í…ŒìŠ¤íŠ¸"""
        special_text = """
# íŠ¹ìˆ˜ ë¬¸ì í…ŒìŠ¤íŠ¸

## ì½”ë“œ ì˜ˆì œ

```python
def secure_ai_model():
    config = {"encryption": True}
    return config
```

## ìˆ˜ì‹ ì˜ˆì œ

A = alpha x beta + gamma

**êµµì€ í…ìŠ¤íŠ¸**ì™€ *ê¸°ìš¸ì„ í…ìŠ¤íŠ¸*ë„ í¬í•¨
"""
        
        chunks = self.chunker.chunk_document(special_text)
        
        # íŠ¹ìˆ˜ ë¬¸ìê°€ í¬í•¨ëœ ì²­í¬ê°€ ì •ìƒ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸
        self.assertGreater(len(chunks), 0)
        
        # ì½”ë“œ ë¸”ë¡ì´ë‚˜ íŠ¹ìˆ˜ ë¬¸ìê°€ ê¹¨ì§€ì§€ ì•ŠëŠ”ì§€ í™•ì¸
        content = ''.join(chunk.content for chunk in chunks)
        self.assertIn('```python', content)
        self.assertIn('alpha x beta', content)
        self.assertIn('**êµµì€ í…ìŠ¤íŠ¸**', content)

    def test_chunk_id_generation(self):
        """ì²­í¬ ID ìƒì„± í…ŒìŠ¤íŠ¸"""
        chunks = self.chunker.chunk_document(self.test_markdown)
        
        # ëª¨ë“  ì²­í¬ IDê°€ ìœ ë‹ˆí¬í•œì§€ í™•ì¸
        chunk_ids = [chunk.chunk_id for chunk in chunks]
        self.assertEqual(len(chunk_ids), len(set(chunk_ids)), "ì¤‘ë³µëœ ì²­í¬ ID ë°œê²¬")
        
        # ì²­í¬ ID í˜•ì‹ í™•ì¸ (16ì í•´ì‹œ)
        for chunk_id in chunk_ids:
            self.assertIsInstance(chunk_id, str)
            self.assertEqual(len(chunk_id), 16)

    def test_batch_document_processing(self):
        """ë°°ì¹˜ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        documents = [
            {
                'content': self.test_markdown,
                'metadata': {'source': 'doc1'}
            },
            {
                'content': "# Simple Document\n\nThis is a longer content for the second document to ensure it passes the chunk cleaner minimum length requirement. This content should be sufficient to create at least one chunk after processing.",
                'metadata': {'source': 'doc2'}
            }
        ]
        
        all_chunks = self.chunker.chunk_documents(documents)
        
        # ì—¬ëŸ¬ ë¬¸ì„œì˜ ì²­í¬ê°€ ëª¨ë‘ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
        self.assertGreater(len(all_chunks), 2)
        
        # ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°ê°€ ë³´ì¡´ë˜ì—ˆëŠ”ì§€ í™•ì¸
        sources = [chunk.metadata.get('source') for chunk in all_chunks]
        self.assertIn('doc1', sources)
        self.assertIn('doc2', sources)


class TestHierarchicalChunkerEdgeCases(unittest.TestCase):
    """HierarchicalMarkdownChunker ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì¤€ë¹„"""
        if not HIERARCHICAL_CHUNKER_AVAILABLE:
            self.skipTest("HierarchicalMarkdownChunker not available")
        
        self.chunker = HierarchicalMarkdownChunker()

    def test_malformed_markdown(self):
        """ì˜ëª»ëœ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì²˜ë¦¬"""
        malformed_text = """
        # ì •ìƒ í—¤ë”
        
        ## ì •ìƒ ì„¹ì…˜
        
        ###ì˜ëª»ëœí—¤ë”(ê³µë°±ì—†ìŒ)
        
        ####    ë„ˆë¬´ë§ì€ê³µë°±    ####
        
        ì¼ë°˜ í…ìŠ¤íŠ¸
        """
        
        # ì˜ˆì™¸ ë°œìƒ ì—†ì´ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
        chunks = self.chunker.chunk_document(malformed_text)
        self.assertIsInstance(chunks, list)

    def test_very_long_headers(self):
        """ë§¤ìš° ê¸´ í—¤ë” ì²˜ë¦¬"""
        long_header = "ì´ê²ƒì€ ë§¤ìš° ê¸´ í—¤ë”ì…ë‹ˆë‹¤ " * 20
        long_text = f"# {long_header}\n\në‚´ìš©ì…ë‹ˆë‹¤."
        
        chunks = self.chunker.chunk_document(long_text)
        
        # í—¤ë”ê°€ ë©”íƒ€ë°ì´í„°ì— ì˜¬ë°”ë¥´ê²Œ ì €ì¥ë˜ëŠ”ì§€ í™•ì¸
        for chunk in chunks:
            if chunk.metadata.get('parent_header'):
                self.assertIn('ë§¤ìš° ê¸´ í—¤ë”', chunk.metadata['parent_header'])

    def test_unicode_content(self):
        """ìœ ë‹ˆì½”ë“œ ì½˜í…ì¸  ì²˜ë¦¬"""
        unicode_text = """
# í•œêµ­ì–´ ì œëª©

## ì„¹ì…˜ ğŸ”’

ë‹¤ì–‘í•œ ì–¸ì–´: English, í•œêµ­ì–´, æ—¥æœ¬èª, ä¸­æ–‡

íŠ¹ìˆ˜ê¸°í˜¸: âš¡ âœ… âŒ ğŸ¯ ğŸ“Š
"""
        
        chunks = self.chunker.chunk_document(unicode_text)
        
        # ìœ ë‹ˆì½”ë“œê°€ ì˜¬ë°”ë¥´ê²Œ ë³´ì¡´ë˜ëŠ”ì§€ í™•ì¸
        content = ''.join(chunk.content for chunk in chunks)
        self.assertIn('ğŸ”’', content)
        self.assertIn('æ—¥æœ¬èª', content)
        self.assertIn('âš¡', content)

    def test_chunk_cleaner_disabled(self):
        """ChunkCleaner ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸"""
        chunker_no_cleaner = HierarchicalMarkdownChunker(use_chunk_cleaner=False)
        
        test_text = "# Test\n\n   \n\në‚´ìš©"
        chunks = chunker_no_cleaner.chunk_document(test_text)
        
        # ChunkCleaner ì—†ì´ë„ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
        self.assertGreater(len(chunks), 0)


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì „ í™˜ê²½ í™•ì¸
    if HIERARCHICAL_CHUNKER_AVAILABLE:
        print("HierarchicalMarkdownChunker available - running all tests")
    else:
        print("HierarchicalMarkdownChunker not available - skipping tests")
    
    unittest.main(verbosity=2)