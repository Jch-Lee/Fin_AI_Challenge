당신은 금융 보안 전문가입니다. 주어진 컨텍스트를 바탕으로 질문에 답변해주세요.

=== 관련 컨텍스트 ===
[문서 1]
제1장. 가이드라인 개요●●● AI 보안의 중요성은 날로 커지고 있으며, AI의 보안성을 확보하기 위한 국내･외 다양한 정책이 발표되었다. 참고 국내･외 AI 보안 관련 주요 정책 국가 주요 정책 EU ∙ 인공지능 규제 샌드박스 발표(’22.6월) ∙ AI 규제법안(’21.4월) 미국 ∙ 디지털 플랫폼 위원회법 발의(’22.5월) ∙ 미국 데이터 프라이버시와 보호 법(’22.5월) 한국 ∙ 금융권 인공지능(AI) 활용 활성화 및 신뢰확보 방안(’22.7월, 금융위) ∙ 신뢰할 수 있는 인공지능 실현 전략(’21.5월, 과기부) 이러한 정책은 AI의 보안성을 확보하기 위한 규제･원칙을 다루고 있으나, 실무 위주의 세부적 안내 또한 필요한 실정이다. 특히, 금융 분야는 고객의 재산과 직접적 관련이 있어 AI 보안성 확보를 위한 실무 위주의 안내가 더욱 중요하다. 본 가이드라인은 AI 실무자가 AI 보안에 대해 쉽게 이해하고 금융회사 등이 자체적으로

[문서 2]
●●●금융분야 AI 보안 가이드라인 제1장 가이드라인 개요 본 가이드라인은 금융권에서 사용하는 인공지능(AI) 서비스의 안전한 활용에 필요한 사항을 안내하여, 금융회사의 AI 활용에 있어 안전성을 높이고자 한다. 추진 배경 및 목적 최근 디지털 금융산업의 발전과 함께, 인공지능(AI)을 활용한 서비스의 도입이 확대됨에 따라 개인정보 유출 등 다양한 보안 위협이 발생하고 있다. 참고 인공지능 관련 사고 사례 구 분 특 징 ∙ AI 챗봇 ‘이루다’(’21.1.) ∙ 실명, 계좌번호, 주소 등 개인정보 유출 발생 ∙ 특정 소수자 차별 등으로 출시 1달여 만에 서비스 일시 중단 ∙ AI 헬스케어 ‘GPT-3’(’20.10.) ∙ 정신과 챗봇으로 출시전 모의 환자에게 자살 권유 ∙ AI 성별식별 ‘젠더리파이’(’20.7.) ∙ 여성, 유색인종, 노인 등 소수자 차별 ∙ MIT의 ‘사이코패스AI’(’18.6.) ∙ 연구를 통해 부정･편향된 인공지능 학습 결과, 반사회･반인륜적인 행위 증명

[문서 3]
●●●금융분야 AI 보안 가이드라인 분류 소분류 연번 보안성 체크리스트 악성코드 방지 대책 챗봇 시스템 내 악성코드에 대한 대책이 마련되어있는가? 백업/복구 절차 챗봇 시스템에 대한 백업 및 복구절차가 수립/이행되고 있는가? 패치 관리 챗봇 시스템 내 정보자산에 대한 패치 관리정책 및 절차가 적절히 수립(e.g., 인터넷 직접 접속을 통한 패치가 제한 등)되어 이행되는가? 침해사고 대응 챗봇서비스 관련 침해사고 대응 절차를 수립하여 이행하는가? 위험관리 AI를 활용한 챗봇서비스를 구축하는 경우, 이용자에게 잠재적 으로 미칠 위험을 평가하고, 이를 관리하기 위한 위험관리 정책을 수립 이행하는가? 외부자 계약 챗봇서비스 제공자와 같은 외부자와 계약 체결 시 정보보호 요구사항을 식별하고, 관련 내용을 계약서에 명시하여 그 이행 여부를 주기적으로 관리하는가? 정보자산 식별 챗봇 서비스 관련 주요 정보자산(e.g., 관리 시스템, 인프라 등)을

[문서 4]
●●●금융분야 AI 보안 가이드라인 제2장 AI 서비스 구성 본 장에서는 보안 관점에서 AI 서비스의 구성요소와 각 기능에 대해서 안내한다. AI 서비스 구성 AI 서비스를 원활히 운영하기 위해서는 이용자의 채널(메시지 입력), AI 엔진(AI 모델 작동) 등 다양한 구성 요소가 필요하다. 아래 구성도와 같이, AI 서비스의 구성 요소에 대해서 개념적으로 표현할 수 있으며, 각 요소에 대해 안내한다. ※ 서비스 목적･기능, 금융회사 등의 환경에 따라 기능 및 세부설계가 다를 수 있음 [ AI 서비스 구성도 ]


=== 질문 ===
금융 AI 시스템의 보안을 위해 어떤 조치들이 필요한가요?

=== 답변 ===
