"""
RAG ì‹œìŠ¤í…œ ì „ì²´ í…ŒìŠ¤íŠ¸ ë° ì¤‘ê°„ ê³¼ì • ë¡œê¹…
ëª¨ë“  ë‹¨ê³„ì˜ ì¶œë ¥ì„ ìƒì„¸íˆ ê¸°ë¡í•˜ì—¬ ì‹œìŠ¤í…œ ì‘ë™ í™•ì¸
"""

import sys
import io
import time
import json
import torch
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

# UTF-8 ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# ë¡œê¹… ì„¤ì •
log_dir = Path("logs")
log_dir.mkdir(exist_ok=True)

# ë¡œê·¸ íŒŒì¼ ì„¤ì •
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = log_dir / f"rag_test_{timestamp}.log"

# ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ë¡œê¹…
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

# ì‹œìŠ¤í…œ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from packages.rag import create_rag_pipeline
from packages.rag.reranking import get_default_config


class RAGSystemTester:
    """RAG ì‹œìŠ¤í…œ í…ŒìŠ¤í„° - ëª¨ë“  ì¤‘ê°„ ê³¼ì • ê¸°ë¡"""
    
    def __init__(self, enable_reranking: bool = True):
        self.enable_reranking = enable_reranking
        self.pipeline = None
        self.test_results = {
            "timestamp": timestamp,
            "system_info": {},
            "pipeline_config": {},
            "test_cases": [],
            "performance_metrics": {}
        }
    
    def log_section(self, title: str, char: str = "="):
        """ì„¹ì…˜ êµ¬ë¶„ì„  ë¡œê¹…"""
        line = char * 60
        logger.info(f"\n{line}")
        logger.info(f"{title}")
        logger.info(f"{line}")
    
    def check_system(self):
        """ì‹œìŠ¤í…œ í™˜ê²½ ì²´í¬"""
        self.log_section("1. ì‹œìŠ¤í…œ í™˜ê²½ ì²´í¬")
        
        # GPU ì •ë³´
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            logger.info(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {gpu_name}")
            logger.info(f"   VRAM: {gpu_memory:.2f} GB")
            device = "cuda"
        else:
            logger.info("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€ - CPU ëª¨ë“œ")
            device = "cpu"
        
        # Python ë²„ì „
        logger.info(f"Python ë²„ì „: {sys.version}")
        
        # PyTorch ë²„ì „
        logger.info(f"PyTorch ë²„ì „: {torch.__version__}")
        
        self.test_results["system_info"] = {
            "device": device,
            "gpu_name": gpu_name if device == "cuda" else None,
            "gpu_memory_gb": gpu_memory if device == "cuda" else None,
            "python_version": sys.version,
            "pytorch_version": torch.__version__
        }
        
        return device
    
    def initialize_pipeline(self, device: str):
        """RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.log_section("2. RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”")
        
        try:
            logger.info("íŒŒì´í”„ë¼ì¸ êµ¬ì„± ì¤‘...")
            
            # Reranker ì„¤ì •
            reranker_config = None
            if self.enable_reranking:
                logger.info("  - Reranking í™œì„±í™”")
                reranker_config = get_default_config("qwen3")
                reranker_config.device = device
                logger.info(f"  - Reranker ëª¨ë¸: {reranker_config.model_name}")
            
            # íŒŒì´í”„ë¼ì¸ ìƒì„±
            start_time = time.time()
            self.pipeline = create_rag_pipeline(
                embedder_type="kure",
                retriever_type="hybrid",
                device=device,
                enable_reranking=self.enable_reranking,
                reranker_config=reranker_config
            )
            init_time = time.time() - start_time
            
            logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {init_time:.2f}ì´ˆ)")
            
            # íŒŒì´í”„ë¼ì¸ ì„¤ì • ê¸°ë¡
            stats = self.pipeline.get_statistics()
            logger.info(f"íŒŒì´í”„ë¼ì¸ êµ¬ì„±:")
            logger.info(f"  - Embedder: {stats['embedder_model']}")
            logger.info(f"  - Embedding ì°¨ì›: {stats['embedding_dim']}")
            logger.info(f"  - Retriever: {stats['retriever_type']}")
            logger.info(f"  - Reranking: {'í™œì„±í™”' if stats['reranking_enabled'] else 'ë¹„í™œì„±í™”'}")
            
            self.test_results["pipeline_config"] = stats
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def add_test_documents(self):
        """í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¶”ê°€"""
        self.log_section("3. í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¶”ê°€")
        
        # ê¸ˆìœµ ë³´ì•ˆ ê´€ë ¨ í…ŒìŠ¤íŠ¸ ë¬¸ì„œë“¤
        documents = [
            # ì‚¬ì´ë²„ ë³´ì•ˆ ê´€ë ¨
            "ê¸ˆìœµ ê¸°ê´€ì˜ ì‚¬ì´ë²„ ë³´ì•ˆì€ ë‹¤ì¸µ ë°©ì–´ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤. ë°©í™”ë²½, ì¹¨ì… íƒì§€ ì‹œìŠ¤í…œ, ì—”ë“œí¬ì¸íŠ¸ ë³´ì•ˆ ì†”ë£¨ì…˜ì„ ì¢…í•©ì ìœ¼ë¡œ ìš´ì˜í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ê¸ˆìœµë³´ì•ˆì›ì€ 24ì‹œê°„ ì‚¬ì´ë²„ ìœ„í˜‘ ëª¨ë‹ˆí„°ë§ ì²´ê³„ë¥¼ ìš´ì˜í•˜ë©°, ì´ìƒ ì§•í›„ ë°œê²¬ ì‹œ ì¦‰ì‹œ ëŒ€ì‘ í”„ë¡œí† ì½œì„ ê°€ë™í•©ë‹ˆë‹¤.",
            "ëœì„¬ì›¨ì–´ ê³µê²©ì— ëŒ€ë¹„í•˜ì—¬ ê¸ˆìœµ ê¸°ê´€ì€ ì •ê¸°ì ì¸ ë°±ì—…ê³¼ ë³µêµ¬ í›ˆë ¨ì„ ì‹¤ì‹œí•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ì§ì› ëŒ€ìƒ í”¼ì‹± ë©”ì¼ ëŒ€ì‘ êµìœ¡ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.",
            
            # ê·œì œ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤
            "ê¸ˆìœµìœ„ì›íšŒëŠ” ì „ìê¸ˆìœµê±°ë˜ë²•ì— ë”°ë¼ ê¸ˆìœµíšŒì‚¬ì˜ IT ë³´ì•ˆ ìˆ˜ì¤€ì„ ì •ê¸°ì ìœ¼ë¡œ ì ê²€í•©ë‹ˆë‹¤. ìœ„ë°˜ ì‹œ ê³¼íƒœë£Œê°€ ë¶€ê³¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ê°œì¸ì •ë³´ë³´í˜¸ë²•ê³¼ ì‹ ìš©ì •ë³´ë²•ì— ë”°ë¼ ê³ ê° ê¸ˆìœµ ì •ë³´ëŠ” ì•”í˜¸í™”í•˜ì—¬ ì €ì¥í•´ì•¼ í•˜ë©°, ì ‘ê·¼ ê¶Œí•œì„ ì—„ê²©íˆ í†µì œí•´ì•¼ í•©ë‹ˆë‹¤.",
            
            # ë¦¬ìŠ¤í¬ ê´€ë¦¬
            "ìš´ì˜ ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ê¸ˆìœµ ê¸°ê´€ì€ BCP(Business Continuity Plan)ë¥¼ ìˆ˜ë¦½í•˜ê³  ì—° 2íšŒ ì´ìƒ ëª¨ì˜í›ˆë ¨ì„ ì‹¤ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.",
            "ì‹œì¥ ë¦¬ìŠ¤í¬ëŠ” VaR(Value at Risk) ëª¨ë¸ì„ í†µí•´ ì¸¡ì •í•˜ë©°, ì¼ì¼ í•œë„ë¥¼ ì„¤ì •í•˜ì—¬ ê´€ë¦¬í•©ë‹ˆë‹¤.",
            
            # í•€í…Œí¬ ë° ë””ì§€í„¸ ê¸ˆìœµ
            "ì˜¤í”ˆë±…í‚¹ API ë³´ì•ˆì„ ìœ„í•´ OAuth 2.0 ê¸°ë°˜ ì¸ì¦ê³¼ TLS 1.2 ì´ìƒì˜ ì•”í˜¸í™” í†µì‹ ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.",
            "ë¸”ë¡ì²´ì¸ ê¸°ë°˜ ê¸ˆìœµ ì„œë¹„ìŠ¤ëŠ” ìŠ¤ë§ˆíŠ¸ ì»¨íŠ¸ë™íŠ¸ ê°ì‚¬ë¥¼ í†µí•´ ë³´ì•ˆ ì·¨ì•½ì ì„ ì‚¬ì „ì— ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.",
            
            # ì¸ì¦ ë° ë³¸ì¸í™•ì¸
            "ê¸ˆìœµ ê±°ë˜ ì‹œ ë‹¤ì¤‘ ì¸ì¦(MFA)ì„ ì ìš©í•˜ì—¬ ë³´ì•ˆì„ ê°•í™”í•©ë‹ˆë‹¤. ìƒì²´ ì¸ì¦ê³¼ OTPë¥¼ ì¡°í•©í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤.",
        ]
        
        metadata = [
            {"category": "ì‚¬ì´ë²„ë³´ì•ˆ", "source": "ë³´ì•ˆê°€ì´ë“œ", "id": f"doc_{i+1}"}
            for i in range(len(documents))
        ]
        
        logger.info(f"ì¶”ê°€í•  ë¬¸ì„œ ìˆ˜: {len(documents)}")
        
        try:
            start_time = time.time()
            num_added = self.pipeline.add_documents(
                texts=documents,
                metadata=metadata,
                batch_size=8
            )
            add_time = time.time() - start_time
            
            logger.info(f"âœ… {num_added}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {add_time:.2f}ì´ˆ)")
            logger.info(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {add_time/num_added:.3f}ì´ˆ/ë¬¸ì„œ")
            
            # ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥
            kb_path = "test_knowledge_base.pkl"
            self.pipeline.save_knowledge_base(kb_path)
            logger.info(f"ğŸ’¾ ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥: {kb_path}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def test_retrieval(self, query: str, test_name: str = "Test"):
        """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ - ëª¨ë“  ì¤‘ê°„ ê³¼ì • ê¸°ë¡"""
        self.log_section(f"4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: {test_name}")
        
        test_case = {
            "name": test_name,
            "query": query,
            "stages": {},
            "timings": {},
            "results": {}
        }
        
        logger.info(f"ì§ˆë¬¸: {query}")
        logger.info("-" * 40)
        
        try:
            # Stage 1: Query Embedding
            logger.info("\n[Stage 1] ì§ˆë¬¸ ì„ë² ë”© ìƒì„±")
            start = time.time()
            query_embedding = self.pipeline.embedder.embed(query, is_query=True)
            embed_time = time.time() - start
            
            logger.info(f"  - ì„ë² ë”© ì°¨ì›: {len(query_embedding)}")
            logger.info(f"  - ì„ë² ë”© norm: {torch.norm(torch.tensor(query_embedding)):.4f}")
            logger.info(f"  - ì†Œìš” ì‹œê°„: {embed_time:.3f}ì´ˆ")
            
            test_case["stages"]["embedding"] = {
                "dimension": len(query_embedding),
                "norm": float(torch.norm(torch.tensor(query_embedding))),
                "time": embed_time
            }
            
            # Stage 2: Initial Retrieval
            logger.info("\n[Stage 2] ì´ˆê¸° ë¬¸ì„œ ê²€ìƒ‰")
            start = time.time()
            
            # ë§ì€ í›„ë³´ë¥¼ ë¨¼ì € ê²€ìƒ‰ (rerankingì„ ìœ„í•´)
            initial_k = 10 if self.enable_reranking else 5
            retrieved_docs = self.pipeline.retrieve(query, top_k=initial_k)
            retrieve_time = time.time() - start
            
            logger.info(f"  - ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}")
            logger.info(f"  - ì†Œìš” ì‹œê°„: {retrieve_time:.3f}ì´ˆ")
            
            # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
            logger.info("\n  ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼:")
            for i, doc in enumerate(retrieved_docs[:5], 1):
                score = doc.get('score', 0)
                content = doc.get('content', '')[:100]
                logger.info(f"    {i}. [ì ìˆ˜: {score:.4f}] {content}...")
            
            test_case["stages"]["retrieval"] = {
                "num_docs": len(retrieved_docs),
                "time": retrieve_time,
                "top_scores": [doc.get('score', 0) for doc in retrieved_docs[:5]]
            }
            
            # Stage 3: Reranking (if enabled)
            if self.enable_reranking and hasattr(self.pipeline, 'reranker') and self.pipeline.reranker:
                logger.info("\n[Stage 3] ë¦¬ë­í‚¹")
                start = time.time()
                
                # Rerankerë¥¼ ì§ì ‘ í˜¸ì¶œ
                reranked_docs = self.pipeline.reranker.rerank(
                    query=query,
                    documents=retrieved_docs,
                    top_k=5
                )
                rerank_time = time.time() - start
                
                logger.info(f"  - ë¦¬ë­í‚¹ í›„ ë¬¸ì„œ ìˆ˜: {len(reranked_docs)}")
                logger.info(f"  - ì†Œìš” ì‹œê°„: {rerank_time:.3f}ì´ˆ")
                
                # ë¦¬ë­í‚¹ ê²°ê³¼ ì¶œë ¥
                logger.info("\n  ë¦¬ë­í‚¹ ê²°ê³¼:")
                for i, doc in enumerate(reranked_docs, 1):
                    rerank_score = doc.get('rerank_score', 0)
                    original_score = doc.get('score', 0)
                    content = doc.get('content', '')[:100]
                    logger.info(f"    {i}. [ë¦¬ë­í‚¹: {rerank_score:.4f}, ì›ë³¸: {original_score:.4f}]")
                    logger.info(f"       {content}...")
                
                test_case["stages"]["reranking"] = {
                    "num_docs": len(reranked_docs),
                    "time": rerank_time,
                    "score_changes": [
                        {
                            "original": doc.get('score', 0),
                            "reranked": doc.get('rerank_score', 0)
                        }
                        for doc in reranked_docs
                    ]
                }
                
                final_docs = reranked_docs
            else:
                final_docs = retrieved_docs[:5]
            
            # Stage 4: Context Generation
            logger.info("\n[Stage 4] ì»¨í…ìŠ¤íŠ¸ ìƒì„±")
            start = time.time()
            context = self.pipeline.generate_context(query, top_k=5, max_length=2000)
            context_time = time.time() - start
            
            logger.info(f"  - ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)} ë¬¸ì")
            logger.info(f"  - ì†Œìš” ì‹œê°„: {context_time:.3f}ì´ˆ")
            logger.info("\n  ìƒì„±ëœ ì»¨í…ìŠ¤íŠ¸ (ì²« 500ì):")
            logger.info(f"    {context[:500]}...")
            
            test_case["stages"]["context"] = {
                "length": len(context),
                "time": context_time
            }
            
            # ì „ì²´ ì‹œê°„ ê³„ì‚°
            total_time = embed_time + retrieve_time
            if self.enable_reranking:
                total_time += rerank_time
            total_time += context_time
            
            logger.info(f"\nâ±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.3f}ì´ˆ")
            
            test_case["timings"] = {
                "embedding": embed_time,
                "retrieval": retrieve_time,
                "reranking": rerank_time if self.enable_reranking else 0,
                "context": context_time,
                "total": total_time
            }
            
            test_case["results"]["success"] = True
            test_case["results"]["final_docs"] = len(final_docs)
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            test_case["results"]["success"] = False
            test_case["results"]["error"] = str(e)
        
        self.test_results["test_cases"].append(test_case)
        return test_case
    
    def run_test_suite(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰"""
        self.log_section("RAG ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘", "=")
        
        # 1. ì‹œìŠ¤í…œ ì²´í¬
        device = self.check_system()
        
        # 2. íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        if not self.initialize_pipeline(device):
            logger.error("íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
            return False
        
        # 3. ë¬¸ì„œ ì¶”ê°€
        if not self.add_test_documents():
            logger.error("ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
            return False
        
        # 4. ë‹¤ì–‘í•œ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        test_queries = [
            ("ì‚¬ì´ë²„ ë³´ì•ˆ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ë²•ì€?", "ì‚¬ì´ë²„ë³´ì•ˆ"),
            ("ê¸ˆìœµ ê¸°ê´€ì˜ ê°œì¸ì •ë³´ ë³´í˜¸ ê·œì •ì€?", "ê·œì œì¤€ìˆ˜"),
            ("ëœì„¬ì›¨ì–´ ê³µê²© ëŒ€ì‘ ë°©ì•ˆì€?", "ìœ„í˜‘ëŒ€ì‘"),
            ("ì˜¤í”ˆë±…í‚¹ API ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ì€?", "í•€í…Œí¬"),
            ("ê¸ˆìœµ ê±°ë˜ ë³¸ì¸ ì¸ì¦ ê°•í™” ë°©ë²•ì€?", "ì¸ì¦"),
        ]
        
        self.log_section("5. ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸")
        
        for query, category in test_queries:
            self.test_retrieval(query, test_name=category)
            logger.info("\n" + "="*60 + "\n")
        
        # 6. ì„±ëŠ¥ í†µê³„
        self.calculate_performance_metrics()
        
        # 7. ê²°ê³¼ ì €ì¥
        self.save_results()
        
        return True
    
    def calculate_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        self.log_section("6. ì„±ëŠ¥ í†µê³„")
        
        if not self.test_results["test_cases"]:
            logger.warning("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ê°€ ì—†ì–´ í†µê³„ ê³„ì‚° ë¶ˆê°€")
            return
        
        # ì‹œê°„ í†µê³„
        timings = {
            "embedding": [],
            "retrieval": [],
            "reranking": [],
            "context": [],
            "total": []
        }
        
        for case in self.test_results["test_cases"]:
            if case["results"]["success"]:
                for key in timings:
                    if key in case["timings"]:
                        timings[key].append(case["timings"][key])
        
        metrics = {}
        for key, values in timings.items():
            if values:
                metrics[f"{key}_avg"] = sum(values) / len(values)
                metrics[f"{key}_min"] = min(values)
                metrics[f"{key}_max"] = max(values)
        
        self.test_results["performance_metrics"] = metrics
        
        # ì¶œë ¥
        logger.info("í‰ê·  ì²˜ë¦¬ ì‹œê°„:")
        logger.info(f"  - ì„ë² ë”©: {metrics.get('embedding_avg', 0):.3f}ì´ˆ")
        logger.info(f"  - ê²€ìƒ‰: {metrics.get('retrieval_avg', 0):.3f}ì´ˆ")
        if self.enable_reranking:
            logger.info(f"  - ë¦¬ë­í‚¹: {metrics.get('reranking_avg', 0):.3f}ì´ˆ")
        logger.info(f"  - ì»¨í…ìŠ¤íŠ¸: {metrics.get('context_avg', 0):.3f}ì´ˆ")
        logger.info(f"  - ì „ì²´: {metrics.get('total_avg', 0):.3f}ì´ˆ")
        
        # ìºì‹œ í†µê³„ (if available)
        if hasattr(self.pipeline, 'reranker') and self.pipeline.reranker:
            if hasattr(self.pipeline.reranker, 'get_stats'):
                stats = self.pipeline.reranker.get_stats()
                if 'cache_stats' in stats:
                    cache = stats['cache_stats']
                    logger.info("\nìºì‹œ í†µê³„:")
                    logger.info(f"  - ì ì¤‘: {cache.get('hits', 0)}")
                    logger.info(f"  - ë¯¸ìŠ¤: {cache.get('misses', 0)}")
                    hit_rate = cache['hits'] / (cache['hits'] + cache['misses']) if (cache['hits'] + cache['misses']) > 0 else 0
                    logger.info(f"  - ì ì¤‘ë¥ : {hit_rate:.1%}")
    
    def save_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        self.log_section("7. ê²°ê³¼ ì €ì¥")
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        result_file = log_dir / f"rag_test_results_{timestamp}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {result_file}")
        logger.info(f"âœ… ë¡œê·¸ íŒŒì¼: {log_file}")
        
        # ìš”ì•½ ì¶œë ¥
        logger.info("\n" + "="*60)
        logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ ìš”ì•½")
        logger.info("="*60)
        logger.info(f"ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(self.test_results['test_cases'])}")
        success_count = sum(1 for case in self.test_results['test_cases'] if case['results']['success'])
        logger.info(f"ì„±ê³µ: {success_count}/{len(self.test_results['test_cases'])}")
        
        if self.test_results["performance_metrics"]:
            avg_total = self.test_results["performance_metrics"].get("total_avg", 0)
            logger.info(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_total:.3f}ì´ˆ")


def main(use_reranking=False):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        use_reranking: Reranking ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    """
    print("="*60)
    print("RAG ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸")
    print("ëª¨ë“  ì¤‘ê°„ ê³¼ì •ì„ ìƒì„¸íˆ ê¸°ë¡í•©ë‹ˆë‹¤")
    print("="*60)
    
    # ëª…ë ¹ì¤„ ì¸ì ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥
    import os
    if os.environ.get('USE_RERANKING', '').lower() == 'true':
        use_reranking = True
    
    if use_reranking:
        print("\nâš ï¸ Reranking ëª¨ë“œ í™œì„±í™”")
        print("- Qwen3-Reranker-4B ëª¨ë¸ ì‚¬ìš©")
        print("- transformers>=4.51.0 í•„ìš”")
    else:
        print("\nğŸ“Œ ê¸°ë³¸ ëª¨ë“œ (Reranking ë¹„í™œì„±í™”)")
        print("- ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ë§Œ ì‚¬ìš©")
    
    # í…ŒìŠ¤í„° ìƒì„± ë° ì‹¤í–‰
    tester = RAGSystemTester(enable_reranking=use_reranking)
    success = tester.run_test_suite()
    
    if success:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: logs/")
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
    
    return success


if __name__ == "__main__":
    try:
        success = main()
        exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\ní…ŒìŠ¤íŠ¸ê°€ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        exit(1)
    except Exception as e:
        print(f"\n\nì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        exit(1)