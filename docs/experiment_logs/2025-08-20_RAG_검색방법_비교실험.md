# 2025년 8월 20일 RAG 검색 방법 비교 실험

## 실험 개요
**목적**: RAG 시스템의 최적 검색 방법 결정을 위한 비교 실험
**환경**: 원격 서버 (SSH: root@47.186.63.142:55033), RTX 4090 24GB
**모델**: Qwen2.5-7B-Instruct (16-bit), KURE-v1 임베더

---

## 실험 1: BM25 vs Vector 독립 비교 (개선된 프롬프트)

### 실험 설계
- **방법**: BM25-only(100%) vs Vector-only(100%) 독립 실행
- **데이터**: test.csv 첫 20개 문제 (객관식 10개, 주관식 10개)
- **프롬프트**: `generate_final_submission_bm25_070.py`의 생산 레벨 프롬프트 적용

### 핵심 결과
- **일치율**: 70% (객관식), 0% (주관식)
- **전체 일치율**: 35% (7/20)
- **처리 시간**: BM25 1.86초/문제, Vector 2.31초/문제

### 주요 발견
1. **프롬프트 엔지니어링의 중요성**
   - 극도로 제한적인 객관식 프롬프트가 일치율을 30% → 70%로 향상
   - 프롬프트 최적화가 검색 방법 선택보다 더 큰 영향

2. **상호보완적 관계**
   - BM25: 키워드 정확 매칭에 강점
   - Vector: 의미적 유사성 기반 검색에 강점
   - 30% 불일치는 각 방법의 고유한 강점 존재

---

## 실험 2: BM25+Vector 결합 방식 (각 3개씩 독립 선택)

### 실험 설계
- **방법**: BM25 상위 3개 + Vector 상위 3개 독립적 선택 (총 6개 문서)
- **비교 대상**: 기존 하이브리드 가중치 방식 (BM25=70%, Vector=30%)
- **가설**: 독립 선택이 더 풍부한 컨텍스트 제공

### 구현 과정
1. **초기 시도**: RAGPipeline 클래스 import 오류
2. **수정 1**: 데이터 직접 로드 방식으로 변경
3. **수정 2**: BM25 메서드 오류 (`retrieve` → `get_top_n`)
4. **수정 3**: GPU 메모리 문제 해결 (임베더 재사용)
5. **최종**: 성공적 실행

### 기술적 문제 해결
- **BM25 tokenize 오류**: `update=False` 파라미터 제거
- **청크 데이터 구조**: 딕셔너리에서 'content' 키 추출
- **GPU 메모리 부족**: 임베더를 한 번만 초기화하고 재사용

### 핵심 결과
- **성공적 구현**: 20개 샘플에서 검증 완료
- **평균 처리 시간**: 3.3초/문제
- **문서 다양성**: 각 방법에서 독립적으로 선택하여 정보 다양성 확보

---

## 실험 3: 전체 테스트셋 예측 (515문제)

### 실행 정보
- **스크립트**: `generate_submission_bm25_vector_top3.py`
- **시작 시간**: 2025-08-20 12:11
- **완료 시간**: 2025-08-20 12:15 (약 4분 15초)
- **출력 파일**: `submission_bm25_vector_top3_20250820_121132.csv`

### 처리 성능
- **처리 속도**: 평균 2-3개/초
- **메모리 관리**: 100개마다 가비지 컬렉션 및 CUDA 캐시 정리
- **안정성**: 에러 핸들링으로 기본값 설정

### 🎯 리더보드 결과
- **제출 점수**: **0.55** (기존 0.46 대비 **+19.6% 향상**)
- **순위 상승**: 대폭 상승
- **핵심 성공 요인**: BM25+Vector 독립 선택 방식의 우수성 입증

---

## 핵심 인사이트

### 1. 프롬프트 > 검색 방법
- 동일한 검색 결과에서도 프롬프트 개선으로 133% 성능 향상
- 극도의 제약이 오히려 일관성 있는 답변 유도

### 2. 독립 선택 > 가중치 통합
- BM25 3개 + Vector 3개 = 총 6개 문서로 더 풍부한 컨텍스트
- 중복 허용으로 정보 다양성 극대화
- 하이브리드 점수 통합보다 우수한 문제해결능력

### 3. 실무 적용 방안
- **즉시 적용**: 개선된 프롬프트 + BM25/Vector 독립 선택 방식
- **추가 개선**: 리랭킹 모델 도입 검토
- **동적 가중치**: 질문 특성에 따른 실시간 조정

### 4. 검증된 성능 향상
- **실제 리더보드 점수**: 0.46 → 0.55 (**+19.6%**)
- **BM25+Vector Top3 방식이 하이브리드 가중치 방식보다 우수함 확인**
- **독립 선택이 각 검색 방법의 강점을 최대한 활용**

---

## 기술적 교훈

### 성공 요인
1. **반복적 디버깅**: 오류 발생 시 즉시 원인 파악 및 수정
2. **리소스 관리**: GPU 메모리 효율적 사용 (임베더 재사용)
3. **데이터 구조 이해**: 청크 딕셔너리 구조 파악 및 적절한 추출

### 실패와 해결
1. **BM25S 라이브러리**: tokenize 메서드 파라미터 불일치 → Kiwi 토크나이저 사용
2. **GPU OOM**: 반복적 임베더 생성 → 초기화 1회로 제한
3. **파일 경로**: 가정한 경로 구조 불일치 → 실제 경로 확인 후 수정

---

## 다음 단계

1. **메인 파이프라인 업데이트**: ✅ BM25+Vector Top3 방식 채택 결정
2. **성능 평가**: ✅ 리더보드 점수 0.55 달성 (19.6% 향상)
3. **추가 최적화**: 
   - 리랭킹 모델 적용
   - 문제 유형별 동적 k값 조정
   - 앙상블 접근법 검토
4. **프로덕션 배포**: BM25+Vector Top3를 기본 검색 전략으로 설정

---

## 실험 환경 정보

### 하드웨어
- GPU: NVIDIA RTX 4090 (24GB VRAM)
- CPU: 서버 환경
- Memory: 충분한 시스템 메모리

### 소프트웨어
- Python: 3.x
- PyTorch: CUDA 지원
- Transformers: 4.41.2
- FAISS: GPU 가속
- BM25: rank_bm25 라이브러리

### 데이터
- RAG 청크: 8,270개
- 임베딩: KURE-v1 (1024차원)
- 테스트셋: 515문제 (객관식 + 주관식 혼합)

---

**작성일**: 2025-08-20
**작성자**: RAG 실험 팀
**상태**: ✅ 완료 - BM25+Vector Top3 방식 채택 확정
**리더보드 점수**: 0.55 (기존 0.46 대비 +19.6%)