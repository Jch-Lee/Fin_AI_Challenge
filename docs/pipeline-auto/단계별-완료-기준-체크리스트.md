# 📋 단계별 완료 기준 체크리스트

## **Epic 1: 데이터 파이프라인 완료 기준**

### 1.1. 프로젝트 초기화 ✅
- [ ] **1.1.1** 폴더 구조 생성 완료 (`tree` 명령으로 구조 확인)
- [ ] **1.1.2** `requirements.txt` 설치 성공 (`pip install -r requirements.txt` 오류 없음)
- [ ] **1.1.3** 코드 품질 도구 설정 (`ruff --version`, `black --version` 실행 가능)

**✅ Epic 1.1 완료 조건**: 모든 의존성 설치 완료 + 폴더 구조 검증 통과

### 1.2. 데이터 수집 및 전처리 ✅
- [ ] **1.2.1** 외부 데이터셋 다운로드 스크립트 실행 성공 (최소 1GB 이상 데이터 수집)
- [ ] **1.2.2** 라이선스 검증 로그 생성 (`data/raw/license_report.json` 파일 생성)
- [ ] **1.2.3** PDF 파싱 테스트 통과 (샘플 PDF → 텍스트 추출 성공)
- [ ] **1.2.4** HTML 파싱 테스트 통과 (샘플 HTML → 정제된 텍스트 추출)
- [ ] **1.2.5** KoreanEnglishTextProcessor 클래스 단위 테스트 통과

**✅ Epic 1.2 완료 조건**: `data/raw/` 폴더에 1GB+ 데이터 + 파싱 테스트 100% 통과

### 1.3. RAG - 청킹 및 임베딩 ✅
- [ ] **1.3.1** RecursiveCharacterTextSplitter로 청크 생성 (청크 크기 300-600 토큰 범위)
- [ ] **1.3.2** KoNLPy 형태소 분석 함수 동작 (한국어 텍스트 → 형태소 리스트 출력)
- [x] **1.3.3** KURE-v1 임베딩 생성 (샘플 텍스트 → 1024차원 벡터 출력)

**✅ Epic 1.3 완료 조건**: `data/processed/chunks.jsonl` 파일 생성 + 임베딩 차원 검증

### 1.4. RAG - 지식 베이스 구축 ✅
- [ ] **1.4.1** FAISS 인덱스 생성 (`data/knowledge_base/faiss.index` 파일 생성)
- [ ] **1.4.2** 인덱스 저장/로드 테스트 (저장 → 로드 → 검색 쿼리 성공)

**✅ Epic 1.4 완료 조건**: FAISS 검색 쿼리 응답 시간 < 100ms + Top-5 결과 반환

### 1.5. 학습 데이터 준비 ✅
- [ ] **1.5.1** Teacher Model 로드 성공 (GPU 메모리 사용량 < 20GB)
- [ ] **1.5.2** Q&A 프롬프트 템플릿 검증 (객관식/주관식 구분 템플릿 작동)
- [ ] **1.5.3** SyntheticQAPair 생성 (최소 1,000개 Q&A 쌍 생성)
- [ ] **1.5.4** 품질 평가 통과 (평균 품질 스코어 ≥ 7.0)

**✅ Epic 1.5 완료 조건**: `data/finetune/synthetic_qa.jsonl` 생성 + 품질 스코어 7.0+

## **Epic 2: Distill-M 2 준비 완료 기준**

### 2.1. 응답 생성 (Logits Generation) ✅
- [ ] **2.1.1** vllm 환경 설정 (`vllm --version` 실행 성공)
- [ ] **2.1.2** Teacher 응답 생성 (샘플 질문 → logits 파일 저장)
- [ ] **2.1.3** Student 응답 생성 (동일 질문 → logits 파일 저장)

**✅ Epic 2.1 완료 조건**: Teacher/Student logits 파일 쌍 생성 + 파일 크기 검증

## **Epic 3: 최종 훈련, 추론 및 최적화 완료 기준**

### 3.1. 최종 훈련 (Distill-M 2) ✅
- [ ] **3.1.1** 데이터 재포맷 성공 (TRL 호환 형식 변환)
- [ ] **3.1.2** DistiLLMTrainer 훈련 완료 (Loss 수렴 확인)
- [ ] **3.1.3** wandb 로그 기록 (훈련 메트릭 시각화 확인)

**✅ Epic 3.1 완료 조건**: 훈련 손실 수렴 + 모델 체크포인트 저장 완료

### 3.2. 추론 파이프라인 구축 ✅
- [ ] **3.2.1** Question Classifier 정확도 ≥ 95% (객관식/주관식 분류)
- [ ] **3.2.2** Cache Layer 동작 (캐시 히트율 ≥ 80%)
- [ ] **3.2.3** Multi-Stage Retriever 성능 (검색 응답 시간 < 200ms)
- [ ] **3.2.4** Inference Orchestrator 통합 테스트 통과
- [ ] **3.2.5** 오프라인 환경 동작 검증 (대회 규칙 5) 필수)

## 3.2.5. 오프라인 환경 대응 검증 상세

**목적**: 대회 환경에서 **인터넷 연결이 완전히 차단된 상태**에서도 정상 동작 보장

**오프라인 환경 시뮬레이션 절차**:

1. **네트워크 차단 테스트 환경 구축**
   ```bash
   # Linux 환경에서 모든 외부 네트워크 차단
   sudo iptables -A OUTPUT -o lo -j ACCEPT
   sudo iptables -A OUTPUT -j DROP
   sudo iptables -A INPUT -i lo -j ACCEPT  
   sudo iptables -A INPUT -j DROP
   ```

2. **필수 오프라인 동작 검증 항목**
   - **모델 로딩**: 로컬 파일에서 모델 가중치 및 토크나이저 로드
   - **데이터 처리**: 외부 API 호출 없이 전처리 및 후처리 수행
   - **추론 실행**: 인터넷 연결 없이 완전한 추론 파이프라인 동작
   - **결과 저장**: 로컬 파일 시스템에 결과 저장

3. **오프라인 호환성 체크리스트**
   - [ ] Hugging Face Hub 캐시 의존성 제거 (`HF_HUB_OFFLINE=1` 환경변수 설정)
   - [ ] 모든 모델/토크나이저 파일 로컬 저장 (`./models/` 디렉토리)
   - [ ] 외부 API 호출 코드 완전 제거 (OpenAI, Anthropic, Google 등)
   - [ ] 인터넷 연결 확인 코드 제거 (`requests.get()`, `urllib` 등)
   - [ ] 패키지 다운로드 의존성 제거 (`pip install` 실행 시 오류 없음)

4. **오프라인 테스트 자동화 스크립트**
   ```python
   # scripts/offline_environment_test.py 구현 예시
   class OfflineEnvironmentValidator:
       def __init__(self, inference_script_path: str):
           self.inference_script = inference_script_path
           self.test_data_path = './test.csv'
           
       def simulate_offline_environment(self):
           """오프라인 환경 시뮬레이션"""
           # 1. 네트워크 연결 차단 (Docker/VM 환경)
           os.environ['HF_HUB_OFFLINE'] = '1'
           os.environ['TRANSFORMERS_OFFLINE'] = '1'
           
           # 2. DNS 서버 접근 차단
           os.environ['NO_PROXY'] = '*'
           
       def validate_offline_inference(self) -> Dict[str, bool]:
           """오프라인 추론 검증"""
           validation_results = {}
           
           try:
               # 1. 모델 로딩 테스트
               validation_results['model_loading'] = self.test_model_loading()
               
               # 2. 추론 실행 테스트  
               validation_results['inference_execution'] = self.test_inference_execution()
               
               # 3. 결과 저장 테스트
               validation_results['result_saving'] = self.test_result_saving()
               
               # 4. 네트워크 호출 누락 검사
               validation_results['no_network_calls'] = self.detect_network_calls()
               
           except Exception as e:
               validation_results['error'] = str(e)
               
           return validation_results
           
       def detect_network_calls(self) -> bool:
           """코드 내 네트워크 호출 패턴 검사"""
           prohibited_patterns = [
               'requests.get', 'requests.post', 'urllib.request',
               'socket.connect', 'http.client', 'openai.api',
               'anthropic.', 'google.api', 'huggingface_hub.download'
           ]
           
           # 소스 코드 정적 분석으로 금지 패턴 검사
           return self.scan_source_code_for_patterns(prohibited_patterns)
   ```

5. **오프라인 환경 최적화 전략**
   - **사전 캐시 구축**: 모든 필요한 모델/데이터를 사전에 다운로드하여 로컬 저장
   - **Fallback 메커니즘**: 네트워크 의존 기능에 대한 오프라인 대체 로직 구현  
   - **환경 변수 설정**: `HF_HUB_OFFLINE=1`, `TRANSFORMERS_OFFLINE=1` 등 오프라인 모드 활성화
   - **의존성 최소화**: 네트워크 연결이 필요한 라이브러리 사용 최소화

**오프라인 테스트 완료 기준**:
- [ ] **3.2.5.1** 네트워크 차단 상태에서 추론 스크립트 정상 실행
- [ ] **3.2.5.2** 모든 모델/데이터 파일 로컬에서 로드 성공  
- [ ] **3.2.5.3** 외부 API 호출 패턴 완전 제거 확인
- [ ] **3.2.5.4** 결과 파일 정상 생성 및 형식 준수

**✅ Epic 3.2 완료 조건**: 전체 추론 파이프라인 End-to-End 테스트 성공

### 3.3. 예측 및 제출 ✅
- [ ] **3.3.1** 배치 처리 성능 (1000개 문제 < 1시간 처리)
- [ ] **3.3.2** Fallback Handler 동작 (타임아웃 시 대체 답변 생성)
- [ ] **3.3.3** submission.csv 형식 검증 (컬럼명, 인코딩, 행 수 일치)

**✅ Epic 3.3 완료 조건**: 제출 파일 형식 100% 준수 + 성능 목표 달성

### 3.4. 최종화 (Finalization) ✅
- [ ] **3.4.1** 모델 양자화 완료 (모델 크기 < 15GB + 성능 유지)
- [ ] **3.4.2** 성능 비교 리포트 (양자화 전후 정확도/속도 비교표)
- [ ] **3.4.3** 제출 패키지 생성 (`submission.zip` 파일 + 실행 가이드)

**✅ Epic 3.4 완료 조건**: RTX 4090에서 4.5시간 내 전체 추론 완료 + 제출 패키지 검증

## **🎯 전체 프로젝트 완료 최종 기준**

1. **성능 목표 달성**:
   - 단일 문제 추론 시간: < 3초
   - 전체 추론 시간: < 4.5시간 (RTX 4090 기준)
   - GPU 메모리 사용량: < 22GB

2. **품질 검증 통과**:
   - Question Classifier 정확도: ≥ 95%
   - 캐시 히트율: ≥ 80%
   - 검색 응답 시간: < 200ms

3. **제출 준비 완료**:
   - submission.csv 형식 100% 준수
   - 실행 환경 검증 완료
   - 제출 패키지 압축 완료

이 상세 작업 목록과 완료 기준이 팀의 실제 개발을 위한 구체적인 가이드가 될 것입니다.

---

![image.png](image.png)

![image.png](image%201.png)

![image.png](image%202.png)

---

## **RAG + Distill-M 2 파이프라인 스토리 📖**

아주 오래전, 세상의 모든 금융과 IT 보안 지식이 담긴 **'위대한 도서관'** 이 있었습니다. 이 도서관의 지식을 완벽하게 이해하여 어려운 시험에 통과하는 것이 우리의 목표입니다.

## **1장: 도서관 정리와 카드 목록 제작 (Epic 1: 데이터 파이프라인)** 📚

시험을 준비하기 전, 먼저 도서관부터 정리해야 합니다.

- **'성실한 사서 팀' (`Data Preprocessing Component`)** 이 도서관에 도착합니다. 도서관에는 오래된 양피지(PDF), 두루마리(HTML), 석판(TXT) 등 온갖 형태의 책들이 뒤죽박죽 섞여 있습니다.
- 사서들은 이 모든 책을 펼쳐 먼지를 털고(`텍스트 정제`), 내용을 깔끔한 **'지식 카드' (`DocumentChunk`)** 로 한 장씩 옮겨 적습니다.
- 마지막으로, 어떤 질문에도 즉시 관련 카드를 찾을 수 있도록, 모든 카드의 위치와 핵심 내용을 담은 마법의 **'카드 색인집' (`FAISS Index`)** 을 만듭니다.

이제 도서관은 완벽하게 정리되었습니다.

## **2장: 거장의 특별한 훈련법 (Epic 2 & 3: Distill-M 2 훈련)** 🧠

도서관에는 모든 것을 아는 **'거장' (`Teacher Model`)** 이 있지만, 그는 너무 거대해서 작은 시험장에는 들어갈 수 없습니다. 그래서 재능 있는 **'영재 견습생' (`Student Model`)** 을 대신 시험에 내보내기로 하고, 특별한 훈련을 시작합니다.

1. **모의고사:** '사서'가 가져온 '지식 카드'를 보고 '견습생'이 먼저 문제의 답을 풀어봅니다. 중요한 것은, 답뿐만 아니라 그 답을 고른 **'생각의 과정' (`Student Logits`)** 까지 상세히 기록하는 것입니다.
2. **거장의 해설:** 같은 문제를 '거장'도 풀어봅니다. 그리고 자신의 완벽한 답과 함께, 왜 그렇게 생각했는지에 대한 **'생각의 과정' (`Teacher Logits`)** 을 남깁니다.
3. **1:1 특별 과외 (`DistiLLMTrainer`):** 이제 **'특별 교사'** 가 등장합니다. 그는 견습생의 답과 거장의 답을 비교하며 이렇게 가르칩니다.
    
    > "견습생, 자네는 정답을 맞혔지만, 거장께서는 자네가 생각하지 못한 다른 가능성도 5% 정도 고려하셨네. 그 미묘한 차이가 진짜 실력일세."
    > 
    
    단순히 정답을 알려주는 것이 아니라, 두 사람의 **'생각의 과정(로짓)'이 어떻게 다른지를 비교 분석**하여, 견습생이 무엇을 더 배워야 하는지를 알려줍니다. 이것이 바로 **'대조적 증류(Contrastive Distillation)'** 입니다.
    
4. **깨달음과 성장:** '견습생'은 이 특별 과외를 통해, 단순히 지식을 암기하는 것을 넘어 **'거장처럼 생각하는 법'** 을 배우며 성장합니다.

## **3장: 결전의 날 (Epic 3: 최종 추론)** 🏆

드디어 시험 당일, 완벽하게 훈련된 '견습생'과 그의 팀이 시험장에 들어섭니다.

1. **문제 분석 (`Question Classifier`):** 시험관이 문제를 나눠주자마자, '분석가'가 즉시 문제가 객관식인지 주관식인지 파악합니다.
2. **자료 수집 (`Multi-Stage Retriever`):** '자료 조사팀'이 마법의 '카드 색인집(FAISS)'과 키워드 검색(BM25)을 동시에 사용하여, 질문과 관련된 가장 정확한 '지식 카드'들을 순식간에 찾아냅니다. (이전에 찾아본 자료는 **`캐시`** 에서 더 빨리 꺼내옵니다.)
3. **답안 작성 (`Inference Orchestrator` & `Student Model`):** '감독관'이 질문과 찾아낸 지식 카드들을 '견습생'에게 전달합니다. '견습생'은 거장처럼 생각하는 훈련을 통해, 지식 카드를 근거로 완벽한 답안을 작성합니다.
4. **최종 제출:** 감독관은 답안지를 채점 규정에 맞게 **`submission.csv`** 라는 공식 답안지로 옮겨 적어 제출합니다.

이 이야기처럼, 우리 파이프라인은 체계적인 데이터 준비, 독창적인 훈련 방식, 그리고 효율적인 추론 팀플레이를 통해 최종 목표를 달성하도록 설계되었습니다.