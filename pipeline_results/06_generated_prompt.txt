당신은 금융 보안 전문가입니다. 주어진 컨텍스트를 바탕으로 질문에 답변해주세요.

=== 관련 컨텍스트 ===
제2장. AI 서비스 구성                           - ●●

마. 로깅

 이용자의 메시지, AI 모델 학습 관련 데이터, 웹/시스템 로그 등의 데이터를 수집하는

단계이다.(❼ 과정)

 관리자는 웹/시스템 로그, AI 엔진 출력값 등의 로그를 모니터링 또는 대시보드 등에

적용하여 운영에 참고할 수 있다.(➑ 과정)

 또한, 로그 데이터는 AI 모델 학습 데이터로 활용할 수 있으며, 이를 통해 AI 모델의

성능을 향상시킬 수 있다.(❾ 과정)

･
바. 모니터링 리포팅

 관리자는 대시보드 등을 활용하여 AI 서비스의 운영상태, AI 모델의 성능 등을 모니터링

할 수 있다.

 웹/시스템 로그 등 서비스와 관련된 로그 정보를 기반으로 AI 서버 상황, 공격 여부,

이용자 현황 등을 파악할 수 있다.


AI 서비스의 성능을 모니터링하고, AI 엔진 재학습 등을 판단할 수 있는 지표로

활용할 수 있다.

참고 AI챗봇서비스 활용예시

< 챗봇서비스 구성도 >

13

- ●● 금융분야 AI 보안 가이드라인

･
❶ (AI 활용) 챗봇 사용자의 문장(질문)에서 의도를 정확히 이해 분류하는 자연어처리
   - (NLP)에 활용하며, 챗봇 전문업체나 금융회사가 개발한 NLP, 또는 글로벌 클라우드

NLP를 연계 사용

- 컨텐츠 분류, 주제 발견 및 모델링, 맥락 추출, 음성↔문자간 변환(STT,TTS) 등

- AI 엔진은 내부 시스템(온프레미스)에 구축 비율이 높으나, 자체 클라우드로

전환하거나 API 연계를 통해 클라우드 기반 PaaS, SaaS 서비스 이용 사례도

다수 존재

- ‘잘 알아듣는 챗봇’을 만들려면 AI 엔진의 정확도를 향상시키기 위해 시나리오에 따라

･
인텐트(의도)와 엔티티(핵심 개체), 답변 시나리오 집합 등을 지속 수정 보완한 후
AI 엔진을 (재)학습

･
❷ (챗봇 용도 및 방식) 금융 상품 소개 상담용, 내부 직원용, 금융 웹/앱과 통합한 형태의

< 오염된 중앙서버의 AI 모델 비교 >

✓ 악성 클라이언트는 AI 모델을 비정상적인 방향으로 학습시키고자 하며, 이를 통해

회피 공격과 같은 적대적 공격, 교란 등의 행위 가능

< 악성 클라이언트의 학습 방향 >

33

- ●● 금융분야 AI 보안 가이드라인


비잔티움 에러를 완화하기 위해서 클라이언트로부터 학습되는 과정을 확인하거나

통계적인 기법을 확인하는 방법이 연구되고 있다.

(학습과정 확인을 통한 탐지 [9)] ) 클라이언트로부터 중앙 서버의 AI 모델의 학습 정도가

변화되는 과정을 확인하여, 악성 클라이언트를 탐지한다.

참고 FoolsGold 기법 [9)]

✓ 클라이언트로부터 전달받은 매개변수를 적용한 학습 시에, 정상 클라이언트로부터

받은 매개변수와 악성 클라이언트로부터 받은 매개변수의 학습 방향이 다를 것이라

가정하고 이러한 특성을 통해 악성 클라이언트를 탐지

∙ 정상 클라이언트의 학습 방향과 공격자 간 벡터 각도는 γ로 표시할 수 있으며,

악성 클라이언트 간 각도는 θ로 표시

∙ 일정 θ와 γ를 기준으로 악성을 탐지

< FoolsGold 기법 개념 >

9) Fung, Clement, Chris JM Yoon, and Ivan Beschastnikh., “Mitigating Sybils in Federated Learning
Poisoning”, 2018.

34

제3장. AI 학습 데이터 및 모델 보안 관리                    - ●●

･
4 AI 모델 검증 평가

가. 개요

 학습 후 AI 모델의 성능을 확인하기 위해서 검증 및 평가(테스트)를 시행하는 단계이다.


(모델 검증) 학습이 완료된 모델을 검증하기 위한 단계로 학습 시에 이용된 데이터셋의

일부를 검증에 이용한다.

※ 홀드아웃 검증, K폴드 교체검증 등의 기법 활용 가능


(평가) 학습과 검증 후에 모델의 최종 성능을 평가하기 위하여 테스트하는 단계로

･
학습 검증용 데이터셋과 별개의 평가 데이터셋을 준비해 평가에만 사용한다.

참고 AI 서비스 개발 시의 데이터셋 구분 10)

나. 보안 고려사항

- 1 (정보 관리) 검증･테스트 시에 이용한 데이터셋, AI 모델 매개변수 등의 정보를 관리한다.


AI 모델을 개발하는 데 있어, 투명성은 서비스의 품질 및 사고 대응에 도움이 되며,

보안 팀이나 개발자가 성능 저하 및 장애가 발생한 시기와 지점을 확인할 수 있다.

- 2 (적대적 공격 테스트) AI 모델을 대상으로 적대적 공격 등을 수행하여, 성능 수준을

평가한다.


AI 모델 성능이 일정 수준 이하로 저하된다면, 적대적 예제를 다시 학습하거나 적대적

공격 탐지 기법 적용 등 강건성 확보 대책을 마련할 수 있다.

10) https://statology.org/validation-set-vs-test-set/

35

- ●● 금융분야 AI 보안 가이드라인

- 3 (최종 출력값 확인) 개인정보 등 민감한 정보가 이용자에게 출력되는지 확인한다.

 민감한 정보가 출력되는 경우, 불특정 다수 또는 타인에게 노출이 되지 않도록 하는

방안을 마련한다.

※ AI 학습 데이터의 개인정보 활용과 관련된 상세한 사항은 개인정보보호법 및 인공지능

(AI) 개인정보보호 자율점검표(’21.5., 개인정보위) 참조

- 4 (출력 횟수 제한) AI 모델의 출력 횟수를 제한하여 모델의 정보 및 학습 데이터 유추를

어렵게 한다.

 ･
공격자는 AI 모델의 입 출력값을 기반으로 모델의 정보를 유추하고, 공격을 시도한다.

※ [참고3] 모델 추출 공격, [참고4] 모델 인버전 공격, [참고5] 회피 공격 참조

 실제로 입･출력값 수집을 통해 아마존과 BigML의 유료 AI 모델을 99% 이상의

유사성으로 복제한 사례가 있다. [11)]

 ･
AI 모델 정보의 유추와 모델 복제를 막기 위해서는 입 출력 횟수와 시간을 제한하는

방법 등을 적용할 수 있다.

=== 질문 ===
금융 AI 시스템의 보안을 위해 어떤 조치들이 필요한가요?

=== 답변 ===
주어진 컨텍스트를 바탕으로 정확하고 간결한 답변을 제공하세요.